---
title: "2025-09-01 看完杨植麟访谈，才意识Benchmark是当前最关键的卡点"
date: 2025-12-05T13:54:04.763099
tags: ['tech', 'ai']
description: ""
---

听了张小珺对杨植麟的访谈播客，我最大的感受是，杨植麟已经清晰地将自己定位成一位“攀登者”。他花很少篇幅谈论商业化，却深入分享了很多AI算法和趋势的看法，其中“强化学习”和“Agent”是出现频率最高的词。对比他以前的访谈，除了对Scaling Law的坚持没变，其它观点几乎都有刷新。

这种转变，很大程度上是由于行业标杆的推动——去年9月OpenAI发布o1，以及今年初DeepSeek的进展，让整个行业更加坚定地走向了强化学习之路。

他提到一本对他影响很大的书《The Beginning of Infinity》，书中有两句话：“问题是不可避免的”和“问题是可以解决的”。能感受到，他在研发过程中遇到了数不清的难题，而这两句话，某种程度上成了他坚持的信念。

他谈论的以下几个方面是我比较关注的：

## 过去一年大模型的技术演进

最明显的是，整个技术范式正从“监督微调”转向“强化学习”。具体呈现为两种方式：

1. “强思考”推理模型：让模型学会反思——先提出猜想，再验证对错。这种方式大幅提高了模型的推理能力，从原来多次生成才可能答对（Pass@k），进化到经常一次就命中正确答案（Pass@1）。
1. 多轮Agent范式：模型不再是“一问一答”，而是可以边思考、边操作，通过多轮交互完成任务。不管是通过更多轮次交互，还是更深入的思考，本质上都是同一种思路——在推理阶段投入更多计算，也就是“Test Time Scaling”。
## Agentic LLM（这是我认为最有价值的一段）

### Agent的目的

Agent的核心在于与外界交互，体现为多轮对话和使用工具。工具目前有联网和代码等第。以后会有个性化的工具，例如定制的文档接口，定制的公司的数据库，定制的api等等。如果Agentic LLM可以泛化到这些长尾的问题上，那么专用的Agent可能就会被淘汰。

工作其实就是多轮使用工具的序列。哪怕是程序员，写代码也只占了工作的一小部分。

Agent 系统的主要目的不是模拟人，而是通用。所以它不需要跟人在每一个环节都对齐。它在目标是可以和人是对齐的，但是在做法上面，可能在某些方面是类似的，但是也有可能是不相同的。

那么怎么样提高这些 Agent 的通用性呢？我们刚刚说过，目前的基准测试（benchmark）非常不足，可能的一个方法是用 AI 训练 AI，用 AI 对齐 AI。

### 做Agent，大模型公司 vs 应用公司有什么不同？

- 应用公司是在“逆向工程”：通过设计提示词、组合工具和上下文工程等方式，激发模型能力。
- 大模型公司是在做“正向工程”：在训练阶段就内建了对工具的理解和使用能力，所以在对应场景中表现更自然、更强大，比如Claude Code和ChatGPT Agent。
### 最大的瓶颈

Agentic LLM最大的问题是缺乏能真正衡量Agent泛化能力的Benchma。目前的benchmark非常不足，在某一些benchmark会过拟合不代表真正性能的提升。因为当前Agent的训练和评估都是“单点”的，容易在特定Benchmark上过拟合，而非获得真正的通用能力。

### 需要解决的问题

1. 高频使用的工具还可以做得更好
1. 长尾的工具无法泛化
1. 缺乏能真实反映Agent水平的Benchmark
## 未来

期待用Innovation的方式提高Agent能力，当模型能自我迭代（拥有Agentic功能的模型参与自身的开发过程）时，才会迎来真正的突破。

## 感想

听完这期播客，不知为何我想起了推石上山的西西弗斯。知识的边界不断拓展，旧问题解决了，新问题又来了——或许重要的不是终点，而是攀登本身。杨植麟目前坚持的，也许正是这样一种信念：大模型的前景尚未明朗，但只要持续把Agentic LLM做下去，就有机会改变很多事情。而即便问题永远不断，享受这个过程，本身就已是一种回应。

 