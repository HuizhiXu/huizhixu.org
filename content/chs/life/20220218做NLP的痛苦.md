---
author: "Huizhi"
title: "2022-02-18 做NLP基础不牢的痛苦"
date: 2022-02-18T20:07:58+08:00 
lastmod: 2022-10-14
description: "做NLP太痛苦了，不知其然，也不知其所以然。这就是我的体会。"
tags: ["life","2022"]
draft: True
pin: false
isCJKLanguage: true
thumbnail: https://picsum.photos/id/43/400/250
---




最近接触到了一些NLP的东西。主要是以下方面：

- [ ]  Resnet152
- [ ]  决策树/随机森林/逻辑回归
- [ ]  TextCNN
- [ ]  NER

上面这些任务，都是用来处理文本的。但是效果都很糟糕。

“如何识别一个标题”

“如何识别一段正文”

“如何识别实体”

“如何判断识别的正文是正文”

做上面每一个任务，我都费了九牛二虎之力。Resnet152没做出什么名堂，但是误打误撞高亮标注让测试员的工作变得简单。决策树/逻辑回归找特征生成特征值这个过程很繁琐，最后效果满意了吗？我不满意但是领导说可以了。TextCNN做了两次，一个用Kashgari做，识别正文，无区分度。一次自己写CNN做，区分标题，两次效果都很一般，当然两次数据集都很小。NER是最令我头疼的，前后花了很多时间。刚开始都不知道数据怎么标注，后面跑起来了，但是没在GPU上运行，后来在GPU上运行成功了，模型保存出错了，现在都没有解决。