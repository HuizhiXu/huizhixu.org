<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage"><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="/favicon.ico">

  <title>
  2023-01-31 如何用HuggingFace对不均衡类别进行分类 - HuizhiXu 的个人博客
  </title>
  <meta name="description" content="如果用Trainer这个API，只要更新compute_loss方法就可以，如果是用pytorch写的训练代码或者用了huggingface accelerate模型，那么要更新自己模型的forward函数。" /><meta name="generator" content="Hugo 0.115.4"><link
    rel="stylesheet"
    href="https://huizhixu.github.io/css/styles.min.a8628a7949d76d4d5a8696640e2a604a1f7c9b8690f3511812a99462f2193a69.css"
    integrity="sha256-qGKKeUnXbU1ahpZkDipgSh98m4aQ81EYEqmUYvIZOmk="
  />
  
  

  <meta property="og:title" content="2023-01-31 如何用HuggingFace对不均衡类别进行分类" />
<meta property="og:description" content="如果用Trainer这个API，只要更新compute_loss方法就可以，如果是用pytorch写的训练代码或者用了huggingface accelerate模型，那么要更新自己模型的forward函数。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://huizhixu.github.io/post/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-01-31T19:31:50+08:00" />
<meta property="article:modified_time" content="2023-01-31T19:31:50+08:00" />

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="2023-01-31 如何用HuggingFace对不均衡类别进行分类"/>
<meta name="twitter:description" content="如果用Trainer这个API，只要更新compute_loss方法就可以，如果是用pytorch写的训练代码或者用了huggingface accelerate模型，那么要更新自己模型的forward函数。"/>

  <meta itemprop="name" content="2023-01-31 如何用HuggingFace对不均衡类别进行分类">
<meta itemprop="description" content="如果用Trainer这个API，只要更新compute_loss方法就可以，如果是用pytorch写的训练代码或者用了huggingface accelerate模型，那么要更新自己模型的forward函数。"><meta itemprop="datePublished" content="2023-01-31T19:31:50+08:00" />
<meta itemprop="dateModified" content="2023-01-31T19:31:50+08:00" />
<meta itemprop="wordCount" content="366">
<meta itemprop="keywords" content="" />

  
</head>
<body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative">
  <a href="https://huizhixu.github.io/" class="capitalize font-extrabold text-2xl">
    
    HuizhiXu 的个人博客
    
  </a>
  <button class="mobile-menu-button md:hidden">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <line x1="4" y1="8" x2="20" y2="8" />
      <line x1="4" y1="16" x2="20" y2="16" />
    </svg>
  </button>
  <ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800">

    

    

    

    
  </ul>
</header>
<main class="flex-1">
  
  

  

  <article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4">

    <h1 class="text-2xl font-bold mb-2">2023-01-31 如何用HuggingFace对不均衡类别进行分类</h1>
    
    <h5 class="text-sm flex items-center flex-wrap">
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <rect x="4" y="5" width="16" height="16" rx="2" />
        <line x1="16" y1="3" x2="16" y2="7" />
        <line x1="8" y1="3" x2="8" y2="7" />
        <line x1="4" y1="11" x2="20" y2="11" />
        <rect x="8" y="15" width="2" height="2" />
      </svg>
      Posted on 
  
    January 31, 2023
  


      
        &nbsp;&bull;&nbsp;
      
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <circle cx="12" cy="12" r="9" />
        <polyline points="12 7 12 12 15 15" />
      </svg>
      2&nbsp;minutes
      &nbsp;&bull;
      <svg xmlns="http://www.w3.org/2000/svg" class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <line x1="3" y1="6" x2="3" y2="19" />
        <line x1="12" y1="6" x2="12" y2="19" />
        <line x1="21" y1="6" x2="21" y2="19" />
      </svg>
      366&nbsp;words
      
        
      
    </h5>
    

    

    <h1 id="如何用huggingface对不均衡类别进行分类">如何用HuggingFace对不均衡类别进行分类</h1>
<h2 id="数据均衡">数据均衡</h2>
<p>做文本分类时，如果类别数量差别不大，可以用hugging face的Trainer类，训练代码如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> BertForSequenceClassification<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;bert-base-chinese&#34;</span>, num_labels<span style="color:#f92672">=</span>len(labels),
</span></span><span style="display:flex;"><span>                                                      problem_type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;multi_label_classification&#34;</span>, id2label<span style="color:#f92672">=</span>id2label,
</span></span><span style="display:flex;"><span>                                                      label2id<span style="color:#f92672">=</span>label2id)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> BertTokenizerFast<span style="color:#f92672">.</span>from_pretrained(<span style="color:#e6db74">&#34;bert-base-chinese&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_metrics</span>(p):
</span></span><span style="display:flex;"><span>    preds <span style="color:#f92672">=</span> p<span style="color:#f92672">.</span>predictions[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">if</span> isinstance(p<span style="color:#f92672">.</span>predictions,
</span></span><span style="display:flex;"><span>                                           tuple) <span style="color:#66d9ef">else</span> p<span style="color:#f92672">.</span>predictions
</span></span><span style="display:flex;"><span>    result <span style="color:#f92672">=</span> multi_label_metrics(
</span></span><span style="display:flex;"><span>        predictions<span style="color:#f92672">=</span>preds,
</span></span><span style="display:flex;"><span>        labels<span style="color:#f92672">=</span>p<span style="color:#f92672">.</span>label_ids)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> result
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">=</span>model_directory, 
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span><span style="color:#ae81ff">5e-5</span>,
</span></span><span style="display:flex;"><span>    per_device_train_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    per_device_eval_batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    num_train_epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>    dataloader_drop_last<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    weight_decay<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>,
</span></span><span style="display:flex;"><span>    save_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>    logging_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>data[<span style="color:#e6db74">&#34;train&#34;</span>],
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>data[<span style="color:#e6db74">&#34;train&#34;</span>],
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    compute_metrics<span style="color:#f92672">=</span>compute_metrics
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>evaluate()
</span></span></code></pre></div><p>model_directory 是模型存储路径，data是数据。</p>
<h2 id="数据不均衡">数据不均衡</h2>
<p>如果类别数据不均衡时，例如 class A有1000个数据，class B有100个数据，也可以用上面的训练代码，但是预测B的效果不会很好。</p>
<p>要解决数据不均衡的问题，可以考虑加一个class weight。加class weight的意思是给class B一个更高的权重，让模型预测的时候多考虑一下class B，方向往class B偏离。</p>
<p>官网给了一个例子，需要我们继承Trainer类，自定义一个类，也就是这里的CustomTrainer，重写compute_loss 这个方法。</p>
<p>在训练的时候只要初始化CustomTrainer类就可以了，也就是把trainer = Trainer(…) 改为trainer = CustomTrainer(…)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> Trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomTrainer</span>(Trainer):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_loss</span>(self, model, inputs, return_outputs<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        labels <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;labels&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># forward pass</span>
</span></span><span style="display:flex;"><span>        outputs <span style="color:#f92672">=</span> model(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> outputs<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;logits&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># compute custom loss</span>
</span></span><span style="display:flex;"><span>        loss_fct <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss(weight<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>tensor([<span style="color:#ae81ff">0.2</span>, <span style="color:#ae81ff">0.3</span>]))
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> loss_fct(logits<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, self<span style="color:#f92672">.</span>model<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>num_labels), labels<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (loss, outputs) <span style="color:#66d9ef">if</span> return_outputs <span style="color:#66d9ef">else</span> loss
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">...</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> CustomTrainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>encoded_data[<span style="color:#e6db74">&#34;train&#34;</span>],
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>encoded_data[<span style="color:#e6db74">&#34;train&#34;</span>],
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    compute_metrics<span style="color:#f92672">=</span>compute_metrics
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>evaluate()
</span></span></code></pre></div><p>直接复制可能会出错。 如果出现了如下错误提示，显示loss_fct和loss错误。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">ValueError</span>: Expected input batch_size (<span style="color:#ae81ff">2</span>) to <span style="color:#66d9ef">match</span> target batch_size (<span style="color:#ae81ff">20</span>)<span style="color:#f92672">.</span>
</span></span></code></pre></div><p>所以要改loss_fct，去看看源代码是如何计算loss的。<a href="https://github.com/huggingface/transformers/blob/v4.17.0/src/transformers/models/bert/modeling_bert.py#L1563-L1583" target="_blank" rel="noopener">源代码</a>
 进行loss的计算是在BertForSequenceClassification的forward方法里面。回归、二分类和多分类都有不同的loss 计算方法。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># 源代码 L1563-L1583</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> labels 
</span></span><span style="display:flex;"><span><span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">is</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>num_labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;regression&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">elif</span> self<span style="color:#f92672">.</span>num_labels <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">and</span> (labels<span style="color:#f92672">.</span>dtype <span style="color:#f92672">==</span> torch<span style="color:#f92672">.</span>long <span style="color:#f92672">or</span> labels<span style="color:#f92672">.</span>dtype <span style="color:#f92672">==</span> torch<span style="color:#f92672">.</span>int):
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;single_label_classification&#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                    self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;multi_label_classification&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;regression&#34;</span>:
</span></span><span style="display:flex;"><span>                loss_fct <span style="color:#f92672">=</span> MSELoss()
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>num_labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>                    loss <span style="color:#f92672">=</span> loss_fct(logits<span style="color:#f92672">.</span>squeeze(), labels<span style="color:#f92672">.</span>squeeze())
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                    loss <span style="color:#f92672">=</span> loss_fct(logits, labels)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;single_label_classification&#34;</span>:
</span></span><span style="display:flex;"><span>                loss_fct <span style="color:#f92672">=</span> CrossEntropyLoss()
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> loss_fct(logits<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, self<span style="color:#f92672">.</span>num_labels), labels<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">elif</span> self<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>problem_type <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;multi_label_classification&#34;</span>:
</span></span><span style="display:flex;"><span>                loss_fct <span style="color:#f92672">=</span> BCEWithLogitsLoss()
</span></span><span style="display:flex;"><span>                loss <span style="color:#f92672">=</span> loss_fct(logits, labels)
</span></span></code></pre></div><p>所以如果出现batch_size和target_size 不匹配的问题， 要考虑我们解决的问题是二分类还是多分类的问题，多分类用BCE，代码如下</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomTrainer</span>(Trainer):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_loss</span>(self, model, inputs, return_outputs<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        labels <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;labels&#34;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># forward pass</span>
</span></span><span style="display:flex;"><span>        outputs <span style="color:#f92672">=</span> model(<span style="color:#f92672">**</span>inputs)
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> outputs<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#39;logits&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># compute custom loss</span>
</span></span><span style="display:flex;"><span>        loss_fct <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BCEWithLogitsLoss(
</span></span><span style="display:flex;"><span>            weight<span style="color:#f92672">=</span>tensor([<span style="color:#ae81ff">0.9999</span>, <span style="color:#ae81ff">3.1111</span>,<span style="color:#ae81ff">0.9999</span>, <span style="color:#ae81ff">0.9999</span>, <span style="color:#ae81ff">0.9999</span>,<span style="color:#ae81ff">2.1333</span>]))
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> loss_fct(logits, labels)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> (loss, outputs) <span style="color:#66d9ef">if</span> return_outputs <span style="color:#66d9ef">else</span> loss
</span></span></code></pre></div><p>loss_fct 里面的 weight 的计算可以用sklearn.utils.compute_weight这个方法计算。classes是数据的类别，不重复，y是所有数据的label。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>class_weights <span style="color:#f92672">=</span> class_weight<span style="color:#f92672">.</span>compute_class_weight(<span style="color:#e6db74">&#39;balanced&#39;</span>, classes<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array(data<span style="color:#f92672">.</span>labels<span style="color:#f92672">.</span>unique()),
</span></span><span style="display:flex;"><span>                                                  y<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>array(data<span style="color:#f92672">.</span>labels))
</span></span><span style="display:flex;"><span>class_weights <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>tensor(class_weights, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float)
</span></span><span style="display:flex;"><span>print(class_weights)
</span></span></code></pre></div><p>如果出现这个错误那，就说明模型训练的时候，有可能模型、输入或者loss在本地device，建议在模型和输入后面加.to(device)。
Hugging Face说Trainer类它自己会识别gpu环境，是不需要把模型和数据转到gpu的。那么最有可能就是loss的计算还在本地。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">RuntimeError</span>: Expected all tensors to be on the same device, but found at least two devices, cuda:<span style="color:#ae81ff">0</span> <span style="color:#f92672">and</span> cpu<span style="color:#960050;background-color:#1e0010">!</span>
</span></span></code></pre></div><p>最后的解决办法是，在计算loss的时候将loss传到device上面去。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda&#34;</span>) <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cpu&#34;</span>)
</span></span><span style="display:flex;"><span>loss_fct <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BCEWithLogitsLoss(
</span></span><span style="display:flex;"><span>            weight<span style="color:#f92672">=</span>tensor([<span style="color:#ae81ff">0.9529</span>, <span style="color:#ae81ff">0.9529</span>, <span style="color:#ae81ff">1.8027</span>, <span style="color:#ae81ff">0.9394</span>, <span style="color:#ae81ff">0.9529</span>, <span style="color:#ae81ff">0.9529</span>, <span style="color:#ae81ff">0.9529</span>, <span style="color:#ae81ff">0.9667</span>, <span style="color:#ae81ff">0.9529</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#ae81ff">0.9529</span>]))<span style="color:#f92672">.</span>to(device)
</span></span></code></pre></div><p>总结：如果用Trainer这个API，只要更新compute_loss方法就可以，如果是用pytorch写的训练代码或者用了huggingface accelerate模型，那么要更新自己模型的forward函数。</p>
<h2 id="参考">参考</h2>
<p><strong><a href="https://discuss.huggingface.co/t/how-can-i-use-class-weights-when-training/1067" target="_blank" rel="noopener">How can I use class_weights when training?</a>
</strong></p>
<p><strong><a href="https://stackoverflow.com/questions/71581197/what-is-the-loss-function-used-in-trainer-from-the-transformers-library-of-huggi" target="_blank" rel="noopener">What is the loss function used in Trainer from the Transformers library of Hugging Face?</a>
</strong></p>
<p><strong><a href="https://discuss.huggingface.co/t/custom-loss-function-forward-vs-custom-loss/21526" target="_blank" rel="noopener">Custom loss function forward vs. custom_loss</a>
</strong></p>

  </article><div class="bg-pink-50 dark:bg-gray-900">
  <div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center">
    <div>
      <div class="text-2xl font-bold mb-2"></div>
      <p class="opacity-60"></p>
    </div>

    <ul class="flex justify-center gap-x-3 flex-wrap gap-y-2">
      
    </ul>
  </div>
</div>

    </main><footer class="container p-6 mx-auto flex justify-between items-center">
  <span class="text-sm font-light">
    
    2023 © HuizhiXu 的个人博客
    
  </span>
  <span onclick="window.scrollTo({top: 0, behavior: 'smooth'})" class="p-1 cursor-pointer">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5"
      stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M18 15l-6 -6l-6 6h12" />
    </svg>
  </span>
</footer>









<script>
  const mobileMenuButton = document.querySelector('.mobile-menu-button')
  const mobileMenu = document.querySelector('.mobile-menu')
  function toggleMenu() {
    mobileMenu.classList.toggle('hidden');
    mobileMenu.classList.toggle('flex');
  }
  if(mobileMenu && mobileMenuButton){
    mobileMenuButton.addEventListener('click', toggleMenu)
  }
</script>
</body>
</html>
