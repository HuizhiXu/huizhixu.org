<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on 徐慧志的个人博客</title><link>https://huizhixu.github.io/chs/</link><description>Recent content in Blog on 徐慧志的个人博客</description><generator>Hugo</generator><language>chs</language><lastBuildDate>Thu, 27 Nov 2025 13:55:11 +0000</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/index.xml" rel="self" type="application/rss+xml"/><item><title>2025-11-27 人脑的记忆和Agent的记忆是完全不同的</title><link>https://huizhixu.github.io/chs/know_how/20251127-%E4%BA%BA%E8%84%91%E7%9A%84%E8%AE%B0%E5%BF%86%E5%92%8Cagent%E7%9A%84%E8%AE%B0%E5%BF%86%E6%98%AF%E5%AE%8C%E5%85%A8%E4%B8%8D%E5%90%8C%E7%9A%84/</link><pubDate>Thu, 27 Nov 2025 13:55:11 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251127-%E4%BA%BA%E8%84%91%E7%9A%84%E8%AE%B0%E5%BF%86%E5%92%8Cagent%E7%9A%84%E8%AE%B0%E5%BF%86%E6%98%AF%E5%AE%8C%E5%85%A8%E4%B8%8D%E5%90%8C%E7%9A%84/</guid><description>&lt;p&gt;最近在看 Agent 记忆的一些设计，调研了4个流行的框架（MEM0、LangGraph、ZeP、ADK）之后，我发现这些框架在记忆部分其实都比较雷同——无论是短期记忆还是长期记忆，本质上都是引入一些外部知识，或者增加一个数据存储层。&lt;/p&gt;
&lt;p&gt;短期记忆一般指当前会话中出现的消息、临时变量和当前状态，它只在当前运行的线程或 session 内有效。&lt;/p&gt;
&lt;p&gt;长期记忆则是经过 LLM 提炼后的一些事实、事件或语义关系，是更持久的信息，对未来其他会话也可见。&lt;/p&gt;
&lt;p&gt;在这个过程中，我比较关注的是短期记忆如何转化为长期记忆。结果发现，最后一步仍然需要依赖大模型来做转换。也就是说，只要明确定义好长期记忆和短期记忆的结构，就可以在对话中实现这种转化。&lt;/p&gt;
&lt;p&gt;之后我又去调研了一下人脑的记忆机制，发现 Agent 的记忆和人脑记忆其实是完全不同的。Agent 的记忆只能说强行模仿人类记忆的分类方式，分为短期和长期，但只是套了个壳子，内部运行机制完全不一样。人脑处理记忆是一个极其复杂的生物学过程，记忆的载体是神经元和突触之间的连接。&lt;/p&gt;
&lt;p&gt;如果人类是唯一有智能的生物，那么 AIGC的路还远着呢！&lt;/p&gt;
&lt;h2 id="一记忆的形成和存储"&gt;一、记忆的形成和存储&lt;/h2&gt;
&lt;p&gt;记忆的形成和存储大致可以分为三个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过编码初步获取信息
编码是记忆形成的第一步，指将外界的感觉信息（视觉、听觉、触觉等）转化为大脑可以处理和存储的神经表征。这个过程是高度选择性的，并不是所有进入感官的信息都会被编码。注意力在其中起到关键作用，它决定了哪些信息能优先进入工作记忆或短期记忆。比如在咖啡馆，你能专注于和朋友的对话，而忽略周围的背景噪音。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;编码的深度和质量会直接影响记忆的强度和持久性。深层次的理解和与已有知识的联系，比机械重复更能促进长期记忆的形成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过巩固来强化记忆
巩固是指新形成的不稳定记忆痕迹逐渐转变为稳定、持久的长期记忆的过程。它分为两个层面：突触巩固和系统巩固。突触巩固发生在学习后的几分钟到几小时内，主要涉及突触连接的局部生化改变，比如长时程增强（LTP）的诱导和维持。系统巩固则更缓慢，可能持续数周到数年，涉及记忆在不同脑区之间的重新组织和转移。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分布式按功能存储记忆
存储是指记忆信息在大脑中被长期保持的过程。记忆并非存储在单一位置，而是分布式地存储于由大量神经元相互连接构成的复杂神经回路中，其核心是突触结构的改变。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，对一个朋友的记忆，可能包括面孔（存储在颞叶的视觉皮层）、名字（存储在语言相关区域）、声音（存储在听觉皮层）以及情感（存储在杏仁核等边缘系统结构）等多个组成部分，它们通过神经连接整合在一起。&lt;/p&gt;
&lt;h2 id="二短期记忆和长期记忆"&gt;二、短期记忆和长期记忆&lt;/h2&gt;
&lt;h3 id="短期记忆"&gt;短期记忆&lt;/h3&gt;
&lt;p&gt;短期记忆是指信息在大脑中保持几秒到一分钟左右的记忆系统。它的容量非常有限，通常认为只能同时存储几个信息单元（如数字、字母等）。短期记忆容量小、持续时间短，容易受干扰，主要作为信息处理的临时工作台，用于暂时保持和操作信息，指导当前的决策和行为。&lt;/p&gt;
&lt;p&gt;比如拨电话时，你会短暂记住一串号码，打完就忘。&lt;/p&gt;
&lt;p&gt;工作记忆是对短期记忆的拓展，它不仅包括信息的暂时存储，还包括对信息的加工和操作，比如心算或逻辑推理。&lt;/p&gt;
&lt;h3 id="长期记忆"&gt;长期记忆&lt;/h3&gt;
&lt;p&gt;长期记忆是指信息在大脑中保持数小时、数天、数年甚至终生的记忆系统。它的容量几乎是无限的，相对稳定，不易受干扰。长期记忆的形成需要将短期记忆中不稳定的神经活动模式转化为持久的、结构性的改变，这个过程就是巩固。&lt;/p&gt;
&lt;p&gt;长期记忆可以分为外显记忆和内隐记忆。外显记忆也叫陈述性记忆，包括对个人经历和事件的情景记忆，以及对事实、概念等知识的语义记忆。内隐记忆则包括程序性记忆（如技能和习惯）、启动效应等。这些不同类型的长期记忆依赖于不同的脑区网络。&lt;/p&gt;
&lt;h3 id="短期记忆是如何转化为长期记忆的"&gt;短期记忆是如何转化为长期记忆的？&lt;/h3&gt;
&lt;p&gt;这个问题本身可能就不太准确，因为长期记忆不一定是短期记忆直接“转化”来的，更准确的说法是长期记忆的巩固。&lt;/p&gt;
&lt;p&gt;2017年MIT的研究表明，在学习事件发生时，记忆痕迹同时在海马体和大脑皮层的长期存储位置形成。但在早期，皮层中的记忆痕迹处于沉默状态，无法被主动提取。只有当这些痕迹逐渐成熟后，才能独立于海马体被提取。这说明记忆巩固不是简单的信息转移，而是海马体和皮层并行处理、相互作用的结果。&lt;/p&gt;
&lt;p&gt;传统的记忆巩固模型认为，新记忆最初依赖于海马体编码和短期存储，然后通过系统巩固逐渐转移到大脑皮层进行长期存储。&lt;/p&gt;
&lt;p&gt;除了海马体，睡眠（特别是慢波睡眠）在记忆巩固中也扮演着重要角色，它通过“重放”白天的学习经历来加强和稳定记忆痕迹。&lt;/p&gt;
&lt;h2 id="agent-记忆借鉴人类记忆的部分"&gt;Agent 记忆借鉴人类记忆的部分&lt;/h2&gt;
&lt;p&gt;那么，Agent 记忆设计到底借鉴了人脑记忆的哪些部分？&lt;/p&gt;
&lt;p&gt;其实主要就是分类方式。Agent 也引入了外显记忆和内隐记忆的概念：外显记忆包括情景记忆和语义记忆，内隐记忆包括程序性记忆、启动效应等。&lt;/p&gt;
&lt;p&gt;情景记忆（Episodic Memory）就是记下某一次具体经历。比如“昨天下午在星巴克和王老师一起喝了杯拿铁”，这个记忆里包含了时间、地点、人物和当时的感受，主要解决When Where Who 这样的问题。&lt;/p&gt;
&lt;p&gt;语义记忆（Semantic Memory）则是关于事实的知识。比如“拿铁是咖啡和牛奶混合的饮料”，这个知识不依赖于某次具体经历，而是作为一个客观事实存在。它回答的是What的问题。这种记忆通常是从多次类似经历中慢慢提炼出来的。&lt;/p&gt;
&lt;p&gt;程序性记忆（Procedural Memory）是关于“怎么做”的记忆。比如你知道怎么冲泡一杯拿铁——怎么操作咖啡机，怎么打奶泡。这种记忆需要反复练习才能形成，但一旦学会了就很难忘记，就像骑自行车一样。它解决How的问题。&lt;/p&gt;
&lt;p&gt;有意思的是，当我们想到“拿铁”这个词的时候，这三种记忆往往会同时被激活：我们知道它是什么（语义记忆），可能想起某次喝拿铁的经历（情景记忆），还知道怎么制作它（程序性记忆）。它们共同构成了我们对一个事物的完整认识。&lt;/p&gt;
&lt;p&gt;我还做了一个思维导图，可以从文件里下载查看。&lt;/p&gt;</description></item><item><title>2025-11-18 Lilian Weng 202510访谈启发_学会趋难避易才能真成长</title><link>https://huizhixu.github.io/chs/life/20251118-lilian-weng-202510%E8%AE%BF%E8%B0%88%E5%90%AF%E5%8F%91%E5%AD%A6%E4%BC%9A%E8%B6%8B%E9%9A%BE%E9%81%BF%E6%98%93%E6%89%8D%E8%83%BD%E7%9C%9F%E6%88%90%E9%95%BF/</link><pubDate>Tue, 18 Nov 2025 14:11:34 +0000</pubDate><guid>https://huizhixu.github.io/chs/life/20251118-lilian-weng-202510%E8%AE%BF%E8%B0%88%E5%90%AF%E5%8F%91%E5%AD%A6%E4%BC%9A%E8%B6%8B%E9%9A%BE%E9%81%BF%E6%98%93%E6%89%8D%E8%83%BD%E7%9C%9F%E6%88%90%E9%95%BF/</guid><description>&lt;p&gt;看了翁莉今年十月的访谈，我发现她真的是一个认知水平很高的人。她的做法，跟我最近在看的《认知觉醒》里提到的方法非常像。我记录了三段对我启发最大的内容。&lt;/p&gt;
&lt;p&gt;首先，主持人问她：“你会用ChatGPT帮你总结论文吗？”她沉默了一下，表示自己不用。她说：&lt;/p&gt;
&lt;p&gt;她不让AI代替她思考和做决策。只有做难的事情，人才能成长。&lt;/p&gt;
&lt;p&gt;这里涉及到《认知觉醒》里面的三个底层原理。&lt;/p&gt;
&lt;p&gt;一是人的天性是避难趋易，克服这种天性就是成长。&lt;/p&gt;
&lt;p&gt;用ChatGPT总结论文多轻松啊，各位搞AI的谁还没有用AI总结过论文呢？我自己去年也用过小绿虫和元宝的早期版本。但是翁莉的习惯是”趋难避易“，这是反人性的——而反人性的事，是真正获益的。 今年我也开始自己一篇篇啃论文了，速度虽然慢，但效果非常好。如果一直依赖AI总结，等于把思考的能力让渡给了AI，自己这方面得不到锻炼，也就很难有大的进步。&lt;/p&gt;
&lt;p&gt;二是对时间的认知。 聪明的人能预估做一件事情大概要花多长时间。很多人没有这个概念，他们不知道做一件事情有多难。&lt;/p&gt;
&lt;p&gt;预估时间为什么重要？首先，每个人的时间都是有限的，预估能帮我们更好地分配时间。其次，对时间没概念，在生活中容易引发矛盾。比如分配任务时，过于乐观估计下属要花的时间，导致完成不了；或是低估伴侣做家务要用的时间，让伴侣觉得委屈。那怎么培养时间感知？只有靠实践，从一次次做事中积累经验。&lt;/p&gt;
&lt;p&gt;三是对任务的安排：先做什么样的任务。&lt;/p&gt;
&lt;p&gt;她说：&lt;/p&gt;
&lt;p&gt;我有一次意识到自己和领导的区别：面对一个很难、不知道要花多久的任务，和一个简单、一上午就能完成的任务，他坚持把简单的往后推，先做难的。那个时候刚好读了《认知觉醒》，我才发现，自己还是太“趋易避难”了，总想先搞定简单的。以后碰到这种情况要优先做难而重要的事情。&lt;/p&gt;
&lt;p&gt;其次，主持人问她遇到不懂的代码怎么处理。 她的回答是：&lt;/p&gt;
&lt;p&gt;这其实就是学习能力的一种体现。通过提问来学习，效果非常明显。我记得高中时有几本数学选修内容，老师就让我们先自己看书，然后提问，再由懂的同学来回答。这种方式对我影响很深，提问和回答能高效地处理信息，尤其是在自己不太明白的地方。这种在“不懂/不太顺畅”之处下功夫的学习方式，正好和《认知觉醒》里提到的“在舒适区边缘学习”是一个道理。&lt;/p&gt;
&lt;p&gt;最后，主持人问她，”我们的观众里，对于那些考虑成为创始人的人，或者那些非技术背景但想进入 AI 领域的人，你有什么建议？“ 她回复说:&lt;/p&gt;
&lt;p&gt;她这段话背后，其实是一个 “认知——行动——改变” 的完整逻辑。比如说，我知道读论文重要，也真的去读了，但紧靠阅读带来的收获是很有限的。必须得去实践、去做实验，才能更深刻地理解论文里的方法。只有持续这么做，才有可能带来真正的改变。&lt;/p&gt;
&lt;p&gt;同样地，坚持尝试不同的AI工具，也一定能给生活带来变化。 我在小红书上就看到不少人，在这个过程中发现了可以用AI优化的环节，或者找到了还没被满足的小众需求，然后就开始创业了。如果我只读论文却不去复现和实践，就永远无法获得最宝贵的东西——也就是实践经验。&lt;/p&gt;</description></item><item><title>2025-11-09 不起眼的凯尔卡门——读《人类群星闪耀时》</title><link>https://huizhixu.github.io/chs/life/20251109-%E4%B8%8D%E8%B5%B7%E7%9C%BC%E7%9A%84%E5%87%AF%E5%B0%94%E5%8D%A1%E9%97%A8%E8%AF%BB%E4%BA%BA%E7%B1%BB%E7%BE%A4%E6%98%9F%E9%97%AA%E8%80%80%E6%97%B6/</link><pubDate>Sun, 09 Nov 2025 14:11:36 +0000</pubDate><guid>https://huizhixu.github.io/chs/life/20251109-%E4%B8%8D%E8%B5%B7%E7%9C%BC%E7%9A%84%E5%87%AF%E5%B0%94%E5%8D%A1%E9%97%A8%E8%AF%BB%E4%BA%BA%E7%B1%BB%E7%BE%A4%E6%98%9F%E9%97%AA%E8%80%80%E6%97%B6/</guid><description>&lt;p&gt;最近读了茨威格大名鼎鼎的《人类群星闪耀时》，里面的故事真是个个精彩。
我超级喜欢《拜占庭的陷落》这个故事，读了好几遍。这个故事讲的是奥斯曼帝国攻打君士坦丁堡的故事。&lt;/p&gt;
&lt;p&gt;背景是这样的，拜占庭帝国就是东罗马帝国，君士坦丁堡是拜占庭帝国的首都，这时候已经是帝国余晖了。而奥斯曼帝国，是一个新兴的、强大的伊斯兰帝国，由苏丹穆罕默德二世率领。&lt;/p&gt;
&lt;p&gt;起初，命运站在奥斯曼这边，拜占庭的防线已经快顶不住了，城市眼看就要被攻破。就在这时，一个意想不到的转机出现了，几艘热那亚的船只成功冲破封锁，赶来支援。这支援军让几乎绝望的守城将士重新燃起了希望。
谁知情况很快又变了。海上突然刮起了大风，奥斯曼舰队借着风势，迅速向城防发起猛攻。热那亚的船在风浪中处于劣势，完全抵挡不住。城墙在舰队的攻击下岌岌可危，眼看就要失守。
然而，就在这最危急的时刻，风又毫无征兆地停了。失去风力的奥斯曼舰队一下子动弹不得，攻势被迫中断。拜占庭人竟然又一次从绝境中暂时解脱，获得了喘息的机会。
可他们还没来得及庆幸，另一个谁也没想到的意外发生了——一扇平时不显眼的小门（凯尔卡门），竟然没有被关好。奥斯曼士兵从这个小小的疏忽中潜入城内，让整座城市陷落。&lt;/p&gt;
&lt;p&gt;读这个故事时，我完全带入拜占庭人，心情完全被情节牵动着，刚看到些许希望，下一分钟就又陷入紧张。茨威格的文字读起来很顺畅，他把每一个小变化如何影响大局都写得很生动，让人忍不住一直往下读。&lt;/p&gt;
&lt;p&gt;读完这个故事后，我还有另外一层思考：当我回顾过去的人生，我发现我很难准确判断自己正处在命运的哪个节点。&lt;/p&gt;
&lt;p&gt;十八岁时以为考上大学就OK了，结果读完还是很迷茫，人生到底要朝哪一个方向走呢？二十二岁带着这份迷茫出国，以为换个环境就能找到答案，但殊不知正是低谷的开始。二十六岁时以为抓住了一个光鲜的行业，人生便可高枕无忧，谁知几年后整个行业会面临震荡。&lt;/p&gt;
&lt;p&gt;当时的我，和故事里的拜占庭人一样，身处其中而浑然不觉。他们不知道自己究竟是处在援军抵达前最黑暗的黎明，还是灭亡前夜的安全假象。我也无法预知，此刻的挫折是否是希望到来的前兆，此刻的顺境又是否藏着尚未察觉的隐患呢？
我们如何保持清醒，胜不骄败不馁呢？
只能时时刻刻提醒自己，并且转变角度角度看待问题。从历史视角看待人生的此刻，心胸就会变得很宽广，内核会更稳，就会觉得没有什么大的事情，因为在历史层面其实都是小的事情。&lt;/p&gt;</description></item><item><title>2025-11-05 从零构建大模型—针对分类的微调</title><link>https://huizhixu.github.io/chs/know_how/20251105%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%92%88%E5%AF%B9%E5%88%86%E7%B1%BB%E7%9A%84%E5%BE%AE%E8%B0%83/</link><pubDate>Wed, 05 Nov 2025 13:54:46 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251105%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%92%88%E5%AF%B9%E5%88%86%E7%B1%BB%E7%9A%84%E5%BE%AE%E8%B0%83/</guid><description>&lt;p&gt;这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。&lt;/p&gt;
&lt;p&gt;微调通常可分为以下三个阶段：&lt;/p&gt;
&lt;p&gt;第一阶段：数据准备&lt;/p&gt;
&lt;p&gt;包括下载数据集、进行数据预处理以及构建数据加载器。&lt;/p&gt;
&lt;p&gt;第二阶段：模型准备&lt;/p&gt;
&lt;p&gt;涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。&lt;/p&gt;
&lt;p&gt;第三阶段：模型微调与部署&lt;/p&gt;
&lt;p&gt;包括执行模型微调、评估微调效果，以及在新数据上进行推理。&lt;/p&gt;
&lt;p&gt;在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&amp;quot;垃圾消息&amp;quot;或&amp;quot;非垃圾消息&amp;quot;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。&lt;/p&gt;
&lt;h2 id="第一阶段准备数据"&gt;第一阶段：准备数据&lt;/h2&gt;
&lt;h3 id="1-下载数据"&gt;1. 下载数据&lt;/h3&gt;
&lt;p&gt;网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。&lt;/p&gt;
&lt;h3 id="2-数据集预处理"&gt;2. 数据集预处理&lt;/h3&gt;
&lt;p&gt;预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; uu &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; encode
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; torch.utils.data &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; Dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; tiktoken
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; pandas &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;SpamDataset&lt;/span&gt;(Dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, csv_file, tokenizer, max_len&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;200&lt;/span&gt;,pad_token_id&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50256&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;csv_file &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; csv_file
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;read_csv(csv_file, sep&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#39;&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;\\&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;t&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;[tokenizer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encode(text) &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; text &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; max_len
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processed_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; encoded &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 截断到最大长度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; truncated &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; encoded[:&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 填充到最大长度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; padded &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; truncated &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; [pad_token_id] &lt;span style="color:#ff79c6"&gt;*&lt;/span&gt; (&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(truncated))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processed_texts&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(padded)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; processed_texts
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__getitem__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, index):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts[index]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; label &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;iloc[index][&lt;span style="color:#f1fa8c"&gt;&amp;#39;label&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; (torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tensor(encoded, dtype&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;long), torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tensor(label, dtype&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;long))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__len__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="3-创建数据加载器"&gt;3. 创建数据加载器&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;train_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(train_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;val_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(val_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;test_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(test_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="第二阶段修改模型"&gt;第二阶段：修改模型&lt;/h2&gt;
&lt;h3 id="1-模型初始化"&gt;1. 模型初始化&lt;/h3&gt;
&lt;p&gt;GPTModel是在《徒手组装GPT》章节中构建好的类。&lt;/p&gt;</description></item><item><title>2025-11-03 读 AutoGen 论文</title><link>https://huizhixu.github.io/chs/know_how/20251103%E8%AF%BB-autogen-%E8%AE%BA%E6%96%87/</link><pubDate>Mon, 03 Nov 2025 13:55:08 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251103%E8%AF%BB-autogen-%E8%AE%BA%E6%96%87/</guid><description>&lt;p&gt;最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。&lt;/p&gt;
&lt;p&gt;最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。&lt;/p&gt;
&lt;h2 id="1-什么是autogen"&gt;1. 什么是AutoGen？&lt;/h2&gt;
&lt;p&gt;简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。&lt;/p&gt;
&lt;h3 id="11-核心需求"&gt;1.1 核心需求&lt;/h3&gt;
&lt;p&gt;AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：&lt;/p&gt;
&lt;p&gt;1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？&lt;/p&gt;
&lt;p&gt;2.如何开发一个能够适应多种智能体对话模式的统一接口？&lt;/p&gt;
&lt;h3 id="12-技术可行性"&gt;1.2 技术可行性&lt;/h3&gt;
&lt;p&gt;AutoGen的提出基于三个关键的技术可行性因素。&lt;/p&gt;
&lt;p&gt;首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。&lt;/p&gt;
&lt;p&gt;其次，智能体能够提供或者接收推理、观察、评价和验证。&lt;/p&gt;
&lt;p&gt;最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。&lt;/p&gt;
&lt;h2 id="2-核心概念"&gt;2. 核心概念&lt;/h2&gt;
&lt;h3 id="21-可定制化智能体customizable-and-conversable-agents"&gt;2.1 可定制化智能体（Customizable and conversable agents）&lt;/h3&gt;
&lt;p&gt;AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。&lt;/p&gt;
&lt;h3 id="22-对话编程范式conversation-programming"&gt;2.2 对话编程范式（Conversation programming）&lt;/h3&gt;
&lt;p&gt;AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：&lt;/p&gt;
&lt;p&gt;1.定义具有特定能力和角色的可对话智能体集合&lt;/p&gt;
&lt;p&gt;2.通过以对话为中心的计算和控制来编程智能体间的交互行为&lt;/p&gt;
&lt;h2 id="3-智能体能力体系"&gt;3. 智能体能力体系&lt;/h2&gt;
&lt;h3 id="31-三大能力来源"&gt;3.1 三大能力来源&lt;/h3&gt;
&lt;p&gt;AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。&lt;/p&gt;
&lt;h3 id="311-大型语言模型能力"&gt;3.1.1 大型语言模型能力&lt;/h3&gt;
&lt;p&gt;基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。&lt;/p&gt;
&lt;h3 id="312-人类参与能力"&gt;3.1.2 人类参与能力&lt;/h3&gt;
&lt;p&gt;AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。&lt;/p&gt;
&lt;h3 id="313-工具执行能力"&gt;3.1.3 工具执行能力&lt;/h3&gt;
&lt;p&gt;工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。&lt;/p&gt;
&lt;h3 id="32-智能体分类体系"&gt;3.2 智能体分类体系&lt;/h3&gt;
&lt;p&gt;AutoGen建立了完整的智能体分类体系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具&lt;/li&gt;
&lt;li&gt;AssistantAgent：ConversableAgent的子类，专门用于AI助手功能&lt;/li&gt;
&lt;li&gt;UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具&lt;/li&gt;
&lt;li&gt;GroupChatManager：用于管理群组对话的专门组件&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="4-对话编程机制"&gt;4. 对话编程机制&lt;/h2&gt;
&lt;h3 id="41-编程模式"&gt;4.1 编程模式&lt;/h3&gt;
&lt;p&gt;对话编程范式需要考虑两个关键维度：&lt;/p&gt;
&lt;p&gt;1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动&lt;/p&gt;
&lt;p&gt;2.控制流（Control Flow）：计算发生的条件&lt;/p&gt;
&lt;h3 id="42-自动回复机制"&gt;4.2 自动回复机制&lt;/h3&gt;
&lt;p&gt;AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。&lt;/p&gt;
&lt;p&gt;智能体自动回复机制是AutoGen的核心特性：&lt;/p&gt;</description></item><item><title>2025-11-01 从零构建大模型—通过微调遵循人类指令</title><link>https://huizhixu.github.io/chs/know_how/20251101-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E5%BE%AE%E8%B0%83%E9%81%B5%E5%BE%AA%E4%BA%BA%E7%B1%BB%E6%8C%87%E4%BB%A4/</link><pubDate>Sat, 01 Nov 2025 13:55:35 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251101-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E5%BE%AE%E8%B0%83%E9%81%B5%E5%BE%AA%E4%BA%BA%E7%B1%BB%E6%8C%87%E4%BB%A4/</guid><description>&lt;p&gt;终于来到这本书的最后一章啦。&lt;/p&gt;
&lt;p&gt;这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）&lt;/p&gt;
&lt;p&gt;当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。&lt;/p&gt;
&lt;p&gt;接下来是本章的内容：&lt;/p&gt;
&lt;p&gt;预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。
但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。&lt;/p&gt;
&lt;p&gt;这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。&lt;/p&gt;
&lt;p&gt;第一阶段：数据准备&lt;/p&gt;
&lt;p&gt;包括下载数据集、进行数据预处理以及构建数据加载器。&lt;/p&gt;
&lt;p&gt;第二阶段：模型微调&lt;/p&gt;
&lt;p&gt;包括加载预训练大语言模型、执行指令微调以及监控模型损失。&lt;/p&gt;
&lt;p&gt;第三阶段：评估大语言模型&lt;/p&gt;
&lt;p&gt;包括提取模型回复、进行量化评估以及对生成内容打分。&lt;/p&gt;
&lt;h2 id="第一阶段数据准备"&gt;第一阶段：数据准备&lt;/h2&gt;
&lt;h3 id="1-下载数据"&gt;1. 下载数据&lt;/h3&gt;
&lt;p&gt;可以使用网上已有的数据集：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;url &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;指令微调所需的数据是“输入-输出”对。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {&lt;span style="color:#f1fa8c"&gt;&amp;#39;instruction&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#39;Identify the correct spelling of the following word.&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;input&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#39;Ocassion&amp;#39;&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#34;The correct spelling is &amp;#39;Occasion.&amp;#39;&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Below &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt; an instruction that describe a task&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt; Write a response that appropriately
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; complete the request&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Instruction:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Identify the correct spelling of the following word&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Input:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Ocassion
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The correct spelling &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;Occasion&amp;#39;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-数据集预处理"&gt;2. 数据集预处理&lt;/h3&gt;
&lt;p&gt;数据下载后，需要将样本填充至相同长度，并进行批次处理。&lt;/p&gt;</description></item><item><title>2025-10-28 MiniMax Agent（M2）有惊喜也有失望</title><link>https://huizhixu.github.io/chs/know_how/20251028-minimax-agentm2%E6%9C%89%E6%83%8A%E5%96%9C%E4%B9%9F%E6%9C%89%E5%A4%B1%E6%9C%9B/</link><pubDate>Tue, 28 Oct 2025 13:54:09 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251028-minimax-agentm2%E6%9C%89%E6%83%8A%E5%96%9C%E4%B9%9F%E6%9C%89%E5%A4%B1%E6%9C%9B/</guid><description>&lt;p&gt;MiniMax发布了M2模型，同时限免了Agent。他们Agent之前的Slogan是“Code is cheap, show me the requirement”，擅长的任务包括代码开发、PPT生成等功能。它据说是“国内最好用的Agent”。&lt;/p&gt;
&lt;p&gt;我之前想开会员，但看到最基础的定价一个月39刀，比Codex和Cursor还贵，就放弃了。不过最近MiniMax在M2发布期间限时免费，嘿嘿，所以我又回来用了。&lt;/p&gt;
&lt;h2 id="总结"&gt;总结&lt;/h2&gt;
&lt;p&gt;MiniMax Agent 确实具备完成任务的能力。模型方面既可以选择免费的轻量版本，也可以选用旗舰模型。它的一个显著优点是，在执行任务前会先进行判断——如果任务本身可以由更简单的模型完成，就无需创建复杂计划或委托给其他代理。&lt;/p&gt;
&lt;p&gt;与其他智能体一样，MiniMax 在执行任务时支持实时查看进度，随时调试，也支持下载代码到本地运行，甚至还提供版本回滚功能。&lt;/p&gt;
&lt;p&gt;我对整体功能和完成度是比较满意的。&lt;/p&gt;
&lt;p&gt;不过，它也有一些令人失望的地方。&lt;/p&gt;
&lt;p&gt;对于编码任务，我们为什么不用 Cursor、Codex 或 Trae 这类专门工具呢？在网页上编码和调试非常不便，例如第一个“电子衣橱”任务，反复运行多次，每次都要重新下载代码、安装环境、运行程序，过程相当繁琐。如果能直接在 IDE 中修改，体验会好很多。而在其他任务类型上——比如生成绘本、数据可视化或制作 PPT——这些智能体之间的差距又有多大呢？是否足以让我坚定选择 A 而非 B？目前看来，我并不那么确定，因为它们在表现上似乎相差不大。&lt;/p&gt;
&lt;p&gt;MiniMax 有一个比较有意思的功能是 Gallery 中的“remix”，我可以基于他人已有的代码进行修改和呈现。但问题是，有多少人会和我有同样的需求呢？&lt;/p&gt;
&lt;p&gt;我做了三个测试。&lt;/p&gt;
&lt;h2 id="第一个任务电子衣橱"&gt;第一个任务：电子衣橱&lt;/h2&gt;
&lt;p&gt;第一个任务非常难。最近换季了，我想做一个电子衣橱，用来管理穿衣和搭配。市面上的电子衣橱产品都限制上传张数，不好用。所以我想在本地自己做一个纯自用的产品demo。&lt;/p&gt;
&lt;p&gt;我写了一份产品文档，然后它开始运行。&lt;/p&gt;
&lt;p&gt;这是它的呈现。它的第一步是规划和确认。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/59900dc5.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这里不得不提一个很有用的功能——revert。因为我确认的时候打错了字，小的typo会造成歧义，所以我用这个 restore checkpoint 功能直接回到了“需要确认”这一步，然后输入正确的即可。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/446c18ff.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;任务完成后，它交付给我一个项目代码包，包含各种详细文档和启动代码说明。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/fccee854.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我按照启动代码说明在本地启动，中间没有出现错误。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/ef0707fe.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这是代码启动后的界面，看起来还不错。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/695e32e5.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我点击“添加物品”和“记录穿搭”，里面是空白的，这些功能还没有实现。&lt;/p&gt;
&lt;p&gt;于是我进行了一轮反馈：“添加物品和记录穿搭这两个页面都是空白的，请帮我实现这两页，让我可以真正使用。”然后它开始修复bug。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/85db979f.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;重新下载它交付的代码，运行起来没有问题。点击“添加物品”，这次页面有内容了。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/74a91da4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我填入了一些信息，发现一个bug导致无法进入下一步，于是进行了第三轮对话，要求修复这个问题。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/29b2808b.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;它调试时的做法还是很清晰的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/190c32b2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这里我发现每次下载的文件夹都叫 package.zip，感觉有覆盖的风险。&lt;/p&gt;
&lt;p&gt;再次打开，一切顺利，现在功能有了。但添加物品失败，我又去反馈了，第四轮。修复好后，分类又没了。再次反馈，第五轮。这样来来回回多次之后，还是添加不了物品。&lt;/p&gt;
&lt;h2 id="第二个任务把河童做成绘本"&gt;第二个任务：把《河童》做成绘本&lt;/h2&gt;
&lt;p&gt;第二个测试是把将杨千嬅《河童》做成绘本的prompt直接给MiniMax。&lt;/p&gt;
&lt;p&gt;它先规划步骤，让用户确认。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/a8351589.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;在程序运行的过程中，我一张一张查看生成的图片，比较震惊的是发现其中一张与 OK Computer 生成的画面非常相似（这个画面对应的歌词是“令这世界别冻”）。&lt;/p&gt;
&lt;p&gt;这是MiniMax Agent生成的：&lt;/p&gt;</description></item><item><title>2025-10-17 月之暗面的OK Computer还可以更好</title><link>https://huizhixu.github.io/chs/know_how/20251017%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2%E7%9A%84ok-computer%E8%BF%98%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%A5%BD/</link><pubDate>Fri, 17 Oct 2025 12:50:41 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251017%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2%E7%9A%84ok-computer%E8%BF%98%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%A5%BD/</guid><description>&lt;p&gt;体验了一下Moonshot新推出的OK computer，这个产品最大的特点是端到端训练，model as agent，在训练时就已经把agent的能力融入到模型里面了。&lt;/p&gt;
&lt;p&gt;OK Computer说自己能够独立完成网站开发、数据分析、图像视频生成及高质量PPT制作。它的定位为“你专属的AI产品与工程团队“，但是交付的形式是产品本身，而不是像TRAE一样交付的是代码。&lt;/p&gt;
&lt;p&gt;我给它的第一个任务是做一个PPT，因为8月份我用过kimi里面的PPT助手，想对比看一下这次的提升。&lt;/p&gt;
&lt;p&gt;8月份那次制作PPT，要自己选择模版、上传文档，而kimi只能大概做一个基础性的框架，内容很少，图片和表格都需要手动补充。&lt;/p&gt;
&lt;p&gt;这一次不需要选择模版，直接上传文档，我给的指令很简单，是“帮我根据文档进行生成PPT”，就开始了。最终生成的6页幻灯片，风格令人惊艳，知识点拆解也重点突出。整体效果比起8月份那次，真的进步太多。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/36797f09.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/e8df851b.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我给的第二个任务是让它把一段文本做成绘本。&lt;/p&gt;
&lt;p&gt;官网有一个例子是把以前的课文《口技》做成绘本，有图像，也有环境音，感觉很生动。&lt;/p&gt;
&lt;p&gt;我仿照官网案例，尝试将杨千嬅的歌曲《河童》制成一个可交互的水彩风网页绘本。《河童》这首歌有画面，有意境，很适合AI创作。&lt;/p&gt;
&lt;p&gt;我用的提示词是官网的《口技》的例子修改而来。&lt;/p&gt;
&lt;p&gt;虽然这是个网页版agent，但是有一个可视化界面，左边是任务的规划和完成情况，会先创立一个任务列表，然后一项一项的执行，执行完打勾。右边是实时界面，可以看到这个过程生成的所有的文档、图片和音频等。&lt;/p&gt;
&lt;p&gt;任务列表：&lt;/p&gt;
&lt;p&gt;执行过程中中的所有文件都能浏览，最后也可以打包下载。&lt;/p&gt;
&lt;p&gt;最终出来的结果是这样的，看到时我感觉超出了预期。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/c43d9970.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;总的画面是这样的，还是很美的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/af7fa845.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;第一幕还蛮好的，有画面，有互动，有音乐。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/9e5ba6eb.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;但是接着问题就出现了，点击“下一幕”后，URL显示已进入第二个页面，但画面仍停留在第一个。反馈修复了之后也依然不行。并且发现额度已经用完了。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/1785576d.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;OK Computer展现的能力是强大的。生成了详细的任务清单，并逐步执行，最终输出了包括13张插图、13段音效及完整网页代码在内的成品，中间的步骤我看了，它生成的交互文档和专业设计文档都十分全面，任务执行也精准到位。&lt;/p&gt;
&lt;p&gt;唯一遗憾的是，即便遵循了官方优秀案例，最终成品仍存在影响使用的前端Bug，距离完美仅一步之遥。这一步之遥让我纠结这会员到底开还是不开啊。&lt;/p&gt;</description></item><item><title>2025-10-10 算法工程师为什么一直对自己不满意</title><link>https://huizhixu.github.io/chs/life/20251010%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%80%E7%9B%B4%E5%AF%B9%E8%87%AA%E5%B7%B1%E4%B8%8D%E6%BB%A1%E6%84%8F/</link><pubDate>Fri, 10 Oct 2025 12:50:39 +0000</pubDate><guid>https://huizhixu.github.io/chs/life/20251010%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%80%E7%9B%B4%E5%AF%B9%E8%87%AA%E5%B7%B1%E4%B8%8D%E6%BB%A1%E6%84%8F/</guid><description>&lt;p&gt;我注意到我身边的算法朋友和同事，包括我自己，我们这一个群体，普遍容易对自己不满意，时常陷入焦虑。
这真的不完全是个人性格的问题，而是一种结构性焦虑。&lt;/p&gt;
&lt;p&gt;为什么做算法的人特别容易焦虑？&lt;/p&gt;
&lt;p&gt;首先，这个岗位的评价标准很单一。&lt;/p&gt;
&lt;p&gt;研究型算法工程师的价值往往和论文专利紧密挂钩，业务型算法工程师的价值被强行与业务指标绑定。算法工作其实很单调：看论文，复现思路，计算指标，有提高的话这个月就稳了，没有就会焦虑。有时候一番辛苦操作下来，准备率不升反降，但是业务指标又迫在眉睫，于是就出现失眠、灰心丧心、精神不振和食欲不佳等症状。&lt;/p&gt;
&lt;p&gt;其次，这个领域的知识半衰期极短。&lt;/p&gt;
&lt;p&gt;大家都有体会，过去学过的算法，很多都没有在用了。&lt;/p&gt;
&lt;p&gt;大模型时代来临，新知识层出不穷，很多人都吐槽”学不动“了。因为学不完，真的学不完，而且还有学完就过时的风险。&lt;/p&gt;
&lt;p&gt;第三，是天才叙事和社交媒体的影响。&lt;/p&gt;
&lt;p&gt;算法圈有很多大佬和青年才俊，看到新闻报道，看到别人更年轻，有更好的学历，更多的paper，更大的影响力，更好的位置，无形之中就会产生压力，觉得自己太菜。但是媒体所呈现的，往往只是那顶尖的 5%，背后常伴随着特定目的或传播策略。新闻需要造势，资金需要流向热点，公司也需要宣传——这些因素共同塑造了很多的精英叙事，如果你了解它背后的运行原理，你看到这些新闻就不会有那么大的压力。&lt;/p&gt;
&lt;p&gt;我写这些，并不是为了让大家垂头丧气。恰恰相反，尽管这个领域从业者众多，但是机会依然存在。我不知道这个领域什么时候会迎来寒冬，但是目前来看，未解决的问题还有很多，估计接下来的几年会慢慢给出答案。作为工程师，能够探索这些问题本身就很有意思；如果能伴随一个新兴行业共同成长，更是一种幸运。前几天 Kaparthy 也提到，AI Agent 的发展至少还需要十年。&lt;/p&gt;
&lt;p&gt;很多人一生都在追求更好，包括我，但是从来没有停下来问，对谁更好？按谁的标准？&lt;/p&gt;
&lt;p&gt;不必过度焦虑，我们不一定非要成为前5%，但可以成为那个真正理解问题、踏实解决问题的工程师——这本身，就是一件非常有价值的事。&lt;/p&gt;</description></item><item><title>2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks</title><link>https://huizhixu.github.io/chs/know_how/20251001-%E5%A7%9A%E9%A1%BA%E9%9B%A8%E5%8D%9A%E5%A3%AB%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93-language-agentsbenchmarks-methods-and-frameworks/</link><pubDate>Wed, 01 Oct 2025 14:11:50 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251001-%E5%A7%9A%E9%A1%BA%E9%9B%A8%E5%8D%9A%E5%A3%AB%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93-language-agentsbenchmarks-methods-and-frameworks/</guid><description>&lt;p&gt;不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。&lt;/p&gt;
&lt;p&gt;视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4&lt;/p&gt;
&lt;p&gt;注：文中所有的图都来自上面视频链接，文中不再注明&lt;/p&gt;
&lt;h1 id="概览"&gt;概览&lt;/h1&gt;
&lt;p&gt;Agent：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rule-based agents: manual design 人工写规则&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learning-based agents: trial-and-error 靠试错学习&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Language agents: reasoning to act 先用语言推理，再行动
Environment：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with humans/physical world 与人交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with games/simulation 与游戏交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with the digital world (Internet) 与互联网交互
Challenges:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Accessible methods for general agents&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scalable benchmarks for practical tasks
主要的研究：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 1: Benchmarking agents via digital automation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 2: Building language agents that reason to act&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 3: Principled framework for language agents&lt;/p&gt;</description></item><item><title>2025-09-21 从零构建大模型—文本生成策略</title><link>https://huizhixu.github.io/chs/know_how/20250921%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5/</link><pubDate>Sun, 21 Sep 2025 13:55:34 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250921%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5/</guid><description>&lt;p&gt;在解码的时候，生成的词元是从词汇表的所有词元中选择概率分数最大的那一个，也就是argmax最大的词元id，但是这种形式让大模型失去丰富性，因为多次运行大模型生成的文本是相同的。&lt;/p&gt;
&lt;p&gt;两种技术（温度缩放和Top-k采样）可以用于文本生成的优化。&lt;/p&gt;
&lt;h2 id="温度缩放"&gt;温度缩放&lt;/h2&gt;
&lt;p&gt;用一个从概率分布（这里是大语言模型在每个词元生成步骤为每个词汇条目生成的概率分数）中采样的函数来取代argmax。&lt;/p&gt;
&lt;p&gt;这个概率采样函数Multinomial按照词汇表的概率分数采样下一个词元。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;argmax 永远挑概率最大的那个；&lt;/li&gt;
&lt;li&gt;multinomial 按概率分布随机抽签——大概率事件只是“中签率高”，并非 100 %。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;torch.manual_seed(123)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;next_token_id = torch.multinomial(probas, num_samples=1).item()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(inverse_vocab[next_token_id])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过一个称为温度缩放的概念，可以进一步控制分布和选择过程。温度缩放指的是将logits除以一个大于0的数。温度大于1会导致词元概率更加均匀分布，而小于1的温度将导致更加自信（更尖锐或更陡峭）的分布。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def softmax_with_temperature(logits, temperature):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; scaled_logits = logits / temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return torch.softmax(scaled_logits, dim=0)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用非常小的温度（如0.1）会导致更集中的分布，使得multinomial函数几乎100%选择最可能的词元，接近于argmax函数的行为。温度增大会导致更均匀的分布，使得其他词元更容易被选中。这可以为生成的文本增加更多变化，但也更容易生成无意义的文本。&lt;/p&gt;
&lt;h3 id="设置温度"&gt;设置温度&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;vocab = {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;closer&amp;#34;: 0,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;every&amp;#34;: 1,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;effort&amp;#34;: 2,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;forward&amp;#34;: 3,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;inches&amp;#34;: 4,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;moves&amp;#34;: 5,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;pizza&amp;#34;: 6,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;toward&amp;#34;: 7,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;you&amp;#34;: 8,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;inverse_vocab = {v: k for k, v in vocab.items()}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;next_token_logits = torch.tensor(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def softmax_with_temperature(logits, temperature):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; scaled_logits = logits / temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return torch.softmax(scaled_logits, dim=0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;probas = softmax_with_temperature(next_token_logits, temperature=5)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def print_sampled_tokens(probas):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; torch.manual_seed(123)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sample = [torch.multinomial(probas, num_samples=1).item()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for i in range(1_000)]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sampled_ids = torch.bincount(torch.tensor(sample))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for i, freq in enumerate(sampled_ids):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; print(f&amp;#34;{freq} x {inverse_vocab[i]}&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print_sampled_tokens(probas)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="top-k-采样"&gt;Top K 采样&lt;/h2&gt;
&lt;p&gt;较高的温度值会让下一个词元的概率分布更加均匀，从而产生更加多样化的输出。但是有时候会产生语法不正确或者完全无意义的输出。&lt;/p&gt;</description></item><item><title>2025-09-14 从零构建大模型—在无监督数据上进行预训练</title><link>https://huizhixu.github.io/chs/know_how/20250914%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%97%A0%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E9%A2%84%E8%AE%AD%E7%BB%83/</link><pubDate>Sun, 14 Sep 2025 13:54:05 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250914%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%97%A0%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E9%A2%84%E8%AE%AD%E7%BB%83/</guid><description>&lt;p&gt;这一章主要分为以下三个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评估生成文本的质量&lt;/li&gt;
&lt;li&gt;训练函数&lt;/li&gt;
&lt;li&gt;对大模型进行预训练&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="一前情提要"&gt;一、前情提要&lt;/h1&gt;
&lt;h2 id="文本生成前几章讲过的"&gt;文本生成（前几章讲过的）&lt;/h2&gt;
&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分词器将输入文本转换成一系列词元ID&lt;/li&gt;
&lt;li&gt;模型接收词元ID，并生成相应的logits&lt;/li&gt;
&lt;li&gt;这些logits被转换回词元ID，分词器会将其解码为人类可读的文本
logits是表示词汇表中每个词元的概率分布的向量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;logits 怎么理解：&lt;/p&gt;
&lt;p&gt;logits 是“未归一化”的概率分数向量。经过 softmax 后，logits 变成“概率分布”。&lt;/p&gt;
&lt;p&gt;logits 的用途：&lt;/p&gt;
&lt;p&gt;在推理阶段，取 logits 的 argmax 即可得到每个位置最可能的词元；也可以对 logits 应用温度缩放、Top-K、核采样等技术，再做 multinomial 采样，以平衡多样性与一致性。&lt;/p&gt;
&lt;h2 id="权重参数"&gt;权重参数&lt;/h2&gt;
&lt;p&gt;权重参数指的是在训练过程调整的参数。&lt;/p&gt;
&lt;p&gt;PyTorch允许通过model.parameters()方法直接访问模型的所有可训练参数（包括Weights和Biases）&lt;/p&gt;
&lt;h1 id="二评估文本生成"&gt;二、评估文本生成&lt;/h1&gt;
&lt;h2 id="初始化"&gt;初始化&lt;/h2&gt;
&lt;p&gt;用GPT_CONFIG_124M字典初始化GPTModel类，注意这里只是搭了个框架，随机初始化权重，所以模型生成的文本也是随机生成。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;from gpt2_module.gpt2 import GPTModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;GPT_CONFIG_124M ={
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;vocab_size&amp;#34;:50257,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;context_length&amp;#34;:1024,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;emb_dim&amp;#34;:768,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;n_heads&amp;#34;:12,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;n_layers&amp;#34;:12,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;drop_rate&amp;#34;:0.1,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;qkv_bias&amp;#34;:False
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def generate_text_simple(model, idx, max_new_tokens, context_size):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for _ in range(max_new_tokens):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 将当前文本截断至大模型支持的长度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx_cond = idx[:, -context_size:]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; with torch.no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits = model(idx_cond)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 仅关注最后一个时间步的logits
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits = logits[:, -1, :]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 转换为概率分布
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; probs = torch.softmax(logits, dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 采样下一个token
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx_next = torch.argmax(probs, dim=-1, keepdim=True)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 拼接采样的token
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx = torch.cat((idx, idx_next), dim=1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return idx
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def text_to_token_ids(text, tokenizer):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded = tokenizer.encode(text, allowed_special={&amp;#39;&amp;lt;|endoftext|&amp;gt;&amp;#39;})
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded_tensor = torch.tensor(encoded).unsqueeze(0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return encoded_tensor
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def token_ids_to_text(token_ids, tokenizer):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; flat = token_ids.squeeze(0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return tokenizer.decode(flat.tolist())
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;start_context = &amp;#34;Every effort moves you&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tokenizer = tiktoken.get_encoding(&amp;#34;gpt2&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model = GPTModel(GPT_CONFIG_124M)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;token_ids = generate_text_simple(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model=model,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx=text_to_token_ids(start_context, tokenizer),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_new_tokens=10,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; context_size=GPT_CONFIG_124M[&amp;#34;context_length&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(token_ids_to_text(token_ids, tokenizer))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="交叉熵损失的计算"&gt;交叉熵损失的计算&lt;/h2&gt;
&lt;p&gt;模型训练的目标是增大与正确目标词元ID对应的索引位置的softmax概率，也就是最大化正确词元的可能性。&lt;/p&gt;</description></item><item><title>2025-09-11 Anthropic 做 Multi Agent 系统的工程经验（下）</title><link>https://huizhixu.github.io/chs/know_how/20250911anthropic-%E5%81%9A-multi-agent-%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8B/</link><pubDate>Thu, 11 Sep 2025 12:50:53 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250911anthropic-%E5%81%9A-multi-agent-%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8B/</guid><description>&lt;p&gt;这一篇写Anthropic的智能体评估、生产可靠性和工程挑战。&lt;/p&gt;
&lt;h1 id="智能体评估"&gt;智能体评估&lt;/h1&gt;
&lt;p&gt;如何做智能体评估呢？传统的做法是“给定输入 X，必须走步骤 Y，才能得到正确输出 Z”。但是多智能体不能这样做，因为它没有固定唯一的、可预先写死的解题路径。&lt;/p&gt;
&lt;h2 id="评估什么"&gt;评估什么&lt;/h2&gt;
&lt;p&gt;不要去检查是否走了预设的路径，而要判断是否有合理的过程和正确的结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结果导向：最终答案是否正确、是否满足用户需求。&lt;/li&gt;
&lt;li&gt;过程合理性：虽然允许路径变化，但要确保路径在逻辑、效率、成本、可靠性上“说得通”。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="从小样本集上就开始做评估"&gt;从小样本集上就开始做评估&lt;/h2&gt;
&lt;p&gt;不要等数据量大时才开始做评估，在小样本的时候就开始做评估&lt;/p&gt;
&lt;h2 id="llm-as-judge"&gt;LLM AS JUDGE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;研究输出的评估难题：研究输出通常是自由形式的文本，很难通过程序化的方法进行评估，因为它们很少有唯一正确的答案。&lt;/li&gt;
&lt;li&gt;LLM作为评判工具的适用性：LLM 由于其强大的语言理解和生成能力，非常适合用于评估这种复杂的研究输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="打分规则"&gt;打分规则&lt;/h3&gt;
&lt;p&gt;Anthropic 制定了一些打分规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事实准确性（说法是否与来源一致？）&lt;/li&gt;
&lt;li&gt;引用准确性（引用来源是否真的支撑该说法？）&lt;/li&gt;
&lt;li&gt;完整性（是否涵盖了所有要求的内容？）&lt;/li&gt;
&lt;li&gt;来源质量（是否优先使用了高质量的一手资料，而不是低质量的二手资料？）&lt;/li&gt;
&lt;li&gt;工具效率（是否用了恰当的工具、调用次数是否合理？）
评分方式：LLM评判工具会根据上述标准对每个输出进行评分，评分范围为0.0到1.0，并给出通过或不通过的等级。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验与优化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多评委实验：最初尝试使用多个LLM评判工具来评估每个标准，但发现这种方法不够一致，与人类评判结果的对齐度也不够高。&lt;/li&gt;
&lt;li&gt;单评委优化：最终发现，使用单个LLM评判工具，通过一个单一的提示（prompt）来输出评分和通过/不通过的等级，是最一致且与人类评判结果最接近的方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="人工评估的重要性"&gt;人工评估的重要性&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;自动化评估的局限性：
自动化评估工具（如LLM评判工具）虽然高效，但可能会遗漏一些边缘情况（edge cases）。这些情况包括：&lt;/li&gt;
&lt;li&gt;人工评估的优势：&lt;/li&gt;
&lt;li&gt;多智能体系统的复杂性&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="生产可靠性和工程挑战"&gt;生产可靠性和工程挑战&lt;/h1&gt;
&lt;p&gt;在传统软件里，一个小 bug 可能仅仅让功能崩溃、性能下降或触发一次故障。&lt;/p&gt;
&lt;p&gt;而在agentic 系统里，微小的改动会像滚雪球一样放大，引发巨大的行为漂移——这使得为那些需要在长时间运行中保持状态的复杂智能体编写可靠代码变得异常困难。&lt;/p&gt;
&lt;h2 id="1-增加故障点原地恢复的功能"&gt;1. 增加故障点原地恢复的功能&lt;/h2&gt;
&lt;p&gt;智能体可能长时间运行，在多次工具调用之间持续保持状态。这意味者必须保证代码的持久执行，并在每一步都能妥善处理错误。&lt;/p&gt;
&lt;p&gt;出错时，不能简单地“重启”：重启太昂贵了。所以Anthropic 构建了一套可从故障点原地恢复的系统，并加上了重试逻辑和定期快照来保证断点恢复的功能。&lt;/p&gt;
&lt;h2 id="2-开发全链路追踪"&gt;2. 开发全链路追踪&lt;/h2&gt;
&lt;p&gt;在传统软件里，同样的输入基本会得到同样的输出，可 AI 智能体是“动态、非确定性”的——同一套提示词跑两次，内部决策路径都可能不同，于是调试难度成倍上升。 举个例子：用户投诉“智能体连显而易见的资料都找不到”。光凭日志根本看不出问题出在哪——是它生成了糟糕的搜索关键词？还是选到了垃圾网页？还是工具本身调用失败？&lt;/p&gt;
&lt;p&gt;Anthropic 引入了一套“全链路追踪（full production tracing）”，记录每一次调用、每一个决策节点（关键词→结果→评分→下一步动作），但不记录对话正文，保证用户隐私。&lt;/p&gt;
&lt;p&gt;好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能一眼看出“哦，原来失败都是因为它把 PDF 当网页解析导致失败”之类的根本原因；&lt;/li&gt;
&lt;li&gt;能发现“两个子智能体反复互相踢皮球”这种事先没想到的异常协作；&lt;/li&gt;
&lt;li&gt;把常见失败归纳成模式后，就可以系统性地修 bug、改提示、补工具，而不是靠猜。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="3-部署的时候要考虑用户正在使用"&gt;3. 部署的时候要考虑用户正在使用&lt;/h2&gt;
&lt;p&gt;考虑到无论什么时候发布更新都有可能有用户在使用智能体，Anthropic 采用“彩虹部署（rainbow deployments）”：旧版本和新版本同时在线，逐步将流量从旧实例切到新实例，从而避免打断正在运行的智能体。&lt;/p&gt;
&lt;h2 id="4-同步执行与异步执行"&gt;4. 同步执行与异步执行&lt;/h2&gt;
&lt;h3 id="同步执行优点"&gt;同步执行优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;流程简洁：主智能体按固定顺序等待全部子智能体返回即可，调度与调试成本较低。&lt;/li&gt;
&lt;li&gt;状态一致：所有子任务一次性完成，输出天然对齐，无需额外的合并步骤。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="同步执行挑战"&gt;同步执行挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;吞吐受限：任一子智能体延迟即拖慢全局，系统整体并行度受限。&lt;/li&gt;
&lt;li&gt;缺乏弹性：主智能体无法在运行过程中动态修正子智能体的目标；子智能体之间亦无法实时共享信息或协同。&lt;/li&gt;
&lt;li&gt;资源闲置：当大部分子智能体已结束而少数仍在执行时，算力与带宽均被阻塞，利用率下降。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="异步执行优点"&gt;异步执行优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;并行度显著提升，各子智能体可独立推进并按需衍生新任务；&lt;/li&gt;
&lt;li&gt;主智能体可实时接收中间结果，及时重定向或终止子任务，实现精细化控制；&lt;/li&gt;
&lt;li&gt;子智能体之间可通过消息机制即时协作，提高整体效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="异步执行挑战"&gt;异步执行挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;结果汇总：需额外机制对无序到达的结果进行排序、去重与聚合；&lt;/li&gt;
&lt;li&gt;状态一致：分布式快照或事务协议保障全局视图同步，增加系统复杂度；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="5-上下文管理"&gt;5. 上下文管理&lt;/h2&gt;
&lt;p&gt;当 AI 代理需要与用户进行几百轮对话时，如何让它“记住”前面发生的事，又不会因为上下文窗口塞不下而失效呢？&lt;/p&gt;</description></item><item><title>2025-09-10 Anthropic 做 Multi Agent系统的工程经验（上）</title><link>https://huizhixu.github.io/chs/know_how/20250910anthropic-%E5%81%9A-multi-agent%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8A/</link><pubDate>Wed, 10 Sep 2025 12:50:47 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250910anthropic-%E5%81%9A-multi-agent%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8A/</guid><description>&lt;p&gt;从ChatGPT时代到现在，大家逐渐达成共识：大模型的应用核心不是算法问题，而是工程问题。大模型本身作为基础设施已经就位，关键在于如何通过工程手段解决记忆存储、上下文管理、工具调用和提示词优化等实际问题。&lt;/p&gt;
&lt;p&gt;最近读了Anthropic关于多智能体系统的工程实践， 感觉很有意思，所以分享出来。这一篇将解析：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multi Agent的架构设计（Orchestrator-Worker模式）&lt;/li&gt;
&lt;li&gt;Multi Agent的优劣势&lt;/li&gt;
&lt;li&gt;提示工程实践（8条 Anthropic 核心经验）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下一篇写Anthropic的智能体评估、产品可靠性和工程挑战。&lt;/p&gt;
&lt;h1 id="multi-agent-的架构"&gt;Multi Agent 的架构&lt;/h1&gt;
&lt;h3 id="orchestrator-worker模式解析"&gt;Orchestrator-Worker模式解析&lt;/h3&gt;
&lt;p&gt;Anthropic采用orchestrator-worker架构模式。&lt;/p&gt;
&lt;p&gt;在AI的论文中经常可以看见orchestrate这个单词。orchestrator的本义是是管弦乐的编曲者，是把一首乐曲改编成适合管弦乐队演奏、并为每种乐器分配合适声部和旋律的人。&lt;/p&gt;
&lt;p&gt;在这里orchestrator 引申为“负责总体调度、协调、编排所有子任务的组件，又叫lead agent（主智能体）。 worker是执行子任务的智能体，又叫subagent（子智能体）。&lt;/p&gt;
&lt;p&gt;主智能体作为系统的&amp;quot;指挥中心&amp;quot;，其核心职责包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任务分解与分配&lt;/li&gt;
&lt;li&gt;资源协调与调度&lt;/li&gt;
&lt;li&gt;结果整合与决策
子智能体则专注于执行特定子任务，彼此并行工作，通过分工协作提升系统整体效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="架构图"&gt;架构图&lt;/h3&gt;
&lt;p&gt;下面是研究系统的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250910/69ac33e7.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;如图所示，当用户提交查询时，主智能体会进行分析，制定策略，通过子智能体迭代使用搜索工具收集信息，然后将信息返回给主智能体，最后汇总成最终答案。&lt;/p&gt;
&lt;p&gt;多智能体与RAG的不同：&lt;/p&gt;
&lt;p&gt;检索增强生成 (RAG) 一种静态检索，它们会获取与输入查询最相似的一组词块，并使用这些词块生成响应。而多智能体架构采用多步骤搜索，可以动态地查找相关信息，适应新的发现，并分析结果以生成高质量的答案。&lt;/p&gt;
&lt;h3 id="交互流程"&gt;交互流程&lt;/h3&gt;
&lt;p&gt;下面是多智能体系统的交互流程，这里可以看出，除了不同的智能体、还有Memory模块和Citation Agent。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250910/0c84baf9.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当用户提交查询时，系统会创建一个 LeadResearcher（主研智能体），它进入迭代式研究循环。&lt;/li&gt;
&lt;li&gt;主研先思考整体方案，并把计划写入 Memory（记忆模块），以保证上下文被持久化——因为上下文窗口一旦超过 20 万 token 就会被截断，保留计划至关重要。&lt;/li&gt;
&lt;li&gt;主研创建若干专门的 Subagent（分研智能体，图中示例为 2 个，实际数量可任意），各自领取具体的子任务。&lt;/li&gt;
&lt;li&gt;每个分研独立执行网页搜索，并用“Interleaved thinking”的方式评估工具返回结果，随后将发现返回给主研。&lt;/li&gt;
&lt;li&gt;主研汇总这些结果，并判断是否需要继续研究；&lt;/li&gt;
&lt;li&gt;如需继续，它可以再创建新的分研或调整策略。当信息足够后，系统退出研究循环，把所有发现交给 CitationAgent（引用智能体）。&lt;/li&gt;
&lt;li&gt;引用智能体对文档和研究报告进行处理，为每一处需要引用的内容定位具体来源，确保所有结论都能追溯到出处。最终，带完整引用的研究结果返回给用户。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;值得一提的是，这里说到Interleaved thinking 是指交错思考。&lt;/p&gt;
&lt;p&gt;Claude 4 模型在调用工具（tool calls）时，不把“思考过程”一次性打包完，而是在每次得到工具返回结果之后，再插入一段新的思考（reasoning），然后再决定下一步要不要继续调用工具、调用哪一个工具。&lt;/p&gt;
&lt;p&gt;整个“思考—调用工具—再思考—再调用……”的流程像齿轮交错一样穿插进行，而不是传统的“先一口气想好所有步骤，再连续执行”。&lt;/p&gt;
&lt;h1 id="multi-agent的优劣势"&gt;Multi Agent的优劣势&lt;/h1&gt;
&lt;h3 id="为什么研究性的工作适合用multi-agent-来做"&gt;为什么研究性的工作适合用Multi Agent 来做？&lt;/h3&gt;
&lt;p&gt;因为研究工作主要涉及开放性的问题，研究者会根据在研究过程中出现的线索，持续更新自己的研究方法。&lt;/p&gt;</description></item><item><title>2025-08-30 写在八月结束</title><link>https://huizhixu.github.io/chs/life/20250830%E5%86%99%E5%9C%A8%E5%85%AB%E6%9C%88%E7%BB%93%E6%9D%9F/</link><pubDate>Sat, 30 Aug 2025 13:54:50 +0000</pubDate><guid>https://huizhixu.github.io/chs/life/20250830%E5%86%99%E5%9C%A8%E5%85%AB%E6%9C%88%E7%BB%93%E6%9D%9F/</guid><description>&lt;p&gt;这两个月运动得很疯狂。&lt;/p&gt;
&lt;p&gt;每周六都特别幸福——因为我会去前滩社区连上两节尊巴课，一节是不间断的团课，另一节是Zumba Basic。这两个月教的主要是118套路，每次跳完都酣畅淋漓。&lt;/p&gt;
&lt;p&gt;除了周六，周三和周五晚上我会去做些力量训练。&lt;/p&gt;
&lt;p&gt;对我来说，尊巴最重要的就是放松自己，享受音乐、享受舞蹈本身。但这份“享受”其实跟教练很有关系。我之前特别喜欢的教练后来去了超级猩猩，课都开在很远的地方，加上他在上海越来越受欢迎，每节课人都很多，我就很少再跟了。&lt;/p&gt;
&lt;p&gt;我想找个靠谱的新教练再跟一跟，考察了家附近的几个乐刻的教练之后，都比较失望。直到后来有一次我在朋友圈看到一个为期两个半月的舞蹈课程，抱着试试看的心态报了名。没想到，体验比预期好很多。原本有点焦虑，怕教练不合适，后来发现，并不是所有好教练都被大众熟知。比如现在这位老师，我之前完全没听说过他，但他的舞感和节奏都特别好。后来才知道，他其实是Keepland平台上比较早期的尊巴教练，已经跳了很多年。&lt;/p&gt;
&lt;p&gt;我认为他确实是颗沧海遗珠，但奇怪的是，我以前从没在任何尊巴的公开活动上见过他，而这些活动上海稍微有名气的教练都会去。后来他告诉我，因为他没有注册尊巴的官方会员，所以不能以教练身份公开带课。原来，尊巴教练需要认证ZES资格，否则可能涉及侵权。这也让我想起以前的教练提醒过，尊巴课程内容是有版权的，不能随意传播到社交平台。&lt;/p&gt;
&lt;p&gt;新教练的风格我很喜欢，尤其是Zumba Basic这节课，我们会反复练习很多基础动作，这一点跟我以前的体验很不一样。于是从七月开始，我每周六都准时去上前滩的两节课，一次也没缺席。&lt;/p&gt;
&lt;p&gt;跳舞让我感到特别畅快，连续两个月每周六都上课，也意味着这两个月我都没离开上海——这在以前几乎是不可想象的。自从五一从张掖回来之后，我的心境好像悄悄变了：对旅游不再那么执着。&lt;/p&gt;
&lt;p&gt;曾经，《锵锵行天下》在我心里种下了遥远的梦，让我对地中海、西北和江南都充满了向往。后来我跟着节目里的路线，也陆续去了一些地方，慢慢地，那种“非去不可”的执念就淡了。现在我觉得，去，很好；不去，也可以。&lt;/p&gt;
&lt;p&gt;我逐渐学会在当下就能找到乐趣，不再觉得所求的都在远方。&lt;/p&gt;
&lt;p&gt;现在上班通勤特别近，每天上下班各只要15分钟。省去了漫长的通勤时间，我拥有了更多属于自己的时间。年初我定下一个目标：每周写一篇文章，内容可以是技术总结、阅读心得或生活随想，这个目标我基本都实现了。&lt;/p&gt;
&lt;p&gt;对我而言，看书、学习新知识是一件特别快乐的事。有时候我觉得，这种快乐并不完全来自于所学的内容本身，而更多是源于那种“在进步”的快感。如果我长时间停留在原地、没有任何变化，就很容易感到无聊。但学习不一样，不管学什么，总能给生活带来一些新的气息。&lt;/p&gt;
&lt;p&gt;今&lt;/p&gt;
&lt;p&gt;年我开始尝试用费曼学习法，也就是把学的东西自己重新总结一遍。我发现，光是敲在电脑上，记忆就会加深不少——但这还不够。更有效的是，当我用自己的话把它讲出来，尤其是讲给别人听的时候，我才真的感觉“掌握了”。也许真正的思考，就发生在这个解释与表达的过程中。有时候我甚至会想，如果想让AI变得更智能，是不是也可以参考这样的学习方式？&lt;/p&gt;
&lt;p&gt;这几个月我另一个积极的改变，是读了项飙的书之后，我开始更重视线下生活。我把淘宝卸载了，增加了很多线下购物，也增加了运动、Citywalk、看展和看音乐剧的时间。&lt;/p&gt;
&lt;p&gt;职场方面，我也在慢慢调整。现在的公司氛围很好，领导宽容度高，也愿意倾听我们的建议。令我惊讶的是，“快乐”甚至是公司文化的一部分——不加班、不打卡，把事情做完就可以下班。每天中午，大家围着长桌一起吃饭，聊天说笑，氛围特别轻松。最关键的一点是，在这个公司，有很多人都是带饭上班，慢慢地也影响到我，我也开始做饭，每周带一两次饭。就是这样小小的习惯，让我觉得生活仿佛扎下了根，不再那么飘着。&lt;/p&gt;
&lt;p&gt;当然，职场不总是温情脉脉。跨部门沟通、业务推进中也会遇到无奈甚至无语的时刻。面对这些，我提醒自己两个原则：“不忘初心”和“成全他人”。“不忘初心”是指，记得自己为什么来这里，来这里是干什么的，如果困难对“初心”有没有影响，那是不是可以让一让，克服一下。“成全他人”是指，如果别人想要做一件事，如果有能力，我会去帮助他推进这件事，同时不会把credit归我。随着人的思想慢慢变成熟，以前我很多在意的地方都不在意了。我现在好像知道了什么是最重要的。&lt;/p&gt;
&lt;p&gt;我还读了一些书，都是趁着午休的时候。中午有一个半小时的午休，除了特别困，我现在已经不习惯午睡了。我们公司的旁边有一个公众空间，里面有一个小型图书馆。中午我经常去那边看书，里面各个领域的书都有一些，也有不少杂志。人工智能领域很多大热的书，例如李飞飞的那本和年初很火的我也看完了的《为什么伟大不能被计划》都摆在显眼的位置。不过我打定主意先把这半年的《科幻世界》杂志看完。因为我很好奇，在人工智能时代，现在的人会对未来有什么想象呢？&lt;/p&gt;
&lt;p&gt;科幻除了描写未来的世界，也要描写未来的“人”，除了生存或存在这个命题，还有人的感情、体验以及一切会发生在现在的情感。&lt;/p&gt;
&lt;p&gt;“人工智能”在某种意义上是一种技术，而不是一个全新的世界。我们期待五十年后的世界更便捷，更发达，但也希望更有爱，更治愈，更公平，更温暖，更坚定。但是这个愿望，真能靠科技实现吗？我曾经比较悲观，觉得除了科技发展，世界不会有任何变化。那这样的话，发展科技还有什么动力？&lt;/p&gt;
&lt;p&gt;《黑镜》第七季第一集里面讲述男女主为了维持生命，而把生命卖给科技公司的故事。科技到底是在增强生命，还是在剥削生命？Hinton 提倡“AI for Good”不是没有道理，世界从来不是单一价值的——有人用AI行善，就也有人用它作恶。&lt;/p&gt;
&lt;p&gt;好了，关于AI就写到这里，AI在我生活中已经占据太多了。&lt;/p&gt;
&lt;p&gt;回过头看这几个月，我之前担心的事——比如找不到好教练、不适应新公司、难以融入新团队——其实大多都没有发生。很多烦恼，想通了就不是问题；而那些真正的问题，你可以选择解决，也可以选择不在乎。&lt;/p&gt;
&lt;p&gt;我好像越来越笃定，没那么迷茫了。确实，行动会给自己带来信心。&lt;/p&gt;</description></item><item><title>2025-08-27 TRAE Agent 基于Agent的编程补丁生成与选择框架</title><link>https://huizhixu.github.io/chs/know_how/20250827trae-agent%E5%9F%BA%E4%BA%8Eagent%E7%9A%84%E7%BC%96%E7%A8%8B%E8%A1%A5%E4%B8%81%E7%94%9F%E6%88%90%E4%B8%8E%E9%80%89%E6%8B%A9%E6%A1%86%E6%9E%B6/</link><pubDate>Wed, 27 Aug 2025 14:11:46 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250827trae-agent%E5%9F%BA%E4%BA%8Eagent%E7%9A%84%E7%BC%96%E7%A8%8B%E8%A1%A5%E4%B8%81%E7%94%9F%E6%88%90%E4%B8%8E%E9%80%89%E6%8B%A9%E6%A1%86%E6%9E%B6/</guid><description>&lt;p&gt;最近几个月我都在使用Trae。它更新很频繁，中间经历了一次大改——Logo由橙色改为绿色，以及数不清的小版本迭代。基本上每天打开电脑TRAE都在提示更新。我挺好奇他们是怎么开发Agent的，最近就去看了他们的一些博客和论文。&lt;/p&gt;
&lt;p&gt;Trae用的是agent-first架构。它的核心是Agent，而不是那种通用的聊天模型。也就是说，用户的查询会直接交给一个或一组最合适的Agent来处理。在Trae里，MCP不再直接和用户打交道，而是在底层发挥作用，就像Agent之间以及Agent和外部工具之间沟通和协调的“管道”或“神经系统”。&lt;/p&gt;
&lt;p&gt;论文和博客里讲的都是怎么实现这个编程Agent的。具体来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;真实场景中，修复缺陷往往涉及多个文件和模块，需要跨文件推理、感知上下文，并在整个代码库中验证补丁的正确性。Trae Agent研发了一种基于agent的集合推理框架，能够解决仓库级别的问题。&lt;/li&gt;
&lt;li&gt;Trae Agent的工作分为三个阶段：
&lt;img src="https://uvidumfqwzk.feishu.cn/space/api/box/stream/download/asynccode/?code=YWIzOWViOTgwZDVmOThhYjIzYjU2YzMxMDI4ZWQzMzFfd3B5eVVSR2FRbzNxbldjcjhxbXhRWjc3WFZBblUyZmlfVG9rZW46RUlFd2JXUlkzb3FGZWZ4TFk0OWNJbkRSbkFiXzE3NTYzMDI3NTI6MTc1NjMwNjM1Ml9WNA" alt=""&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（图源于论文：Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling ）&lt;/p&gt;
&lt;h2 id="三个阶段对应三个agent"&gt;三个阶段对应三个Agent&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Coder Agent：并行生成候选补丁，通过提高温度和多模型轮询（如Gemini 2.5 Pro、Claude 3.7 Sonnet和GPT-4.1）来增加多样性。&lt;/li&gt;
&lt;li&gt;Tester Agent：自动提取并执行回归测试，过滤掉错误的补丁。&lt;/li&gt;
&lt;li&gt;Selector Agent：对剩余补丁进行仓库级静态和动态分析，通过投票选出最终补丁。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="生态工具"&gt;生态工具&lt;/h1&gt;
&lt;p&gt;TRAE建立了一个工具生态，包含以下四种工具，这些工具在三个阶段中都会被应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文件编辑工具：查看文件和目录结构，创建和编辑文件。&lt;/li&gt;
&lt;li&gt;Bash工具：提供持久的命令执行接口，让Agent能够与系统交互，捕获输出和错误信息。&lt;/li&gt;
&lt;li&gt;顺序思考工具：将复杂问题拆解，进行迭代式思考和修正，提出假设并验证，提供结构化的问题解决和分析能力。&lt;/li&gt;
&lt;li&gt;任务完成工具：发出任务结束信号，给出最终结果和总结。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="阶段一补丁生成"&gt;阶段一：补丁生成&lt;/h1&gt;
&lt;p&gt;这个阶段主要是采用多个主流大语言模型根据描述生成候选补丁。这个阶段主要由Coder Agent完成，它遵循以下多步流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;分析问题描述，理解要解决的问题是什么；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;探索代码库，定位与问题相关的文件；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复现 bug，验证其表现；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过代码审查诊断根本原因；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成代码补丁以修复已识别的缺陷；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重新运行复现测试，验证补丁的正确性；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;总结整个工作流程，模拟真实的commit message。
为了增加候选结果的多样性，采取了以下措施：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在运行Coder Agent时提高温度，增加多样性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引入Mixture设置，以轮询方式调用三种LLM生成补丁。
此外，为了实现可观测性，轨迹记录系统会详细记录每一步的信息，包括与LLM的交互、Agent的具体步骤、元数据以及错误追踪。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="阶段二补丁修剪"&gt;阶段二：补丁修剪&lt;/h1&gt;
&lt;p&gt;这个阶段由Tester Agent完成，它会自动从原始项目代码库中检索与问题描述相关的回归测试，并过滤掉不正确的补丁。具体做法如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用Python的unidiff库实现补丁解析器，将原始补丁转换为结构化表示。&lt;/li&gt;
&lt;li&gt;通过补丁归一化移除语义无关的元素，如多余空格、换行和注释。&lt;/li&gt;
&lt;li&gt;无法解析的补丁被视为无效并直接丢弃。&lt;/li&gt;
&lt;li&gt;对归一化后的补丁进行等价检测，若多条候选补丁的归一化结果完全相同，则判定其语义等价，仅保留其一。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="阶段三补丁选择"&gt;阶段三：补丁选择&lt;/h2&gt;
&lt;p&gt;这个阶段由Selector Agent完成，它会进行以下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于语法的投票：Selector agent 首先执行基于语法的投票，通过对候选补丁进行语法等价聚类，并选择出现频率最高的聚类作为潜在解决方案。其原理是，如果多个 Coder agent 独立生成了严格语法等价的补丁，则表明存在强烈共识，暗示这些高度一致的补丁更有可能是正确的&lt;/li&gt;
&lt;li&gt;多重选择投票：先对补丁进行去重。然后多个selector agent对去重后的补丁进行投票，选出最可能正确的补丁。如果票数分布均匀会增加投票轮数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="如何评估trae-agent"&gt;如何评估TRAE Agent：&lt;/h2&gt;
&lt;p&gt;TRAE Agent的性能通过与四种最新的集成推理基线方法（Augment、Augment w/ Pruning、DeiBase和DeiBase w/ Pruning）在三种主流LLM（Gemini 2.5 Pro、Claude 3.7 Sonnet和GPT-4.1）上进行对比评估。评估指标包括：&lt;/p&gt;</description></item><item><title>2025-08-24 从零构建大模型-徒手组装GPT</title><link>https://huizhixu.github.io/chs/know_how/20250824-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E5%BE%92%E6%89%8B%E7%BB%84%E8%A3%85gpt/</link><pubDate>Sun, 24 Aug 2025 13:55:15 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250824-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E5%BE%92%E6%89%8B%E7%BB%84%E8%A3%85gpt/</guid><description>&lt;p&gt;《从零构建大模型》8周学习计划（按周打卡！）
1️⃣ 数据预处理✅
2️⃣ 注意力机制✅
3️⃣ 徒手组装GPT✅
4️⃣ 徒手训练GPT
5️⃣ 微调：分类
6️⃣ 微调：SFT
7️⃣-8️⃣ 缓冲周&lt;/p&gt;
&lt;h2 id="gpt的几个概念"&gt;GPT的几个概念：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;参数：指模型的可训练权重，本质是模型的内部变量。在训练过程中通过调整和优化来最小化特定的损失函数来学习。&lt;/li&gt;
&lt;li&gt;GPT-2和GPT3：架构基本相同，训练的数据量不同，参数量不同。GPT-2的权重公开，GPT-3的权重没有。&lt;/li&gt;
&lt;li&gt;GPT2的config
vocab_size表示使用50257个token组成的词汇表。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;context_length指的是模型一次输入的最大token 数量。&lt;/p&gt;
&lt;p&gt;emb_dim表示嵌入维度大小。&lt;/p&gt;
&lt;p&gt;n_heads表示多头注意力机制中注意力头的数量。&lt;/p&gt;
&lt;p&gt;n_layers表示模型中的Transformer块数量。&lt;/p&gt;
&lt;p&gt;drop_rate表示表示有10%的隐藏单元被随机丢弃，以防止过拟合。&lt;/p&gt;
&lt;p&gt;qkv_bias指的是是否在多头注意力机制的线性层中添加一个偏置向量，用于查询、键和值的计算。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;GPT_CONFIG_124M &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;50257&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;context_length&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;1024&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;768&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;n_heads&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;12&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;n_layers&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;12&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;drop_rate&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;0.1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;qkv_bias&amp;#34;&lt;/span&gt;:&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;GPT大语言模型的组件：嵌入层、Transformer块、输出层。&lt;/li&gt;
&lt;li&gt;Transformer块包括层归一化，GELU激活函数、前馈神经网络、残差链接和多头注意力模块。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250824/668b362d.png" alt=""&gt;&lt;/p&gt;
&lt;h2 id="一打好框架构建dummy类"&gt;一、打好框架：构建Dummy类&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;这里的Dummy类只用于结构完整性，并不是具体真实的实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据在模型中的处理流程：它首先计算输入索引的词元和位置嵌入，然后应用dropout，接着通过Transformer块处理数据，再应用归一化，最后使用线性输出层生成logits。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码理解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nn.Embedding 的本质是创建一个权重矩阵，是把词表里的每一个 token_id 映射成一个向量。&lt;/li&gt;
&lt;li&gt;self.tok_emb = nn.Embedding(config[&amp;ldquo;vocab_size&amp;rdquo;], config[&amp;ldquo;emb_dim&amp;rdquo;])—— 在 &lt;strong&gt;init&lt;/strong&gt; 里建表，告诉模型：词表有多大，每个 token 要映射成多少维的向量。这一步只发生一次，把权重矩阵（形状 [vocab_size, emb_dim]）存到 self.tok_emb 里。&lt;/li&gt;
&lt;li&gt;tok_emb = self.tok_emb(in_idx)—— 在 forward 里查表（把输入的 token_id 拿去这张表里查对应的向量）。这一步每次前向传播都会调用，输入是形状 [batch, seq_len] 的整数张量，输出是 [batch, seq_len, emb_dim] 的嵌入张量。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch.nn &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; nn
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyTransformerBlock&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, config) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyLayerNorm&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, normalized_shape, eps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1e-5&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyGPTModel&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, config) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Embedding(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pos_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Embedding(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;context_length&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;drop &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Dropout(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;drop_rate&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;transformer_blocks &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Sequential(&lt;span style="color:#ff79c6"&gt;*&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; DummyTransformerBlock(config) &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; _ &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;range&lt;/span&gt;(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;n_layers&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ]) &lt;span style="color:#6272a4"&gt;# 使用占位符替换TransformerBlock&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;final_norm &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DummyLayerNorm(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;out_head &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Linear(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;], bias&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, in_idx):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; batch_size, seq_len &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; in_idx&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;shape
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tok_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok_emb(in_idx)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; pos_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pos_emb(torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;arange(seq_len, device&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;in_idx&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;device))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; tok_emb &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; pos_emb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;drop(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;transformer_blocks(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;final_norm(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;out_head(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; logits
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="二层归一化"&gt;二、层归一化&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;层归一化指调整神经网络层的输出，使其均值为0且方差为1。&lt;/li&gt;
&lt;li&gt;为什么要层归一化：使训练稳定，加速权重收敛。&lt;/li&gt;
&lt;li&gt;什么时候用：多头注意力的前后；最终输出层之前&lt;/li&gt;
&lt;li&gt;LayerNorm 沿着列方向（hidden_size） 做归一化&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码理解：&lt;/p&gt;</description></item><item><title>2025-08-22 罗永浩和李想的视频对谈</title><link>https://huizhixu.github.io/chs/know_how/20250822-%E7%BD%97%E6%B0%B8%E6%B5%A9%E5%92%8C%E6%9D%8E%E6%83%B3%E7%9A%84%E8%A7%86%E9%A2%91%E5%AF%B9%E8%B0%88/</link><pubDate>Fri, 22 Aug 2025 13:54:01 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250822-%E7%BD%97%E6%B0%B8%E6%B5%A9%E5%92%8C%E6%9D%8E%E6%83%B3%E7%9A%84%E8%A7%86%E9%A2%91%E5%AF%B9%E8%B0%88/</guid><description>&lt;p&gt;昨晚下班后我看了罗永浩和李想的视频播客，我之前只知道李想是理想的创办者，也是汽车之家的创办者，但是我对他的具体的经历不是很了解。&lt;/p&gt;
&lt;p&gt;他首先讲了自己的童年和青少年时期，他跟着底色善良的姥姥姥爷长大，父母上过大学，非常开明，他的童年幸福到罗永浩都忍不住羡慕。&lt;/p&gt;
&lt;p&gt;后面他就谈起自己的创业历程。在初中时，他就显露出商业头脑。&lt;/p&gt;
&lt;p&gt;小时候，他会从漫画批发市场把漫画书批发回来，然后卖给同学挣些钱。初中时，他正式接触电脑，当时他非常痴迷学电脑，但那时他没有电脑，只能看书学习。不过，在这个过程中，他在电脑的世界里找到了归属感。&lt;/p&gt;
&lt;p&gt;后来他真正有了电脑，上手非常快，因为之前的基本功已经相当扎实。他说基本上用了一天时间，就把很多问题都解决了。那时他暑假到买电脑的商家那里帮忙组装电脑，这不仅让他赚到了钱，也让他明确了以后想从事的道路。&lt;/p&gt;
&lt;p&gt;高三时，他自己做了一个“显卡之家”，也很成功。他很有头脑，除了自己写代码，还招了两个人一起写。&lt;/p&gt;
&lt;p&gt;从高中开始，他从这种正向反馈里形成了对自己的认知，即：掌控自己的命运，挑战成长的极限。他从来没有经历过青春期的迷茫，一路走来都很顺利。接触电脑书、打好基础、实践操作快、获得正向反馈、写稿件、建立“显卡之家”。&lt;/p&gt;
&lt;p&gt;高中毕业之后，他跟父母提出不想去上大学，想去创业。他说服父母的理由是，自己高中时就已经赚到钱，已经证明了自己的能力（他高三的月收入就有两万多，是他父母的十几倍）。&lt;/p&gt;
&lt;p&gt;他聊到后面做汽车之家，其实他们汽车之家已经做到了垂直领域最好，他们的技术、内容和产品都非常强，整个商业体系也很强，但是他们只把业务放在一个垂直网站上面，所以他对这一点比较遗憾。这里能看出李想是想要普世大成功的那种人。&lt;/p&gt;
&lt;p&gt;他还说做硬件和做软件的公司，组织方式是不一样的。从科技公司的角度来说，全世界最成功的组织方式有两大类。一大类是有特别严格的流程，因为可能这个品类很复杂，遵循木桶理论，比如手机、终端、操作系统，一个环节出问题就不行。华为和IBM就是这种，这是第一类企业，以流程为主。但这类企业的问题在于做互联网和人工智能会稍微弱一点，因为存在组织适配性的问题。&lt;/p&gt;
&lt;p&gt;另外一类公司，像字节和谷歌，这两类公司不依赖流程，而是依赖更高的人才密度，并用OKR这样的工具把大家连接在一起，所以对人才密度要求非常高。这类企业做平台、做创新、做技术研究都非常好，但去做一些复杂的硬件时就会弱一些。&lt;/p&gt;</description></item><item><title>2025-08-17 从零构建大模型——注意力机制</title><link>https://huizhixu.github.io/chs/know_how/20250817%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link><pubDate>Sun, 17 Aug 2025 13:55:21 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250817%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid><description>&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;h3 id="编码器-解码器"&gt;编码器-解码器&lt;/h3&gt;
&lt;p&gt;编码器将源语言的一串词元序列作为输入，并通过隐藏状态（一个中间神经网络层）编码整个输入序列的压缩表示（可以理解为嵌入）。然后，解码器利用其当前的隐藏状态开始逐个词元进行解码生成。&lt;/p&gt;
&lt;p&gt;编码器-解码器RNN的缺陷：在解码阶段，RNN无法直接访问编码器中的早期隐藏状态，它只能依赖当前的隐藏状态。这可能导致上下文丢失，特别是在依赖关系可能跨越较长的距离的句子中。&lt;/p&gt;
&lt;h2 id="构建大语言模型的三个阶段"&gt;构建大语言模型的三个阶段&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250817/bb022129.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;（图来源于书籍）&lt;/p&gt;
&lt;p&gt;这张图画得很清晰，第三章的主要学习注意力机制。&lt;/p&gt;
&lt;h2 id="学习目标"&gt;学习目标&lt;/h2&gt;
&lt;p&gt;实现4种注意力机制&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简化版的自注意力机制&lt;/li&gt;
&lt;li&gt;加入可训练的权重的自注意力机制&lt;/li&gt;
&lt;li&gt;因果注意力机制&lt;/li&gt;
&lt;li&gt;多头注意力机制&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="简化版的自注意力机制"&gt;简化版的自注意力机制&lt;/h2&gt;
&lt;h3 id="关键概念"&gt;关键概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;注意力机制：对于输出，某些输入词元比其他词元更重要。重要性由注意力权重决定。&lt;/li&gt;
&lt;li&gt;“自”是什么意思：&lt;/li&gt;
&lt;li&gt;上下文向量是什么？&lt;/li&gt;
&lt;li&gt;上下文向量怎么计算？&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="实践"&gt;实践&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;import torch
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;inputs = torch.tensor(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [[0.43, 0.15, 0.89], # Your (x^1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.55, 0.87, 0.66], # journey (x^2)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.57, 0.85, 0.64], # starts (x^3)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.22, 0.58, 0.33], # with (x^4)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.77, 0.25, 0.10], # one (x^5)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.05, 0.80, 0.55]] # step (x^6)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(inputs.shape[0])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;query = inputs[1]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_scores = torch.empty(inputs.shape[0],inputs.shape[0])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_scores = inputs @ inputs.T
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(attn_scores)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_weights = torch.softmax(attn_scores, dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(&amp;#34;Attention weights:&amp;#34;, attn_weights)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(&amp;#34;Sum:&amp;#34;, attn_weights.sum(dim=-1))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;all_context_vecs = attn_weights @ inputs
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(all_context_vecs)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="带可训练权重的自注意力机制缩放点积注意力-scaled-dot-product-attention"&gt;带可训练权重的自注意力机制（缩放点积注意力 scaled dot-product attention）&lt;/h2&gt;
&lt;h3 id="关键概念-1"&gt;关键概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;缩放点积注意力&lt;/p&gt;</description></item><item><title>2025-07-26 论文阅读 LongCite Enabling LLMs to Generate Fine-grained Citations in Long-context QA</title><link>https://huizhixu.github.io/chs/know_how/20250726-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBlongcite-enabling-llms-to-generate-fine-grained-citations-in-long-context-qa/</link><pubDate>Sat, 26 Jul 2025 14:11:41 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250726-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBlongcite-enabling-llms-to-generate-fine-grained-citations-in-long-context-qa/</guid><description>&lt;p&gt;大模型的幻觉一直没有被解决，在有上下文的情况下最直接的应对方式就是让它“自证出处”。在调研的过程中，我发现，目前主流做法要么照搬 DeepSeek-R1 的 prompt 模板让模型当场给出引用，要么事后用规则再捞一遍参考文献。但是这篇论文走了另一条路：拿一个 8B/9B 的小模型，针对“长上下文问答 + 引用生成”做微调。&lt;/p&gt;
&lt;p&gt;这个一年前的论文微调的小模型应该打不过现有的大模型，但是在构造数据集、构造评估的方法等方面都给了我启发。&lt;/p&gt;
&lt;p&gt;原文地址：https://arxiv.org/abs/2409.02897&lt;/p&gt;
&lt;h1 id="背景"&gt;背景&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;长文本大模型用来做信息抽取或者总结，但是因为缺乏引用，无法支撑观点。&lt;/li&gt;
&lt;li&gt;RAG因为缺少完整的上下文信息导致答案质量下降，post-hoc方法则因流程复杂延长用户等待时间。&lt;/li&gt;
&lt;li&gt;虽然有的web search能够提供引用，但是指向整个页面，粒度太粗。而用户需要知道知道具体的引用段落或者句子。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;提出了LongBench-Cite，一个带引用的长上下文问答的benchmark&lt;/li&gt;
&lt;li&gt;提出了CoF，一种用大模型自动构建高质量长上下文数据集的pipeline&lt;/li&gt;
&lt;li&gt;构造了数据集 LongCite-45k&lt;/li&gt;
&lt;li&gt;训练了模型 LongCite-8B 和 LongCite-9B&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="benchmark-longbench-cite"&gt;Benchmark LongBench-Cite&lt;/h2&gt;
&lt;h3 id="1-构造带引用的长上下文问答任务"&gt;1. 构造带引用的长上下文问答任务&lt;/h3&gt;
&lt;p&gt;给定语料$D$和查询$q$，大模型需要返回一个响应$A$，该响应由n个陈述$s_1$，&amp;hellip;，$s_n$组成，每个陈述$s_i$有一个引用列表$Ci = {c_{i,1}, c_{i,2}，&amp;hellip; }$，里面引用了D的片段。&lt;/p&gt;
&lt;p&gt;D表示Document，q表示query，A表示Answer，s表示statement，C表示citation。&lt;/p&gt;
&lt;p&gt;大模型需要把它的结果分割成不同的陈述，格式为&amp;lt;&lt;em&gt;statement&lt;/em&gt;&amp;gt;content&amp;lt;&lt;em&gt;/statement&lt;/em&gt;&amp;gt;。&lt;/p&gt;
&lt;p&gt;有两种粒度的引用，这里主要考虑句子级别的引用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;块级引用 Chunk-level citation&lt;/li&gt;
&lt;li&gt;句级引用 Setence-level citation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-构建基准测试longbench-cite"&gt;2. 构建基准测试：LongBench-Cite&lt;/h3&gt;
&lt;p&gt;整合了现有的以下的两个Benchmark的数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LongBench&lt;/li&gt;
&lt;li&gt;LongBench-Chat&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="3-评估"&gt;3. 评估&lt;/h3&gt;
&lt;p&gt;LongBench-Cite基于两个维度进行评估：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;正确性（Correctness）：大模型的回答是否准确和全面&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引用质量（Citation quality）：回答是否完全能由引用的片段得出，同时没有不相关的片段被引用，并且被引用的片段是细粒度的。
3.1 “正确性”的评估方法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;首先把回答里面引用相关的部分移除，让大模型(GPT-4o)基于query和正确答案来评分，采用之前别人的论文提出来的方法来进行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了看增加引用是否会伤害模型的长上下文问答的性能，增加了correctness ratio的计算。
C 和 C_{LQA} 分别表示带引用和不带引用的正确率，不带引用的做法是直接把语料和query给大模型，生成回复。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.2 “引用质量”的评估方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算 Citation Recall&lt;/li&gt;
&lt;li&gt;计算 Citation Precision
对于每个引用，判断它是否是相关的引用（1/0表示相关/不相关），然后计算平均值。这个过程也是用GPT-4o来做的。&lt;/li&gt;
&lt;li&gt;计算 Citation F1
使用 $F1 = (2 · P · R)/(P + R)$ 来计算&lt;/li&gt;
&lt;li&gt;用 Citation Length来评估粗细粒度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cofcoarse-to-fine"&gt;CoF（Coarse to Fine）&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250726/18029c50.png" alt=""&gt;&lt;/p&gt;</description></item><item><title>2025-07-13 读项飙新书《你好，陌生人》</title><link>https://huizhixu.github.io/chs/life/20250713%E8%AF%BB%E9%A1%B9%E9%A3%99%E6%96%B0%E4%B9%A6%E4%BD%A0%E5%A5%BD%E9%99%8C%E7%94%9F%E4%BA%BA/</link><pubDate>Sun, 13 Jul 2025 13:54:02 +0000</pubDate><guid>https://huizhixu.github.io/chs/life/20250713%E8%AF%BB%E9%A1%B9%E9%A3%99%E6%96%B0%E4%B9%A6%E4%BD%A0%E5%A5%BD%E9%99%8C%E7%94%9F%E4%BA%BA/</guid><description>&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250713/4397806d.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这本书前身是播客，讲述项飚与不同的人的对话，这些对话围绕一个核心——关注陌生人。&lt;/p&gt;
&lt;p&gt;书里给的陌生人的定义是：陌生人在当地的经济和社会中找到他们的位置，但是却无法在文化上、精神上、生活方式上与当地融合成一体。&lt;/p&gt;
&lt;p&gt;一开始我也不明白，为什么缓解焦虑要从陌生人开始。带着疑问读了几个不同的故事之后，才明白用意。&lt;/p&gt;
&lt;h2 id="为什么把陌生人作为切入口"&gt;为什么把陌生人作为切入口？&lt;/h2&gt;
&lt;p&gt;我觉得有三方面原因：&lt;/p&gt;
&lt;p&gt;第一，他们就在身边。我们每天都会接触外卖员、快递员、保安和清洁工阿姨。&lt;/p&gt;
&lt;p&gt;第二，他们数量激增，过去进城务工的农民，在城里打工赚钱，回村里花，他们的情感归属和生活意义仍扎根于乡土，他们是陌生人。现在进城打工的年轻人，在城里有一个工作，表面上在经济中找到自己的位置了，实际上在精神和生活方式上也很难和当地融合，他们也是陌生人。这成为当代人共同的处境。&lt;/p&gt;
&lt;p&gt;第三，科技加剧了人与人的疏离。线上生活让我们对身边的陌生人更冷漠，甚至恐惧，而恐惧会进一步加深焦虑。&lt;/p&gt;
&lt;h2 id="那么该如何看见陌生人呢"&gt;那么，该如何看见陌生人呢？&lt;/h2&gt;
&lt;p&gt;书中提供了两种路径：要么将陌生人作为研究对象，理解他们的真实状态，要么通过具体行动，让陌生人成为社区的一部分。&lt;/p&gt;
&lt;p&gt;整本书一共有五场对话，受访者分别是画画的刘小东，“没药花园”公众号博主何袜皮，拍摄杀马特纪录片的导演李一凡，社区营造实践者刘悦来和南京红山动物园馆长沈志军。他们的实践正体现了这两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;刘小东：画的是”由经验积淀出来的人“，而非”有意识自我呈现出来的像“。&lt;/li&gt;
&lt;li&gt;何袜皮：通过分析犯罪案件探讨“亲密关系”与“陌生人”。&lt;/li&gt;
&lt;li&gt;李一凡：关注杀马特，到他们生活的现场去并记录他们。&lt;/li&gt;
&lt;li&gt;刘悦来：利用社区花园重建附近。&lt;/li&gt;
&lt;li&gt;沈志军：通过红山动物园动物园的互动设计例如《熊在吗》留言本和动物认养，把游客卷进共同叙事。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="营造社区"&gt;营造社区&lt;/h2&gt;
&lt;p&gt;为什么社区营造重要？&lt;/p&gt;
&lt;p&gt;因为我们都是陌生人。在城市里生活得越久，这个感受会越强烈——快递小哥、楼下保安、甚至隔壁邻居，我们天天见面却从不真正认识。在国外，教会或者俱乐部可能是个解决方案，你加入进去，自然就有了群体感。但在中国，我们没有这种传统，儒家思想讲究的是亲疏有别，对陌生人我们总是带着点防备。&lt;/p&gt;
&lt;p&gt;书里讲了营造社区的例子。一个是做社区花园的刘悦来，另一个是南京红山动物园的团队。他们做的事情看起来不一样，但本质上都是在想办法让陌生人之间产生联系。&lt;/p&gt;
&lt;p&gt;先说第一个做社区花园的刘悦来。&lt;/p&gt;
&lt;p&gt;我特别佩服这些在小区内做社区的人。首先，要有行动力。要知道，在小区里想做点事情太难了。光是征求大家意见就能拖上好久，因为每个人的想法都不一样。有的人喜欢安静，有的人觉得公共空间跟他没关系。刘悦来他们很聪明，先不跟任何人打招呼，直接动手种花。等花开好了，自然有人来看，等越来越多的人加入进来，特别是小朋友，他们会和这个地方产生关联，例如一起取名字，一起浇花看花，这也是家长乐于看到的事情，他们也会加入进来去维护。&lt;/p&gt;
&lt;p&gt;其次，社区营造需要审美能力。因为一个能吸引人参与的社区，往往具备独特的视觉或文化吸引力。说实话我们现在这个大环境下，审美是非常难得的。我不知道是因为教育，还是我们的文化就是这样。比如说个人装扮，我们认为一个人只要干净、看起来精神就可以了，这里面其实并没有任何审美的积累，可能我们的审美标准就是干净，但我自己感觉这对于有意思的生活来说是非常不够的。那些有能力做社区的人，一定有自己的审美，并且把自己的审美表达出来。&lt;/p&gt;
&lt;p&gt;最后，做社区本来就是要把各种各样有需求的人，还有植物、动物都连接在一起，它对人的素质要求非常高，难怪项飙把它类比到乡绅。不过不同的是乡绅的环境不会变，社区负责人却面临现代挑战。现代人具有高流动性，人搬来搬去，今天还在这里种花，明天可能就换城市了。小朋友长大了要去上学，不会再来看花园；热心居民可能因为工作调动就搬走了。而且种花不是一劳永逸的事情，今年要除草施肥，明年还得重新来过。所以这种社区项目特别脆弱。&lt;/p&gt;
&lt;p&gt;再说说红山动物园。&lt;/p&gt;
&lt;p&gt;红山动物园为什么这么火爆？就是因为它运营得太好了，它完全是在动物的基础上构建了一个社区。无论是手绘地图、《熊在吗》等书，还是认养动物、召集志愿者，或是推出的一些有趣的周边，这些方法让大家参与进来并进行传播。人们知道在这儿会碰到有趣的事情、生动的动物和有爱心的人，所以才会一直想去。&lt;/p&gt;
&lt;p&gt;书里面讲了《熊在吗》这本书的由来，真的非常有意思——他们把熊馆改造之后，馆变大了，生态变好了，熊的自主行为变得更多了。由于场馆很大，人们去看的时候不一定能看到熊。于是饲养员就在门口挂了一个本子，希望每个游客记下看到熊的状态。&lt;/p&gt;
&lt;p&gt;游客真的会在上面写，比如“熊在睡觉”“熊在吃饭”“熊在打架”，或者“没有熊”“熊在哪里呢”。所以游客去了之后，即便没看到熊，但看到了这个册子，也会觉得有意思，实际上就跟其他游客产生了关联，这就好像是社区互动一样。最后他们把本子上记录的内容整理出来，形成了一本书，叫做《熊在吗》。&lt;/p&gt;
&lt;p&gt;你是游客的话，你也会被吸引的。&lt;/p&gt;
&lt;h2 id="如何形成对生活的理解"&gt;如何形成对生活的理解&lt;/h2&gt;
&lt;p&gt;从项飙的上本书看到这本书，一直强调要形成对生活的理解。究竟怎么样的理解才符合这里这里“对生活的理解”的概念呢？&lt;/p&gt;
&lt;p&gt;我带着疑惑阅读，直到我看到导演李一凡的话——“跟他们一起生活这么久，产生了一种对于这里的理解”，才恍然大悟。&lt;/p&gt;
&lt;p&gt;这个过程就像，有一个上帝视角的我，在看另一个“我”如何生活，如何决定去哪里吃饭，散步，度过闲暇，如何决定采用什么样的语言和人交流，和哪些人交流，如何做关于生活的决策。这里的“我”可以是自己，也可以是我们环境中的人、我们关注的人。理解了这些，才会产生有别于书本上或者博主告诉我们的生活经验，从而拥有我们珍贵的第一手经验。只有这样，才能够说得上理解，而不是知道。&lt;/p&gt;
&lt;h2 id="为什么要在乎另一个人的上下文"&gt;为什么要在乎另一个人的”上下文“&lt;/h2&gt;
&lt;p&gt;书里面有提问，了解这些陌生人好像并不能给我带来什么新的认知，为什么要去了解呢？我感觉这个想法好功利啊，但是这也确实是现代人在乎的问题。那么为什么要学会透过表象看一个人的经历，&lt;/p&gt;
&lt;p&gt;为什么要认真对待身边那些看似与自己无关的人和事呢？&lt;/p&gt;
&lt;p&gt;表面上看，关注陌生人、关心他人能缓解我们的焦虑。但我认为更深层的原因是，在学会看见他人的过程中，我们其实也在重新认识自己。这两者是相互映照的——当我们思考&amp;quot;为什么我会这样做&amp;quot;时，往往也能理解&amp;quot;为什么别人会那样做&amp;quot;。&lt;/p&gt;
&lt;p&gt;这让我意识到，真正的理解不是看到“我”符不符合社会定义的&amp;quot;成功标准&amp;quot;，也不是因为同质化的物质生活产生的理解。我们之所以焦虑，往往是因为盲目追求世俗认可，却从未静下心来问自己:这是我真正想要的吗?我的真实感受是什么?我为什么要做这件事?&lt;/p&gt;
&lt;p&gt;所以，关注陌生人之所以能缓解焦虑，是因为在这个过程中，我们得以重新认识自己。这让我想起佛教说的&amp;quot;见万物见自己&amp;quot;，或是西方哲学强调的&amp;quot;人的一生都在寻找自我&amp;quot;。从这个角度看，关注陌生人确实是个很好的自我认知的起点。&lt;/p&gt;
&lt;h2 id="珍惜线下"&gt;珍惜线下&lt;/h2&gt;
&lt;p&gt;书里的导演说，如果他没有去过杀马特群体的家乡，那么影片中呈现的工厂、留守儿童，或者是空空荡荡的房子等内容，就不会占这么大的篇幅。正因为他去了，才知道纪录片应该呈现什么。所以线下体验非常重要。&lt;/p&gt;
&lt;p&gt;我之前在展会上看到VR摄影，当时戴着头盔看几个纪录片片段，真的有身临其境的感觉。那些纪录片画面，有春天樱花树下的场景，有新疆的优美风景。当时我觉得做得很逼真，戴上头盔后，仿佛不再身处嘈杂的会场，而是到了另一个环境。&lt;/p&gt;
&lt;p&gt;但后来我仔细想想，这和真正去过那些地方还是不一样。因为回想起来时，我发现自己没有亲身体验，没有自己的情绪和感受。但如果我真的去过，就能清楚回味当时自己的状态。这就是亲身经历的重要性。&lt;/p&gt;
&lt;h2 id="共鸣"&gt;共鸣&lt;/h2&gt;
&lt;p&gt;这本书讲到几个方法让我很有共鸣。&lt;/p&gt;
&lt;p&gt;首先是诚恳。现在生活太便利了，外卖、快递随叫随到，我们都把这些服务当成理所当然。慢慢地，人会变得特别傲慢。其实我们都知道，这种便利是建立在很多人的辛苦劳动上的，但我们还是忍不住觉得&amp;quot;这是我应得的&amp;quot;。那么诚恳就是要承认这一点，虽然很难，但至少要试着去努力。作者说的诚恳不是非要我们去跟每个人掏心掏肺，而是在做事情的过程中保持真诚的态度，这样整个氛围就会不一样。&lt;/p&gt;
&lt;p&gt;另一个方法是珍惜生活中的小片段。谁都会遇到糟心事：工作不顺、学习压力、感情问题等。但如果我们能留意并记住一些美好的瞬间，日子就会好过很多。我去年开始学着播客里的方法，记录&amp;quot;fifty good moments&amp;quot;——可能是听到一首好歌、看一场好剧、和朋友聊得特别开心、收到一份小礼物等等，确实很有抗压效果。&lt;/p&gt;
&lt;p&gt;里面还有一个我觉得很nice的例子：有一位朋友在旅行的时候会随身带一点小礼物，跟当地小孩或者老人聊天的时候，就送对方一个小礼物，让对方很惊喜。比如在参观完一个博物馆之后，他送了中国的小礼物给博物馆里面的志愿者阿姨，对方就非常开心。&lt;/p&gt;
&lt;p&gt;这确实是一种很好的释放善意的行为，能够减少边界感，也是一种纯粹的自己和他人的连接，我觉得这是一个蛮好的行为，也是和陌生人的一种互动。关注陌生人，本质是重建人与人的真实联结，对抗数字化时代的虚无感。&lt;/p&gt;
&lt;p&gt;最后一点就是关于思考。书中提到要阶段性的进行回顾。我有同感，因为我后来才发现，如果我不记录，或者不去思考事情为什么是这个样子，只是去体验，那么其实我每天就是随波逐流、得过且过。&lt;/p&gt;
&lt;p&gt;偶尔停下来反思一下这段时间我们的决策、世界的变化或者工作学习，在这个过程中我就会有思考。我认为有创作欲是非常重要的。有创作欲就就会引发思考，因为输入一个东西很容易，但是输出的时候就一定会去想：我到底要输出什么东西？我希望这个内容是什么样子。&lt;/p&gt;
&lt;p&gt;所以培养自己对生活的创作欲去很重要的。去想一下，我的生活是这样的，那么围绕这个生活有什么好玩的地方。我们可以纳入各方面的因素，记录自己的生活、观察别人的生活，来起到思考的作用。&lt;/p&gt;
&lt;h2 id="其他"&gt;其他&lt;/h2&gt;
&lt;p&gt;最后，说实话，这本书我觉得没有《把自己作为方法》那本好。那本书里很多观念我都是第一次听到，所以觉得更有趣一些。这本书总的来说比较零碎：话题零碎，涉及的人物和项目也都比较零碎，我在总结的时候就发现了，很难形成一个统一框架。&lt;/p&gt;
&lt;p&gt;我很感谢项飙，他关注年轻人的困境，提出一个又一个的理念，进行一个又一个的访谈，对很多人包括我来说都很有帮助。我已经没有那么焦虑，也知道如何去生活，接下来就是去认真地实践了。&lt;/p&gt;</description></item><item><title>2025-07-02 GraphRAG实践</title><link>https://huizhixu.github.io/chs/know_how/20250702-graphrag%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 02 Jul 2025 13:54:51 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250702-graphrag%E5%AE%9E%E8%B7%B5/</guid><description>&lt;p&gt;GraphRAG刚出来的时候，使用的是OpenAI的对话模型和向量模型，由于在过程中会使用非常多的调用，所以成本较为昂贵。如果想用便宜的国产大模型或者在本地部署，免费使用，那就涉及到本地模型的使用。
使用其他模型有很多种方式，可以用ollama, slang, vllm，text-generations等方式部署。
GraphRAG改版非常多次，在1.0.0版本不支持使用本地模型，在最新的2.0.0以上的版本开始支持ollam部署的模型。
如果要用OpenAI之外的对话模型和向量模型，建议详细阅读：https://github.com/microsoft/graphrag/issues/657。&lt;/p&gt;
&lt;p&gt;我本次用的是ollama部署的qwen2:7b和本地部署的embedding模型。&lt;/p&gt;
&lt;h1 id="提前准备"&gt;提前准备&lt;/h1&gt;
&lt;h3 id="1-安装环境"&gt;1. 安装环境&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;conda create &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;n graphrag3&lt;span style="color:#bd93f9"&gt;.10&lt;/span&gt; python&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;3.10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;oonda activate graphrag3&lt;span style="color:#bd93f9"&gt;.10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-准备好ollama模型"&gt;2. 准备好ollama模型&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;ollama run qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="使用步骤"&gt;使用步骤&lt;/h1&gt;
&lt;h3 id="1-下载graphrag"&gt;1. 下载graphrag&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;git clone git@github.com:microsoft&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;graphrag&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;git
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cd graphrag
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;pip install &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;e&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-初始化"&gt;2. 初始化&lt;/h3&gt;
&lt;p&gt;准备数据输入文件夹&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;mkdir &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;p &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;graphrag_sophia&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;input&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# 注意一定要建立一个input子文件夹，在创建索引的时候会去识别这个名字。如果是其他名字，可以在settings.yaml更改&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;初始化&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;python &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;m graphrag init &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;root &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;graphrag_sophia
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看见在graphrag_sophia下生成settings.yaml和prompts文件夹。
这一步还需要把要把*.txt文件放入input文件夹中&lt;/p&gt;
&lt;h3 id="3-生成索引"&gt;3. 生成索引&lt;/h3&gt;
&lt;p&gt;3.1 准备数据
先准备数据，在graph_rag文件夹新建input，将.txt文件放进去。如果手头没有.txt文件，可以用官方提供的文件。
mkdir -p ./input （注意一定要建立一个input子文件夹，在创建索引的时候会去识别这个名字。如果是其他名字，可以在settings.yaml更改）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;curl https:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;www&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gutenberg&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;org&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;cache&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;epub&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;24022&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;pg24022&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;txt &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;o &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;data&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;test&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;book&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.2 设置workspace variables&lt;/p&gt;
&lt;p&gt;我在查阅资料的过程中，发现很多人的settings.yaml是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model: qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;11434&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model_supports_json: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;max_tokens: &lt;span style="color:#bd93f9"&gt;32768&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在配置这一步卡了很久，反复报错。原因是新版必须包含三个字段：default_chat_model、type和api_key。官网没给示例，我试了很多写法都不对，估计是因为版本差异。现在我的解决方式是：在.env和settings.yaml里分别设置api_base和api_key。&lt;/p&gt;
&lt;p&gt;我这里的设置：在.env文件中GRAPHRAG_API_KEY=&amp;lt;API_KEY&amp;gt;
settings.yaml文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### This config file contains required core defaults that must be set, along with a handful of common optional settings.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### For a full list of available settings, see https://microsoft.github.io/graphrag/config/yaml/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### LLM settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## There are a number of settings to tune the threading and token limits for LLM calls - check the docs.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;models:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_chat_model:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: openai_chat &lt;span style="color:#6272a4"&gt;# or azure_openai_chat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;11434&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; auth_type: api_key &lt;span style="color:#6272a4"&gt;# or azure_managed_identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_key: ollama &lt;span style="color:#6272a4"&gt;# set this in the generated .env file&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model: qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoding_model: cl100k_base &lt;span style="color:#6272a4"&gt;# automatically set by tiktoken if left undefined&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_supports_json: true &lt;span style="color:#6272a4"&gt;# recommended if this is available for your model.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; concurrent_requests: &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# max number of simultaneous LLM requests allowed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; async_mode: threaded &lt;span style="color:#6272a4"&gt;# or asyncio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retry_strategy: native
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_retries: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokens_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; requests_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_embedding_model:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: openai_embedding &lt;span style="color:#6272a4"&gt;# or azure_openai_embedding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;8005&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;api&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; auth_type: api_key &lt;span style="color:#6272a4"&gt;# or azure_managed_identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_key: ollama
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model: bge
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoding_model: cl100k_base &lt;span style="color:#6272a4"&gt;# automatically set by tiktoken if left undefined&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_supports_json: true &lt;span style="color:#6272a4"&gt;# recommended if this is available for your model.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; concurrent_requests: &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# max number of simultaneous LLM requests allowed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; async_mode: threaded &lt;span style="color:#6272a4"&gt;# or asyncio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retry_strategy: native
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_retries: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokens_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; requests_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Input settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;input&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# or blob&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; file_type: text &lt;span style="color:#6272a4"&gt;# [csv, text, json]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;input&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chunks:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; size: &lt;span style="color:#bd93f9"&gt;200&lt;/span&gt; &lt;span style="color:#6272a4"&gt;#1200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; overlap: &lt;span style="color:#bd93f9"&gt;50&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# 100 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; group_by_columns: [&lt;span style="color:#8be9fd;font-style:italic"&gt;id&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Output/storage settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## If blob storage is specified in the following four sections,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## connection_string and container_name must be provided&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;output:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;output&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cache:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;cache&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;reporting:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;logs&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;vector_store:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_vector_store:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: lancedb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; db_uri: output\lancedb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; container_name: default
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; overwrite: &lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Workflow settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;embed_text:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; vector_store_id: default_vector_store
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/extract_graph.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; entity_types: [organization,person,geo,event]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_gleanings: &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;summarize_descriptions:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/summarize_descriptions.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_length: &lt;span style="color:#bd93f9"&gt;500&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_graph_nlp:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text_analyzer:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; extractor_type: regex_english &lt;span style="color:#6272a4"&gt;# [regex_english, syntactic_parser, cfg]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cluster_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_cluster_size: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_claims:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/extract_claims.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; description: &lt;span style="color:#f1fa8c"&gt;&amp;#34;Any claims or facts that could be relevant to information discovery.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_gleanings: &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;community_reports:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; graph_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/community_report_graph.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/community_report_text.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_length: &lt;span style="color:#bd93f9"&gt;2000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_input_length: &lt;span style="color:#bd93f9"&gt;8000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;embed_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false &lt;span style="color:#6272a4"&gt;# if true, will generate node2vec embeddings for nodes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;umap:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false &lt;span style="color:#6272a4"&gt;# if true, will generate UMAP embeddings for nodes (embed_graph must also be enabled)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;snapshots:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; graphml: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Query settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## The prompt locations are required here, but each search method has a number of optional knobs that can be tuned.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## See the config docs: https://microsoft.github.io/graphrag/config/yaml/#query&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;local_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/local_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;global_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; map_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_map_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; reduce_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_reduce_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; knowledge_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_knowledge_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;drift_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/drift_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; reduce_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/drift_search_reduce_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;basic_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/basic_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.2 生成索引
这个过程非常非常慢，且token的消耗巨大。（在chunk_length为100的情况下，final_documents每100个14分钟，extract_graph一个小时进度35%）&lt;/p&gt;</description></item><item><title>2025-06-26 论文阅读 Qwen3 Embedding</title><link>https://huizhixu.github.io/chs/know_how/20250626%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBqwen3-embedding/</link><pubDate>Thu, 26 Jun 2025 13:55:03 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250626%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBqwen3-embedding/</guid><description>&lt;p&gt;论文地址：https://arxiv.org/pdf/2506.05176&lt;/p&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;基于合成数据的multi-stage训练&lt;/li&gt;
&lt;li&gt;构建高质量合成数据&lt;/li&gt;
&lt;li&gt;引入模型合并（model merging）&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="模型"&gt;模型&lt;/h2&gt;
&lt;h3 id="embedding-models"&gt;Embedding Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;所有嵌入模型均基于 Qwen3 基座大模型构建；&lt;/li&gt;
&lt;li&gt;使用带因果注意力（causal attention）的解码式架构；&lt;/li&gt;
&lt;li&gt;在输入序列的末尾添加 [EOS]，使用其最终一层 hidden state 作为 embedding 表示；&lt;/li&gt;
&lt;li&gt;支持带指令输入（instruction），格式为： {Instruction} {Query}&amp;lt;|endoftext|&amp;gt;；&lt;/li&gt;
&lt;li&gt;官方实验显示：相比无 instruction，指令式输入能显著提升效果；&lt;/li&gt;
&lt;li&gt;支持 MRL。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="reranking-models"&gt;Reranking Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;采用 point-wise reranking with LLMs within a single context：point-wise reranking是指 大型语言模型会对每个候选项单独评估其与查询的相关性，给出一个分数，然后根据这些分数进行排序。&lt;/li&gt;
&lt;li&gt;支持 instruction 输入，prompt 格式如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;system
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Judge whether the Document meets the requirements based on the Query and the
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Instruct provided. Note that the answer can only be &amp;#34;yes&amp;#34; or
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;#34;no&amp;#34;.&amp;lt;|im_end|&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;, →, →
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;user
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Instruct&amp;gt;: {Instruction}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Query&amp;gt;: {Query}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Document&amp;gt;: {Document}&amp;lt;|im_end|&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;assistant
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;think&amp;gt;\n\n&amp;lt;/think&amp;gt;\n\n
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="训练"&gt;训练&lt;/h2&gt;
&lt;h3 id="训练目标"&gt;训练目标&lt;/h3&gt;
&lt;p&gt;Embedding 模型采用 InfoNCE 对比损失&lt;/p&gt;</description></item><item><title>2025-06-20 去看音乐剧《Six》啦</title><link>https://huizhixu.github.io/chs/life/20250620%E5%8E%BB%E7%9C%8B%E9%9F%B3%E4%B9%90%E5%89%A7six%E5%95%A6/</link><pubDate>Fri, 20 Jun 2025 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250620%E5%8E%BB%E7%9C%8B%E9%9F%B3%E4%B9%90%E5%89%A7six%E5%95%A6/</guid><description>&lt;p&gt;超级开心，和同学去美琪大戏院看了音乐剧《Six》，这部来自伦敦西区的音乐剧，讲述的是亨利八世六位妻子的故事。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250620/1.jpg" alt="1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;这六位妻子的故事可以用六个词来概括——“Divorced. Beheaded. Died. Divorced. Beheaded. Survived.”（离婚、斩首、死亡、离婚、斩首、幸存）。六个妻子中，两个离婚，两个被斩首，一个自然死亡，一个幸存，她们把这场演出称为“离婚斩首演唱会”。&lt;/p&gt;</description></item><item><title>2025-06-16 Weaviate使用（四） RAG的两种处理方法</title><link>https://huizhixu.github.io/chs/know_how/20250616weaviate%E4%BD%BF%E7%94%A8_rag%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 16 Jun 2025 12:50:37 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250616weaviate%E4%BD%BF%E7%94%A8_rag%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;执行RAG操作过程中，对检索到的条目有两种处理方法：一种是single_prompt，另一种是grouped_tasks。&lt;/p&gt;
&lt;p&gt;grouped_task是对所有检索到的条目做一个整体的处理，例如&amp;quot;write a tweet about these facts&amp;quot;， &amp;ldquo;what do these movies have in common?&amp;quot;。&lt;/p&gt;
&lt;p&gt;single_prompt是对每一个检索到的object应用prompt。例如&amp;quot;translate this into French:{title}&amp;quot;。&lt;/p&gt;
&lt;h2 id="single-prompt"&gt;Single prompt&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;# Single prompt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;response &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; movies&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;generate&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;near_vector(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; near_vector&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;query_vector,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; limit&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; single_prompt &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Translate this into French:&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{title}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; o &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; response&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;objects:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(o&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;properties[&lt;span style="color:#f1fa8c"&gt;&amp;#34;title&amp;#34;&lt;/span&gt;]) &lt;span style="color:#6272a4"&gt;# Print the title&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(o&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;generated) &lt;span style="color:#6272a4"&gt;# Print the generated text (the title, in French)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结果为&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;I, Robot
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The translation of &lt;span style="color:#f1fa8c"&gt;&amp;#34;I, Robot&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; French &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Je, robot&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Looper
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The word &lt;span style="color:#f1fa8c"&gt;&amp;#34;Looper&amp;#34;&lt;/span&gt; translates to &lt;span style="color:#f1fa8c"&gt;&amp;#34;Loupé&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; French&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从结果可以看出，找出来两个数据”I, Robot”和”Looper”，并且分别翻译成法语。&lt;/p&gt;</description></item><item><title>2025-06-15 Weaviate使用（三） 两种导入数据的方法</title><link>https://huizhixu.github.io/chs/know_how/20250615weaviate%E4%BD%BF%E7%94%A8_%E4%B8%A4%E7%A7%8D%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/</link><pubDate>Sun, 15 Jun 2025 12:50:36 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250615weaviate%E4%BD%BF%E7%94%A8_%E4%B8%A4%E7%A7%8D%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;在导入的时候，可以先生成embedding，写入csv，然后在add_batch的时候添加。另外一种方法是在导入的时候直接embedding。&lt;/p&gt;
&lt;h2 id="第一种方法"&gt;第一种方法&lt;/h2&gt;
&lt;h3 id="先创建集合create-collection"&gt;先创建集合：Create collection&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate.classes.config &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; wc
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; weaviate.classes.config &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; Configure
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; weaviate&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;connect_to_local()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;# client.collections.delete(&amp;#34;MovieCustomVector&amp;#34;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;collections&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;create(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;MovieCustomVector&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; properties&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;title&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;TEXT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;overview&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;TEXT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;vote_average&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;NUMBER),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;genre_ids&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;INT_ARRAY),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;release_date&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DATE),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;tmdb_id&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;INT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; vectorizer_config&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;Configure&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Vectorizer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;none(),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; generative_config&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;Configure&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Generative&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;ollama(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_endpoint&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;http://host.docker.internal:11434&amp;#34;&lt;/span&gt;, model&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;llama3.2&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;close()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="对文本向量化和存储embed_text"&gt;对文本向量化和存储：embed_text&lt;/h3&gt;
&lt;p&gt;这一步组合标题和概述的内容作为要向量化的文本，向量化之后存为csv。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; pandas &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; FlagEmbedding &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; BGEM3FlagModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;generate_embeddings&lt;/span&gt;(df: pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame, batch_size: &lt;span style="color:#8be9fd;font-style:italic"&gt;int&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;&amp;#34;&amp;#34;生成文本的向量表示
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; Args:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; df: 包含电影数据的DataFrame
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; batch_size: 批处理大小
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; Returns:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; DataFrame: 包含所有embeddings的DataFrame
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BGEM3FlagModel(&lt;span style="color:#f1fa8c"&gt;&amp;#34;BAAI/bge-m3&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_dfs &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 批量处理文本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; i, row &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;enumerate&lt;/span&gt;(df&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;itertuples(index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 组合标题和概述&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;f&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;Title: &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{&lt;/span&gt;row&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;title&lt;span style="color:#f1fa8c"&gt;}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;;Overview: &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{&lt;/span&gt;row&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;overview&lt;span style="color:#f1fa8c"&gt;}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(text)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(i)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 达到批处理大小或处理完所有数据时进行向量化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(src_texts) &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; batch_size &lt;span style="color:#ff79c6"&gt;or&lt;/span&gt; i &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(df):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; model&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encode(src_texts)[&lt;span style="color:#f1fa8c"&gt;&amp;#34;dense_vecs&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame(embeddings, index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;indices)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_dfs&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(emb_df)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;concat(emb_dfs)&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;sort_index()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;main&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;&amp;#34;&amp;#34;主函数，处理电影数据并生成向量&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 读取数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; data_path &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;path&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;join(os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;path&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;dirname(&lt;span style="color:#8be9fd;font-style:italic"&gt;__file__&lt;/span&gt;), &lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch/movies_data_1990_2024.json&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;read_json(data_path)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 生成向量并保存&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings_df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; generate_embeddings(df)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;makedirs(&lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch&amp;#34;&lt;/span&gt;, exist_ok&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings_df&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;to_csv(&lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch/movies_data_1990_2024_embeddings.csv&amp;#34;&lt;/span&gt;, index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;__name__&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; main()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="导入数据import-data"&gt;导入数据：Import data&lt;/h3&gt;
&lt;p&gt;在导入数据(batch.add_object)的时候需要把 vector和property分别写入。另外uuid是数据库为每一条数据创建的不重复的id。&lt;/p&gt;</description></item><item><title>2025-06-14 Weaviate使用（二） 使用自定义模型</title><link>https://huizhixu.github.io/chs/know_how/20250614weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 14 Jun 2025 12:50:33 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250614weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;如果不想用Ollama启用的向量模型，想用自定义的模型有多种方法，下面介绍两种：一种是通过huggingface或者其他的框架导入，另一种是直接调用已有的向量调用的服务（例如用FastAPI启动）。&lt;/p&gt;
&lt;p&gt;把向量服务或者大模型封装成服务的好处是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;功能解耦：大模型服务或者向量服务独立出来，在替换的时候无需更改代码&lt;/li&gt;
&lt;li&gt;环境解耦：大模型服务通常需要更多的资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这时的docker compose file 非常简单，不再需要ENABLE_MODULES: &amp;rsquo;text2vec-ollama,generative-ollama&amp;rsquo; 这一行。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;---&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;services&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; command&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;host
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;port
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;8080&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;scheme
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; http
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; image&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; cr.weaviate.io&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;semitechnologies&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1.30&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ports&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;/var/lib/weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; restart&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; on&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;failure&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; environment&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; QUERY_DEFAULTS_LIMIT&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; PERSISTENCE_DATA_PATH&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;/var/lib/weaviate&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_API_BASED_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; CLUSTER_HOSTNAME&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;node1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="通过hugging-face导入"&gt;通过hugging face导入&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def vectorize(texts&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; List[str])&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; from FlagEmbedding &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; BGEM3FlagModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BGEM3FlagModel(&lt;span style="color:#f1fa8c"&gt;&amp;#39;BAAI/bge-m3&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; model.encode(texts)[&lt;span style="color:#f1fa8c"&gt;&amp;#34;dense_vecs&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; embeddings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="通过api调用"&gt;通过API调用&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; CustomEmbedding(EmbedGen)&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; def generate_embeddings(self, texts&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; List[str]) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; np.array&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; requests
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; json
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; payload &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; json.dumps(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; texts,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; )
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; headers &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; {&lt;span style="color:#f1fa8c"&gt;&amp;#34;Content-Type&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;application/json&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; response &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; requests.request(&lt;span style="color:#f1fa8c"&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;, url&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;EMBED_URL, headers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;headers, data&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;payload)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; [i[&lt;span style="color:#f1fa8c"&gt;&amp;#34;embedding&amp;#34;&lt;/span&gt;] &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; i &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; response.json()[&lt;span style="color:#f1fa8c"&gt;&amp;#34;data&amp;#34;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; np.array(embeddings)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; embeddings
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description></item><item><title>2025-06-13 论文阅读BGE-M3</title><link>https://huizhixu.github.io/chs/know_how/20250613%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBbge-m3/</link><pubDate>Fri, 13 Jun 2025 12:50:30 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250613%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBbge-m3/</guid><description>&lt;p&gt;论文地址：https://arxiv.org/abs/2402.03216&lt;/p&gt;
&lt;p&gt;M3的意思是 Multi-Linguality, Multi-Functionality和Multi-Granularity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持100种语言（multi-lingual, cross-lingual)&lt;/li&gt;
&lt;li&gt;支持短句和长文档，最高到8192tokesn&lt;/li&gt;
&lt;li&gt;支持不同的检索方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250613/d5b741c9.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;(图来源于论文)&lt;/p&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;实现了自知识蒸馏，将来自不同检索功能的相关性分数集成到教师信号，从而提高训练质量。&lt;/li&gt;
&lt;li&gt;优化了批处理策略，实现较大的批处理大小和高训练吞吐量，以提高Embedding的区分能力。&lt;/li&gt;
&lt;li&gt;用data curation来得到高质量的数据&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="不同的向量检索方法"&gt;不同的向量检索方法&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[CLS]用来做dense retrieval&lt;/li&gt;
&lt;li&gt;其他token的向量用来做sparse retrieval 和multi-vector retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dataset-sources"&gt;Dataset sources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;extract the unsupervised data from massive multi-lingual corpora&lt;/li&gt;
&lt;li&gt;Integrate the closely related supervised data&lt;/li&gt;
&lt;li&gt;Synthesize the scarce data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="self-knowledge-distillation"&gt;Self-Knowledge Distillation&lt;/h2&gt;
&lt;p&gt;InfoNCE loss 的目标是最大化正样本对的相似度，同时最小化负样本对的相似度。&lt;/p&gt;
&lt;p&gt;InfoNCE loss的计算&lt;/p&gt;
&lt;p&gt;$$Loss= -log \frac{ \exp(sim(x_i,x_i^+)/\tau) }{\sum_{j=1}^K \exp(sim(x_i, x_i^{-j})/\tau) }$$&lt;/p&gt;
&lt;p&gt;假设我们有一个数据集，其中每个样本 xi 有一个对应的正样本 $$x_i^+$$ 和多个负样本 $$x_i^{-1}, x_i^{-2}, &amp;hellip;, x_i^{-K} $$。&lt;/p&gt;
&lt;p&gt;对于每个样本 $$x_i$$，我们希望其与正样本 $$x_i^+ $$的相似度尽可能高。&lt;/p&gt;</description></item><item><title>2025-06-12 Weaviate使用（一） 使用ollama启用大模型和向量模型</title><link>https://huizhixu.github.io/chs/know_how/20250612weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8ollama%E5%90%AF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B/</link><pubDate>Thu, 12 Jun 2025 12:50:29 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250612weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8ollama%E5%90%AF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B/</guid><description>&lt;h2 id="先决条件"&gt;先决条件&lt;/h2&gt;
&lt;p&gt;在本地用docker-compose.yml部署Weaviate。因为使用Ollama来启动模型，所以在配置文件中要加上ENABLE_MODULES: &amp;rsquo;text2vec-ollama,generative-ollama'&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;---&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;services&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; command&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;host
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;port
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;8080&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;scheme
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; http
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; image&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; cr.weaviate.io&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;semitechnologies&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1.30&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ports&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;/var/lib/weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; restart&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; on&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;failure&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; environment&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; QUERY_DEFAULTS_LIMIT&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; PERSISTENCE_DATA_PATH&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;/var/lib/weaviate&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_API_BASED_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;text2vec-ollama,generative-ollama&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; CLUSTER_HOSTNAME&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;node1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在本地安装启动Weaviate之后，运行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; weaviate.connect_to_local()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(client.is_ready())
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;True表示这个数据库是可用的。&lt;/p&gt;
&lt;h2 id="准备数据"&gt;准备数据&lt;/h2&gt;
&lt;p&gt;下面是jeopardy_tiny.json的例子&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;SCIENCE&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;This organ removes excess glucose from the blood &amp;amp; stores it as glycogen&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Liver&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;ANIMALS&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;It&amp;#39;s the only living mammal in the order Proboseidea&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Elephant&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;ANIMALS&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;The gavial looks very much like a crocodile except for this bodily feature&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;the nose or snout&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="创建collection"&gt;创建collection&lt;/h2&gt;
&lt;p&gt;Ollama启动服务，api_endpoint统一为http://host.docker.internal:11434，模型根据模型名填写。&lt;/p&gt;</description></item><item><title>2025-06-07 漫长的五月</title><link>https://huizhixu.github.io/chs/life/20250607%E6%BC%AB%E9%95%BF%E7%9A%84%E4%BA%94%E6%9C%88/</link><pubDate>Sat, 07 Jun 2025 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250607%E6%BC%AB%E9%95%BF%E7%9A%84%E4%BA%94%E6%9C%88/</guid><description>&lt;p&gt;五月过得漫长得仿佛没有尽头，日子就像被拉长的橡皮筋，充满了各种挑战和忙碌。&lt;/p&gt;
&lt;h2 id="通勤的烦恼"&gt;&lt;strong&gt;通勤的烦恼&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;换了工作后，通勤距离一下子拉长了。地铁站离公司和家都有一段距离，我只能靠步行来填补这段空白。有一天，我突然发现，算上中午和同事外出吃饭，我下班到家时，一天的步数居然达到了7000步！&lt;/p&gt;</description></item><item><title>2025-04-17 我辞职了，但我对旷野没有兴趣</title><link>https://huizhixu.github.io/chs/life/20250417%E6%88%91%E8%BE%9E%E8%81%8C%E4%BA%86%E4%BD%86%E6%88%91%E6%B2%A1%E6%9C%89%E5%AF%BB%E6%89%BE%E6%97%B7%E9%87%8E/</link><pubDate>Thu, 17 Apr 2025 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250417%E6%88%91%E8%BE%9E%E8%81%8C%E4%BA%86%E4%BD%86%E6%88%91%E6%B2%A1%E6%9C%89%E5%AF%BB%E6%89%BE%E6%97%B7%E9%87%8E/</guid><description>&lt;p&gt;我辞职了，但我对旷野没有兴趣，我在寻找新的轨道。以下是一些我在找工作时的日志和记录。&lt;/p&gt;
&lt;p&gt;找工作是一次修行。其中的艰辛、烦闷与压力，只有经历过才能s体会。可以看到我的记录中，无数次地安慰自己，给自己打气，对自己说：“不要放弃，坚持下去。” 现在回首，告诉自己，既然又回到了轨道，那就再坚持坚持吧。&lt;/p&gt;</description></item><item><title>2025-04-13 扬州踏春记</title><link>https://huizhixu.github.io/chs/life/20250413%E6%89%AC%E5%B7%9E%E8%B8%8F%E6%98%A5%E8%AE%B0/</link><pubDate>Sun, 13 Apr 2025 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250413%E6%89%AC%E5%B7%9E%E8%B8%8F%E6%98%A5%E8%AE%B0/</guid><description>&lt;p&gt;去年冬天，小爽约我今年三四月份去扬州逛逛，我没去过扬州，听着觉得很不错，于是答应下来。&lt;/p&gt;
&lt;p&gt;三月初，她跟我说机票和酒店都订好了，让我买上海过去的高铁票，再看看扬州的攻略。于是我们就在一个天气巨好的时节，到了扬州。&lt;/p&gt;</description></item><item><title>2025-03-14 读《来自巫师档案》——《哈利·波特》的B面故事</title><link>https://huizhixu.github.io/chs/life/20250314_from_the_wizarding_archive/</link><pubDate>Fri, 14 Mar 2025 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250314_from_the_wizarding_archive/</guid><description>&lt;p&gt;&lt;img src="../img/20250314/1.png" alt="legende"&gt;&lt;/p&gt;
&lt;p&gt;微信读书上去年上了J.K.罗琳的新书——《来自巫师档案》，一直想看来着，最近终于把第一卷看完啦。&lt;/p&gt;
&lt;p&gt;读完这本书，我对《哈利·波特》魔法世界的幕后故事有了更深的了解。书中不仅揭示了波特家族和马尔福家族的历史，还让我对德拉科·马尔福、佩妮阿姨和洛哈特教授有了全新的认识。（书中还有更多魔法世界的设定细节，例如魔杖，巫师的出行方式，世界上其他地方的巫师是怎样的等等。）&lt;/p&gt;</description></item><item><title>2025-02-26 重看《花样年华》，依旧美到窒息</title><link>https://huizhixu.github.io/chs/life/20250226%E9%87%8D%E7%9C%8B%E8%8A%B1%E6%A0%B7%E5%B9%B4%E5%8D%8E%E4%BE%9D%E6%97%A7%E7%BE%8E%E5%88%B0%E7%AA%92%E6%81%AF/</link><pubDate>Wed, 26 Feb 2025 12:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250226%E9%87%8D%E7%9C%8B%E8%8A%B1%E6%A0%B7%E5%B9%B4%E5%8D%8E%E4%BE%9D%E6%97%A7%E7%BE%8E%E5%88%B0%E7%AA%92%E6%81%AF/</guid><description>&lt;p&gt;&lt;img src="../img/20250226/1.png" alt="legende"&gt;&lt;/p&gt;
&lt;p&gt;第一次看这部电影我才十几岁，那时候的我只觉得电影里的一切都充满了高级感——演员的颜值、粤语的韵味、旗袍的优雅、香港街景的浪漫。还有那句经典的台词“如果我多一张船票，你会不会跟我走？”，一听就是一个绝美BE爱情故事。&lt;/p&gt;</description></item><item><title>2025-01-25 花园属于打理花园的人</title><link>https://huizhixu.github.io/chs/life/20250125%E6%80%BB%E7%BB%932024/</link><pubDate>Sat, 25 Jan 2025 12:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20250125%E6%80%BB%E7%BB%932024/</guid><description>&lt;p&gt;今年最大的变化是，我慢慢熟悉了上海这座城市，不再像前两年那样紧绷和陌生。生活逐渐有了新的节奏，也让我有更多机会去感受和思考。&lt;/p&gt;
&lt;p&gt;今年的关键词有三个：离别、爱和反思。&lt;/p&gt;</description></item><item><title>2024-12-30 缓解去东北的焦虑</title><link>https://huizhixu.github.io/chs/life/20241230%E7%BC%93%E8%A7%A3%E5%8E%BB%E4%B8%9C%E5%8C%97%E7%9A%84%E7%84%A6%E8%99%91/</link><pubDate>Mon, 30 Dec 2024 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20241230%E7%BC%93%E8%A7%A3%E5%8E%BB%E4%B8%9C%E5%8C%97%E7%9A%84%E7%84%A6%E8%99%91/</guid><description>&lt;p&gt;虽然今天是个工作日，但是我裸辞了，吞吞休年假。我们约好今天一起喝下午茶，好好放松一下。&lt;/p&gt;
&lt;p&gt;这次我提前做了功课，选的店是《好东西》导演邵艺辉推荐的一家店，叫“茶是一枝花”。听说这家店的环境很雅致，茶点也很有特色，特别适合悠闲的下午时光。&lt;/p&gt;</description></item><item><title>2024-08-29 最近在工作里遇到的好玩的</title><link>https://huizhixu.github.io/chs/life/20240829%E6%9C%80%E8%BF%91%E5%9C%A8%E5%B7%A5%E4%BD%9C%E9%87%8C%E9%81%87%E5%88%B0%E7%9A%84%E5%A5%BD%E7%8E%A9%E7%9A%84/</link><pubDate>Thu, 29 Aug 2024 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240829%E6%9C%80%E8%BF%91%E5%9C%A8%E5%B7%A5%E4%BD%9C%E9%87%8C%E9%81%87%E5%88%B0%E7%9A%84%E5%A5%BD%E7%8E%A9%E7%9A%84/</guid><description>&lt;p&gt;最近在工作中遇到一些好玩的东西，还蛮有意思的。&lt;/p&gt;
&lt;h4 id="1-腾讯元宝"&gt;1. 腾讯元宝&lt;/h4&gt;
&lt;p&gt;现在论文简直是如雨后春笋般冒出来，多得让人眼花缭乱。要是想快速过一遍或者抓住重点，我强烈推荐腾讯元宝。真不是夸张，这玩意儿简直是我遇到的论文阅读神器！&lt;/p&gt;</description></item><item><title>2024-08-19 西西弗斯的命运</title><link>https://huizhixu.github.io/chs/life/20240819%E8%A5%BF%E8%A5%BF%E5%BC%97%E6%96%AF%E7%9A%84%E5%91%BD%E8%BF%90/</link><pubDate>Mon, 19 Aug 2024 21:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240819%E8%A5%BF%E8%A5%BF%E5%BC%97%E6%96%AF%E7%9A%84%E5%91%BD%E8%BF%90/</guid><description>&lt;p&gt;人如何能避免西西弗斯的命运呢？这是我最近意识到的问题。&lt;/p&gt;
&lt;p&gt;以前读到这个神话故事时，不明白西西弗斯为什么能坚持每天把石头推上山，做一些无用功。&lt;/p&gt;
&lt;p&gt;但我最近突然发现，我也在做同样的事情。&lt;/p&gt;</description></item><item><title>2024-07-31 浮云散，明月照人来</title><link>https://huizhixu.github.io/chs/life/20240731%E6%98%8E%E6%9C%88%E7%85%A7%E4%BA%BA%E6%9D%A5/</link><pubDate>Wed, 31 Jul 2024 21:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240731%E6%98%8E%E6%9C%88%E7%85%A7%E4%BA%BA%E6%9D%A5/</guid><description>&lt;p&gt;&lt;img src="../img/20240731/fuyunsan.png" alt="fuyunsan"&gt;&lt;/p&gt;
&lt;p&gt;历时一个月，我终于看完了这本书。&lt;/p&gt;
&lt;p&gt;《北平无战事》是一部引人深思的作品。我之前看过同名电视剧，崔叔和周璇版的《花好月圆》故事令我难以忘怀。但直到这次细读，我才真正理解了这部作品想要传达的深意。&lt;/p&gt;</description></item><item><title>2024-07-15 我们喜欢的球员都退役了</title><link>https://huizhixu.github.io/chs/life/20240715%E5%96%9C%E6%AC%A2%E7%9A%84%E7%90%83%E5%91%98%E4%BB%AC%E9%83%BD%E9%80%80%E5%BD%B9%E4%BA%86/</link><pubDate>Mon, 15 Jul 2024 21:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240715%E5%96%9C%E6%AC%A2%E7%9A%84%E7%90%83%E5%91%98%E4%BB%AC%E9%83%BD%E9%80%80%E5%BD%B9%E4%BA%86/</guid><description>&lt;p&gt;7月6日，欧洲杯八分之一决赛，德国不敌西班牙，出局。&lt;/p&gt;
&lt;p&gt;楚噶喜欢了十几年的克罗斯在赛后宣布退役。克罗斯是德国最伟大的球员之一。&lt;/p&gt;
&lt;p&gt;&lt;img src="../img/20240715/kross.png" alt="legende"&gt;&lt;/p&gt;
&lt;p&gt;7月9日，我最喜欢的球员蒂亚戈宣布退役。&lt;/p&gt;</description></item><item><title>2024-07-04 情绪解码：看《头脑特工队》2</title><link>https://huizhixu.github.io/chs/life/20240704%E6%83%85%E7%BB%AA%E8%A7%A3%E7%A0%81%E7%9C%8B%E5%A4%B4%E8%84%91%E7%89%B9%E5%B7%A5%E9%98%9F2/</link><pubDate>Thu, 04 Jul 2024 21:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240704%E6%83%85%E7%BB%AA%E8%A7%A3%E7%A0%81%E7%9C%8B%E5%A4%B4%E8%84%91%E7%89%B9%E5%B7%A5%E9%98%9F2/</guid><description>&lt;p&gt;某天，一位朋友向我推荐《头脑特工队》2，她告诉我，这部电影让她心中的焦虑减轻了不少。作为一个曾经也深受焦虑困扰的人，我在某个下班后的傍晚，坐下来观看这部电影。&lt;/p&gt;</description></item><item><title>2024-05-25 用大模型理解爆火的KAN网络</title><link>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</link><pubDate>Sat, 25 May 2024 16:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</guid><description>&lt;p&gt;五一假期的时候，KAN突然成为了热门话题。虽然最初我并没有计划弄懂它，但在老板的要求下，我还是探索了一下。&lt;/p&gt;
&lt;h2 id="一kan是什么"&gt;一、KAN是什么？&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Kolmogorov-Arnold 定理是数学领域的一个里程碑，它揭示了多元函数能够通过一组更简单的函数来近似表示的原理。&lt;/strong&gt; 在神经网络的研究领域，来自 MIT 的杰出研究者 Ziming Liu 将这一定理巧妙地融入，提出了创新的 KANs（&lt;strong&gt;Kolmogorov-Arnold Networks&lt;/strong&gt;）概念。（GitHub地址：https://github.com/KindXiaoming/pykan）。&lt;/p&gt;</description></item><item><title>2024-05-13 大型语言模型在「想」什么呢？ — 浅谈大型语言模型的可解释性</title><link>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</link><pubDate>Mon, 13 May 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</guid><description>&lt;p&gt;Explainable 和 Interpretable的区别：&lt;/p&gt;
&lt;p&gt;Explainable： 事物本身是黑箱，我们尝试去解释它的行为或输出。&lt;/p&gt;
&lt;p&gt;Interpretable： 事物本身不是黑箱，其工作原理是清晰和可以理解的。&lt;/p&gt;</description></item><item><title>2024-05-07 欧冠半决赛上海拜仁球迷会观赛</title><link>https://huizhixu.github.io/chs/life/20240507%E6%AC%A7%E5%86%A0%E5%8D%8A%E5%86%B3%E8%B5%9B%E4%B8%8A%E6%B5%B7%E6%8B%9C%E4%BB%81%E7%90%83%E8%BF%B7%E4%BC%9A%E8%A7%82%E8%B5%9B/</link><pubDate>Tue, 07 May 2024 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240507%E6%AC%A7%E5%86%A0%E5%8D%8A%E5%86%B3%E8%B5%9B%E4%B8%8A%E6%B5%B7%E6%8B%9C%E4%BB%81%E7%90%83%E8%BF%B7%E4%BC%9A%E8%A7%82%E8%B5%9B/</guid><description>&lt;p&gt;遥想 18 年，也是欧冠半决赛，也是拜仁对阵皇马，我和楚哥去柏林的一个拜仁酒吧看比赛，记得很清楚，别人喝的是啤酒，我俩只能点Alkoholfrei（无酒精饮料）。那个时候皇马运气真好，赢了拜仁，又赢了利物浦，蝉联三冠。&lt;/p&gt;</description></item><item><title>2024-04-24 上海生活——突然出现的隐藏宝石</title><link>https://huizhixu.github.io/chs/life/20240424%E4%B8%8A%E6%B5%B7%E7%94%9F%E6%B4%BB-%E7%AA%81%E7%84%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E9%9A%90%E8%97%8F%E5%AE%9D%E7%9F%B3/</link><pubDate>Wed, 24 Apr 2024 22:11:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240424%E4%B8%8A%E6%B5%B7%E7%94%9F%E6%B4%BB-%E7%AA%81%E7%84%B6%E5%87%BA%E7%8E%B0%E7%9A%84%E9%9A%90%E8%97%8F%E5%AE%9D%E7%9F%B3/</guid><description>&lt;p&gt;我平时不挑食，什么种类的菜都吃，但是一直在寻找地道的湘菜馆。&lt;/p&gt;
&lt;p&gt;上海商场里面的那些连锁湘菜馆，刚开始去感觉还不错，环境挺好，菜品端上来色香味俱全，看着挺正宗。但是去了两三次之后，就会发现问题——有的配料和食材不太对劲。&lt;/p&gt;</description></item><item><title>2024-04-22 用大语言模型打造AI Agent</title><link>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</link><pubDate>Mon, 22 Apr 2024 23:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</guid><description>&lt;p&gt;人类需要的不仅仅是大模型，而是能做复杂的多步骤的任务的大模型，Agent因此诞生了。&lt;/p&gt;
&lt;h1 id="知名的ai-agent"&gt;知名的AI Agent&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;1. AutoGPT: &lt;a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" rel="noopener"&gt;https://github.com/Significant-Gravitas/AutoGPT&lt;/a&gt;
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AutoGPT是一个由Significant Gravitas开发的开源项目,旨在创建一个自主的AI代理,能够持续地学习、成长并完成各种任务。&lt;/p&gt;</description></item><item><title>2024-04-17 再见英语PK台</title><link>https://huizhixu.github.io/chs/life/20240417%E5%86%8D%E8%A7%81%E8%8B%B1%E8%AF%ADpk%E5%8F%B0/</link><pubDate>Wed, 17 Apr 2024 20:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240417%E5%86%8D%E8%A7%81%E8%8B%B1%E8%AF%ADpk%E5%8F%B0/</guid><description>&lt;p&gt;一个月没有收听英语PK台了，今天晚上打开发现微信读书的公众号订阅，发现英语PK台发了一封告别信。原来在上个月，这个广播节目已经和大家告别了。&lt;/p&gt;
&lt;p&gt;英语PK台从我知道的那天起，一直是我学习英语的主要来源。因为它足够靠谱，足够用心，足够成为我的唯一的选择。&lt;/p&gt;</description></item><item><title>2024-04-14 让AI村民组成虚拟村庄会发生什么事</title><link>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</link><pubDate>Sun, 14 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</guid><description>&lt;p&gt;去年Agent很火的时候，就知道有斯坦福出的这个虚拟小镇的论文了，当时大家都很好奇，怎么能够让大语言模型来操纵agent做出非常复杂的行为呢？&lt;/p&gt;</description></item><item><title>2024-04-13 大型语言模型修炼史（第三阶段）</title><link>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</link><pubDate>Sat, 13 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</guid><description>&lt;h1 id="第三阶段参与实战打磨技巧"&gt;第三阶段：参与实战，打磨技巧&lt;/h1&gt;
&lt;p&gt;如何克服第二阶段的局限性呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键是用第一阶段的参数作为初始参数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（贝叶斯定理这不就来了嘛！）&lt;/p&gt;
&lt;p&gt;所以第三阶段是由第一阶段和第二阶段组合而成的：&lt;/p&gt;
&lt;p&gt;第一阶段：通过网络上任何语料学习而来的，叫做预训练Pretrain&lt;/p&gt;</description></item><item><title>2024-04-05 大型语言模型修炼史（第一、二阶段）</title><link>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</link><pubDate>Fri, 05 Apr 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</guid><description>&lt;h1 id="背景知识"&gt;背景知识&lt;/h1&gt;
&lt;p&gt;大模型的本质是文字接龙。输入一个未完成的句子，输出这个未完成的句子的下一个token。&lt;/p&gt;
&lt;p&gt;大模型可以看成是一个函数。$$ f(未完成的句子)= 下一个token $$这个函数是一个有数十亿个未知参数的函数。&lt;/p&gt;</description></item><item><title>2024-03-05 改进量的期望 Expected Improvement</title><link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link><pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid><description>&lt;p&gt;在看正文之前，先复习一下期望（Expectation）：&lt;/p&gt;
&lt;p&gt;在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。&lt;/p&gt;
&lt;p&gt;对于一个连续随机变量&lt;em&gt;X&lt;/em&gt;，其期望值可以通过以下公式计算：&lt;/p&gt;</description></item><item><title>2024-02-04 人生到处知何似，应似飞鸿踏雪泥</title><link>https://huizhixu.github.io/chs/life/20240204%E6%80%BB%E7%BB%932023/</link><pubDate>Sun, 04 Feb 2024 08:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20240204%E6%80%BB%E7%BB%932023/</guid><description>&lt;p&gt;当高德地图的导航又一次发出MOSS的提醒——“地球的勇士不会选择违章，请珍惜高级驾驶员资格”时，我才意识到，呀，距离《流浪地球》第二部的上映都快一年了。&lt;/p&gt;</description></item><item><title>2024-02-03 Bayesian Optimization</title><link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link><pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid><description>&lt;p&gt;贝叶斯优化有重要的两步步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造代理模型（surrogate model）&lt;/li&gt;
&lt;li&gt;由获取函数（acquisition function）来生成采样建议&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;贝叶斯优化中，因为不知道目标函数的closed-form，所以需要构造一个代理模型（surrogate model）来近似目标函数。记住，代理模型对目标函数的潜在分布进行建模。通常用gaussian process来作为代理模型，也可以用random forest来作为代理模型。（任何模型，只要它为函数提供后验估计，可以用来作为surrogate model）。&lt;/p&gt;</description></item><item><title>2024-02-22 grobid的使用</title><link>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;p&gt;最近被文本分块虐得不轻，看到有人介绍grobid，赶紧用上了。&lt;/p&gt;
&lt;h3 id="1-grobid-介绍"&gt;1. Grobid 介绍&lt;/h3&gt;
&lt;p&gt;Grobid 的全称是Generation of Bibliographic Data。它用机器学习来解析、提取文档。&lt;/p&gt;</description></item><item><title>2023-12-17 Gaussian Process Regression with GPyTorch</title><link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link><pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid><description>&lt;p&gt;这个例子主要是利用GPytorch，来实现高斯过程回归。&lt;/p&gt;
&lt;h1 id="计算mean"&gt;计算Mean&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;zero mean function &lt;code&gt;gpytorch.means.ZeroMean()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;constant mean function &lt;code&gt;gpytorch.means.ConstantMean()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;linear mean function &lt;code&gt;gpytorch.means.LinearMean()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="计算covariance"&gt;计算Covariance&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;RBFKernel &lt;code&gt;gpytorch.kernels.RBFKernel()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;adding a scaling coefficient: &lt;code&gt;kernels.ScaleKernel(gpytorch.kernels.RBFKernel())&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一般会在核函数的输出上添加缩放系数。&lt;/p&gt;
&lt;p&gt;在核函数的输出上添加缩放系数是为了调整核函数的影响力。&lt;/p&gt;</description></item><item><title>2023-12-10 Gaussian Process in Practice 高斯过程实践</title><link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link><pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid><description>&lt;p&gt;这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。&lt;/p&gt;
&lt;h2 id="1-先验分布"&gt;1. 先验分布&lt;/h2&gt;
&lt;h4 id="11-多变量高斯分布"&gt;1.1 多变量高斯分布&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;创建一个包含n个候选输入位置的列表${x_i，i=1,&amp;hellip;,n}$&lt;/li&gt;
&lt;li&gt;初始化均值向量μ和协方差矩阵K（含n x n个元素）
&lt;ul&gt;
&lt;li&gt;假设x_1和x_2是多维的矩阵。x_1是一个 m* d的矩阵，x_2是一个n&lt;em&gt;d的矩阵，那么K是一个m&lt;/em&gt;n的矩阵，$K[i,j] = k(x_1[i,:], x_2[j,:])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;执行Cholesky分解K=LL T来获得L&lt;/li&gt;
&lt;li&gt;通过LN（0,I）获得N（0,K）上的一个样本并存储在f_prior中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;multivariante_samples01 和multivariante_samples02 这两个function的作用是一样的，只不过有两种写法。&lt;/p&gt;</description></item><item><title>2023-12-07 Kernel Function 核函数</title><link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link><pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid><description>&lt;p&gt;这篇文章主要解决三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;正态分布的表示&lt;/li&gt;
&lt;li&gt;核函数是什么，有什么类型&lt;/li&gt;
&lt;li&gt;已知先验知识，如何计算后验分布&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="1-正态分布的表示"&gt;1. 正态分布的表示&lt;/h2&gt;
&lt;p&gt;正态分布一般表示为$f \sim N(0,K)$，书上写作 $p(f|x) = N(f|0,K)$。&lt;/p&gt;</description></item><item><title>2023-11-25 书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title><link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link><pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid><description>&lt;h2 id="1-理解covariance-matrix"&gt;1. 理解covariance matrix&lt;/h2&gt;
&lt;p&gt;Gaussian Process is a stochastic process used to characterize the distribution over function.&lt;/p&gt;
&lt;p&gt;GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。&lt;/p&gt;
&lt;p&gt;假设我们有两个变量，X1和X2，它俩符合multivariate Gaussian distribution。&lt;/p&gt;</description></item><item><title>2023-11-20 论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title><link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link><pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid><description>&lt;p&gt;Abstract&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;types
&lt;ul&gt;
&lt;li&gt;第一种分类
&lt;ul&gt;
&lt;li&gt;data uncertainty (measurement noise)&lt;/li&gt;
&lt;li&gt;model uncertainty ( limited data)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;第二种分类
&lt;ul&gt;
&lt;li&gt;epistemic uncertainty
&lt;ul&gt;
&lt;li&gt;认知上的不确定性，通常是由于没有足够的知识（数据）而产生&lt;/li&gt;
&lt;li&gt;can be reducible&lt;/li&gt;
&lt;li&gt;分为两类
&lt;ul&gt;
&lt;li&gt;model-form uncertainty
&lt;ul&gt;
&lt;li&gt;由于模型的选择导致，例如architectures, activation functions or kernel functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;parameter uncertainty
&lt;ul&gt;
&lt;li&gt;在训练过程产生，由于数据不够导致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;aleatory uncertainty
&lt;ul&gt;
&lt;li&gt;stems from physical systems, 具有随机性, cannot be reducible&lt;/li&gt;
&lt;li&gt;e.g. noises&lt;/li&gt;
&lt;li&gt;这种类型的不确定性在ML模型里面被看成是似然函数的一部分(a part of the likelihood function)&lt;/li&gt;
&lt;li&gt;也被叫做data uncertainty&lt;/li&gt;
&lt;li&gt;捕捉这种不确定性的方式有：同方差 homoscedastic和异方差 heteroscedastic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例子：
&lt;ul&gt;
&lt;li&gt;test data和train data不同分布：epistemic uncertainty (model performs poorer in extrapolation than in interpolation)&lt;/li&gt;
&lt;li&gt;测量数据由仪器导致的误差是aleatory Unc， 大试如果由于精度原因导致，则属于epistemic unc，因为提高精度可以减少这个误差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;causes&lt;/li&gt;
&lt;li&gt;methods:
&lt;ul&gt;
&lt;li&gt;Gaussian process regression
&lt;ul&gt;
&lt;li&gt;a ML method with UQ capability&lt;/li&gt;
&lt;li&gt;一般不用来quantify uncertainty of a final surrogate&lt;/li&gt;
&lt;li&gt;一般用来在高度不确定的采样空间里采样，来减少训练样本的数量
&lt;ul&gt;
&lt;li&gt;to build an accurate surrogate within some lower and upper bounds of input variables&lt;/li&gt;
&lt;li&gt;to find a globally optimally design for black-box objective function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一般不评估GPR的UQ质量
&lt;ul&gt;
&lt;li&gt;因为预测一般在pre-defined design bounds&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bayesian neural network
&lt;ul&gt;
&lt;li&gt;Monte Carlo dropout as an alternative to traditional Bayesian neural network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;neural network ensemble
&lt;ul&gt;
&lt;li&gt;neural network ensemble consisting of multiple neural networks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;deterministic UQ methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;metrics
&lt;ul&gt;
&lt;li&gt;classification
&lt;ul&gt;
&lt;li&gt;probability can be viewed as uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;regression
&lt;ul&gt;
&lt;li&gt;confidence interval :
&lt;ul&gt;
&lt;li&gt;没看懂： prediction may be 120 ± 15, in weeks, which represents a two-sided 95% confidence interval (i.e.,∼1.96 standard deviations subtracted from or added to the mean estimate assuming the model-predicted RUL follows a Gaussian distribution).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>2023-11-05 你只看见符合自己观念的事例，还是会根据事例更新自己的观念？</title><link>https://huizhixu.github.io/chs/life/20231105%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86/</link><pubDate>Sun, 05 Nov 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20231105%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86/</guid><description>&lt;p&gt;随着年岁的增长，越来越发现世界上有两种人。一种人是这样的，他们对某种事情坚持一种观点，不管世事如何变迁，不管观点带有如何明显的偏激性，他只会选择性地看到支持这种观点的数据。如果他认定AI是不好的，他就只会看到AI对人类有害的例子。比方说AI造成种族歧视、造成生命威胁的时候，他就会跳出来，“你看，AI是多么可怕，我说了吧”。但是AI给人类提供方便的时候，促进生产效率的时候，他就沉默不言，仿佛没有这件事情发生。又比方说地域歧视，特别在上海，能感受到部分上海人对上海周边某个地方的人怀有敌意。如果这个地方的车牌在路上变道没有打转向灯，他们会说，“**人就是不行”。但是如果是别的地方的人没有遵守交通规则，他们就不会下这种判断。&lt;/p&gt;</description></item><item><title>2023-10-31 最近用AI干了啥</title><link>https://huizhixu.github.io/chs/life/20231031%E6%9C%80%E8%BF%91%E7%94%A8ai%E5%B9%B2%E4%BA%86%E5%95%A5/</link><pubDate>Tue, 31 Oct 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20231031%E6%9C%80%E8%BF%91%E7%94%A8ai%E5%B9%B2%E4%BA%86%E5%95%A5/</guid><description>&lt;p&gt;总结一下最近用大模型做的事情，还蛮有意思的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;工作上已经离不开 &lt;a href="http://you.com" target="_blank" rel="noopener"&gt;you.com&lt;/a&gt;
 ，基本上每个工作日都会打开它：&lt;/p&gt;
&lt;p&gt;a. 询问一些基本操作，例如Pandas操作的数据格式和类型之间的转换。&lt;/p&gt;</description></item><item><title>2023-08-13 Linux回顾</title><link>https://huizhixu.github.io/chs/life/20230813linux%E5%9B%9E%E9%A1%BE/</link><pubDate>Sun, 13 Aug 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230813linux%E5%9B%9E%E9%A1%BE/</guid><description>&lt;p&gt;最近没有那么忙，便回顾了一下&lt;a href="https://gnu-linux.readthedocs.io/zh/latest/index.html" target="_blank" rel="noopener"&gt;Linux方面的知识&lt;/a&gt;
，看看还有什么比较好用的指令。看完第一二章便发现，原来没有什么新鲜的，这里面的指令我在工作中都用过了。不知不觉中，我慢慢地掌握了这些在以前看起来好难的东西。&lt;/p&gt;</description></item><item><title>2023-07-31 NLP资源</title><link>https://huizhixu.github.io/chs/link/20210731nlp%E8%B5%84%E6%BA%90/</link><pubDate>Mon, 31 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/link/20210731nlp%E8%B5%84%E6%BA%90/</guid><description>&lt;p&gt;以下链接方便日常工作。&lt;/p&gt;
&lt;h2 id="经典文章"&gt;经典文章&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener"&gt;The Unreasonable Effectiveness of Recurrent Neural Networks&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener"&gt;Understanding-LSTMs&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="课程"&gt;课程&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ" target="_blank" rel="noopener"&gt;Natural Language Processing with Dan Jurafsky and Chris Manning&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="tools"&gt;Tools&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://chunkviz.up.railway.app/" target="_blank" rel="noopener"&gt;Visual representation of chunk splitting methods&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://promptperfect.jina.ai/" target="_blank" rel="noopener"&gt;promptperfect&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="blog"&gt;Blog&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://luxiangdong.com/" target="_blank" rel="noopener"&gt;RAG-luxiangdong&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="实践"&gt;实践&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://blog.csdn.net/v_JULY_v/article/details/131552592" target="_blank" rel="noopener"&gt;基于LangChain+LLM的本地知识库问答：从企业单文档问答到批量文档问答&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2023-07-31 更换博客皮肤</title><link>https://huizhixu.github.io/chs/life/20230731%E6%9B%B4%E6%8D%A2%E5%8D%9A%E5%AE%A2%E7%9A%AE%E8%82%A4/</link><pubDate>Mon, 31 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230731%E6%9B%B4%E6%8D%A2%E5%8D%9A%E5%AE%A2%E7%9A%AE%E8%82%A4/</guid><description>&lt;p&gt;哈哈哈，我发现我文章没写多少，时间都花在创建/修改/更换博客、博客域名、托管服务器和博客主题上。但不得不说，这个过程真的很有意思啊。&lt;/p&gt;
&lt;p&gt;之前博客主题用的是github-styles，它的页面和github一模一样。左边是个人头像和个人信息，右边上面是置顶文章，然后是文章提交热力图，再往下就是文章的时间线，一目了然。它还能切换light/dark模式.&lt;/p&gt;</description></item><item><title>2023-07-24 诗歌挽救了我们</title><link>https://huizhixu.github.io/chs/life/20230724%E8%AF%97%E6%AD%8C%E6%8C%BD%E6%95%91%E4%BA%86%E6%88%91%E4%BB%AC/</link><pubDate>Mon, 24 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230724%E8%AF%97%E6%AD%8C%E6%8C%BD%E6%95%91%E4%BA%86%E6%88%91%E4%BB%AC/</guid><description>&lt;p&gt;前几天发现夏昆老师的《在唐诗里孤独漫步》在微信读书又上线了。我之前订阅了这本书，所以收到了上架的消息提醒。&lt;/p&gt;
&lt;p&gt;这本书我之前看过一遍的。在21年的4月份，那时候发现自己很久（有好几年）没有读诗词了。其实在国外，有很多的压力——学习压力工作压力语言压力融入压力，这些压力只想让人努力学习当地国家的语言和文化，找个工作融入当地的环境，最好有native speaker的语言能力，最好有与local people打交道的社交能力。另外国外流行文化很受年轻人的喜欢，新鲜的玩意儿那么多，哪里有时间留给诗词呢？&lt;/p&gt;</description></item><item><title>2023-07-20Redash V10安装（在Ubuntu系统上用docker部署安装）</title><link>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</link><pubDate>Thu, 20 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;市面上的Redash教程太混乱了，官方发布了不同的安装方式，但是写得不是很明白。基本上都会有一个重复安装和卸载的过程，是正常的。&lt;/p&gt;
&lt;p&gt;这次安装的经验就是：&lt;/p&gt;</description></item><item><title>2023-07-19Ubuntu上安装Docker</title><link>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</link><pubDate>Wed, 19 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</guid><description>&lt;h1 id="一设置docker-repository"&gt;一、设置Docker Repository&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;升级&lt;code&gt;apt-get&lt;/code&gt;到最新&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get update
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get install ca&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;certificates curl gnupg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="2"&gt;
&lt;li&gt;添加Docker的官方GPG key&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo install &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;m &lt;span style="color:#bd93f9"&gt;0755&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;d &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;curl &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;fsSL https:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;download&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;com&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;linux&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;ubuntu&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;gpg &lt;span style="color:#ff79c6"&gt;|&lt;/span&gt; sudo gpg &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;dearmor &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;o &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gpg
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo chmod a&lt;span style="color:#ff79c6"&gt;+&lt;/span&gt;r &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gpg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="3"&gt;
&lt;li&gt;设置仓库&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;echo \
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;deb [arch=&amp;#34;&lt;/span&gt;$(dpkg &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;architecture)&lt;span style="color:#f1fa8c"&gt;&amp;#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt; &amp;#34;&lt;/span&gt;$(&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;os&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;release &lt;span style="color:#ff79c6"&gt;&amp;amp;&amp;amp;&lt;/span&gt; echo &lt;span style="color:#f1fa8c"&gt;&amp;#34;$VERSION_CODENAME&amp;#34;&lt;/span&gt;)&lt;span style="color:#f1fa8c"&gt;&amp;#34; stable&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;|&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sudo tee &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;sources&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;list&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;d&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;list &lt;span style="color:#ff79c6"&gt;&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;dev&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="二安装docker-engine"&gt;二、安装Docker Engine&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;升级apt-get到最新&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="2"&gt;
&lt;li&gt;安装最新版本的Docker Engine， containerd和Docker Compose&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get install docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;ce docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;ce&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;cli containerd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;io docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;buildx&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;plugin docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;compose&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;plugin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="3"&gt;
&lt;li&gt;确保安装成功&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo docker run hello&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;world
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="三配置docker环境"&gt;三、配置Docker环境&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#配置log文件大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo sh &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;c &lt;span style="color:#f1fa8c"&gt;&amp;#39;mkdir /etc/docker &amp;amp;&amp;amp; cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt; EOF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;log-driver&amp;#34;&lt;/span&gt;:&lt;span style="color:#f1fa8c"&gt;&amp;#34;json-file&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;log-opts&amp;#34;&lt;/span&gt;:{ &lt;span style="color:#f1fa8c"&gt;&amp;#34;max-size&amp;#34;&lt;/span&gt; :&lt;span style="color:#f1fa8c"&gt;&amp;#34;50m&amp;#34;&lt;/span&gt;,&lt;span style="color:#f1fa8c"&gt;&amp;#34;max-file&amp;#34;&lt;/span&gt;:&lt;span style="color:#f1fa8c"&gt;&amp;#34;3&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;EOF&lt;span style="color:#f1fa8c"&gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#将当前用户加入docker组&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo usermod &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;aG docker $USER
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#启动docker服务并配置自启&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo systemctl start docker &lt;span style="color:#ff79c6"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo systemctl enable docker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="四参考"&gt;四、参考&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener"&gt;Docker官网安装&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2023-07-11 如何应对职场压力</title><link>https://huizhixu.github.io/chs/life/20230711%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E8%81%8C%E5%9C%BA%E5%8E%8B%E5%8A%9B/</link><pubDate>Tue, 11 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230711%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E8%81%8C%E5%9C%BA%E5%8E%8B%E5%8A%9B/</guid><description>&lt;p&gt;想了好久要不要写这一篇，因为它传述的价值观和人生观和我们（全世界）的教育都有点不一样。而我也是看了才发现，还能这样？（我被驯化太久了）&lt;/p&gt;
&lt;p&gt;大家小时候的教育，都是叫我们认真学习，对人有礼貌，尊敬老师，关心同学。&lt;/p&gt;</description></item><item><title>2023-03-02 季读——2023年（一）</title><link>https://huizhixu.github.io/chs/life/20230302%E5%AD%A3%E8%AF%BB/</link><pubDate>Fri, 02 Jun 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230302%E5%AD%A3%E8%AF%BB/</guid><description>&lt;p&gt;本来过年的时候想着今年要读一些书，每个月都至少读一本，结果今天发现已经三月份了，我还在读第一本书。&lt;/p&gt;
&lt;p&gt;虽然没有读书，但是看了很多别人写的材料，博客，听了很多访谈。当然，主要因为chatGPT的爆火，公众号每天都充斥着关于大模型的知识。
有一些大咖表面上在聊chatGPT，其实是趁机卖自己的课和书；还有一些人觉得这是个绝佳的创业的机会；还有一些号，明明和他八竿子打不着关系，还要硬往上面蹭。&lt;/p&gt;</description></item><item><title>2023-06-02 季读——2023年（二）</title><link>https://huizhixu.github.io/chs/life/20230602%E5%AD%A3%E8%AF%BB/</link><pubDate>Fri, 02 Jun 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230602%E5%AD%A3%E8%AF%BB/</guid><description>&lt;p&gt;今天早上醒来，看到朋友圈大家都在（给娃）庆祝儿童节，发现居然已经到了6月了。想起自己的季读还没写多少。😄&lt;/p&gt;
&lt;p&gt;由于行业技术的快速发展，这个季度基本都在一个提高认知、拓宽眼界的技术氛围里。因此，我在这段时间里阅读的大部分文章都与技术有关。&lt;/p&gt;</description></item><item><title>2023-05-18 最近觉得很好用的两个AI产品</title><link>https://huizhixu.github.io/chs/life/20230518%E6%9C%80%E8%BF%91%E8%A7%89%E5%BE%97%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AAai%E4%BA%A7%E5%93%81/</link><pubDate>Thu, 18 May 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20230518%E6%9C%80%E8%BF%91%E8%A7%89%E5%BE%97%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AAai%E4%BA%A7%E5%93%81/</guid><description>&lt;p&gt;第一个产品是ora.ai（之前域名是ora.sh），在这个上面可以创建专业领域的机器人。&lt;/p&gt;
&lt;p&gt;ora上面五花八门的机器人都有，解读法律条款的机器人，帮助人们保持心理健康的机器人，图书馆机器人等。&lt;/p&gt;</description></item><item><title>2023-04-27GPU运行LLaMa模型——用HF的方式推理</title><link>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</link><pubDate>Thu, 27 Apr 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</guid><description>&lt;p&gt;在GPU上运行中文LLaMa模型，主要是按照 &lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener"&gt;https://github.com/ymcui/Chinese-LLaMA-Alpaca&lt;/a&gt;
 这个仓库的方法。
中文LLaMa模型和中文Alpaca的区别是：中文LLaMa在英文llama的基础上扩充了中文词表并且使用了中文数据进行二次训练。中文LLaMa只能进行单轮问答。中文Alpaca经过instruct-tuning 生成，可以进行多轮问答。本次实验主要是针对中文LLaMa模型。&lt;/p&gt;</description></item><item><title>2023-03-05用随机梯度下降来优化人生【转载】</title><link>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</link><pubDate>Sun, 05 Mar 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</guid><description>&lt;h2 id="要有目标"&gt;要有目标。&lt;/h2&gt;
&lt;p&gt;你需要有目标。短的也好，长的也好。认真定下的也好，别人那里捡的也好。就跟随机梯度下降需要有个目标函数一样。&lt;/p&gt;
&lt;h2 id="目标要大"&gt;目标要大。&lt;/h2&gt;
&lt;p&gt;不管是人生目标还是目标函数，你最好不要知道最后可以走到哪里。如果你知道，那么你的目标就太简单了，可能是个凸函数。你可以在一开始的时候给自己一些小目标，例如期末考个80分，训练一个线性模型。但接下来得有更大的目标，财富自由也好，100亿参数的变形金刚也好，得足够一颗赛艇。&lt;/p&gt;</description></item><item><title>2023-03-01我都用chatGPT干了啥</title><link>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</link><pubDate>Wed, 01 Mar 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</guid><description>&lt;ol&gt;
&lt;li&gt;写诗&lt;/li&gt;
&lt;li&gt;帮我写程序&lt;/li&gt;
&lt;li&gt;帮我debug&lt;/li&gt;
&lt;li&gt;帮我构造数据&lt;/li&gt;
&lt;li&gt;帮我优化Resume&lt;/li&gt;
&lt;li&gt;梳理NLP知识时，解释不清晰的名词，并给出例子&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2023-02-20 chatGPT有可能是个骗局吗</title><link>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</link><pubDate>Mon, 20 Feb 2023 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</guid><description>&lt;p&gt;昨天读了一篇文章：&lt;a href="https://www.newyorker.com/tech/annals-of-technology/chatGPT-is-a-blurry-jpeg-of-the-web" target="_blank" rel="noopener"&gt;ChatGPT is a blurry JPEG of the web&lt;/a&gt;
。中文翻译在这：&lt;a href="http://www.chinawriter.com.cn/n1/2023/0213/c404090-32622497.html" target="_blank" rel="noopener"&gt;ChatGPT是网上所有文本的模糊图像&lt;/a&gt;
 ，无比同意这篇文章说的，&amp;ldquo;有一种模糊是可以接受的，那就是用不同的词重新陈述信息；对于完全捏造的模糊，当我们寻找事实时，我们认为这是不可接受的&amp;rdquo;。这就是我使用chatGPT的感受。&lt;/p&gt;</description></item><item><title>2023-02-16 如何理解Seq2seq</title><link>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</link><pubDate>Thu, 16 Feb 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</guid><description>&lt;p&gt;先搞清楚几个基本概念：&lt;/p&gt;
&lt;p&gt;Seq2seq是一个概念，它的表现形式就是有encoder和decoder的一个结构。换言之，有encoder和decoder就可以说这是一个Seq2seq模型。编码器或者解码器具体可以用CNN、RNN、LSTM或者attention来构建。&lt;/p&gt;</description></item><item><title>2023-02-13 chatGPT 在攻陷所有人</title><link>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</link><pubDate>Mon, 13 Feb 2023 20:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</guid><description>&lt;p&gt;承认吧，现在全世界最火就是chatGPT。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;去参加了王建硕老师那边组织的关于chatGPT的讨论。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;会上的讨论：对新技术进行哲学思考无疑是最让我震撼的。正因为他们进行深度思考，才能真正看到事物的本质，才能正确判断事物的走向。&lt;/li&gt;
&lt;li&gt;从心理学和教育学来看，也开拓了我的眼界。&lt;/li&gt;
&lt;li&gt;从高效使用和商业化来看，它无疑会改变很多人的生活。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;chatGPT的使用感受很不错。&lt;/p&gt;</description></item><item><title>2023-02-09 如何理解自注意力机制</title><link>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 09 Feb 2023 08:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid><description>&lt;h2 id="理解输入与输出"&gt;理解输入与输出&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;输入有可能是一个 vector，有可能是多个 vector&lt;/li&gt;
&lt;li&gt;输出：
&lt;ul&gt;
&lt;li&gt;一个序列对应一个 label。the whole sequence has a label
&lt;ul&gt;
&lt;li&gt;例子：在情感分析里面，This is good 对应的输入是多个 vector，输出为 positive，是一个vector。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一个 vector 对应一个 label。一个序列对应多个 label。
&lt;ul&gt;
&lt;li&gt;例子：在词性标注里面，This is good 对应的输入是多个 vector，输出为 代词，动词，形容词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;模型决定 label 的个数。seq2seq 任务
&lt;ul&gt;
&lt;li&gt;例子：在机器翻译里面，This is good 对应的输入是3个 vector，中文翻译是”不错“，输出为2个 vector。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="一个vector对应一个label的情况即输入和输出一样多也叫做sequence-labeling"&gt;一个vector对应一个label的情况，即输入和输出一样多，也叫做sequence labeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;例子： I saw a saw&lt;/li&gt;
&lt;li&gt;如何解决 sequence labeling 的问题：用 fully connected network 对每一个 input vector 进行作用&lt;/li&gt;
&lt;li&gt;弊端：
&lt;ul&gt;
&lt;li&gt;用 fully connected network 来输出，假设对 I saw a saw 做词性标注。对于 FC 层来说，两个 saw没有什么不同，但是他们实际上一个是动词，一个是名词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;解决思路：考虑更多的上下文。每一个 fc 层，都对所有的输入作用。或者给他一个 window，作用于相邻的几个 input vector。但是作用还是有限，计算也很复杂。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们想考虑整个 sequence，但是不想把 sequence 所有的数据都包括在里面，就有了 self-attention。&lt;/p&gt;</description></item><item><title>2023-01-31 如何用HuggingFace对不均衡类别进行分类</title><link>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</link><pubDate>Tue, 31 Jan 2023 19:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</guid><description>&lt;h2 id="数据均衡"&gt;数据均衡&lt;/h2&gt;
&lt;p&gt;做文本分类时，如果类别数量差别不大，可以用hugging face的Trainer类，训练代码如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BertForSequenceClassification&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;from_pretrained(&lt;span style="color:#f1fa8c"&gt;&amp;#34;bert-base-chinese&amp;#34;&lt;/span&gt;, num_labels&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(labels),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; problem_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;multi_label_classification&amp;#34;&lt;/span&gt;, id2label&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;id2label,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; label2id&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;label2id)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tokenizer &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BertTokenizerFast&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;from_pretrained(&lt;span style="color:#f1fa8c"&gt;&amp;#34;bert-base-chinese&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;compute_metrics&lt;/span&gt;(p):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; preds &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions[&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;] &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;isinstance&lt;/span&gt;(p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;tuple&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;else&lt;/span&gt; p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; result &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; multi_label_metrics(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; predictions&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;preds,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; labels&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;label_ids)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; result
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;training_args &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; TrainingArguments(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; output_dir&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;model_directory, 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; learning_rate&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;5e-5&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; per_device_train_batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; per_device_eval_batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; num_train_epochs&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;3&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; dataloader_drop_last&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weight_decay&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0.01&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; save_steps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logging_steps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; Trainer(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; args&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;training_args,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; train_dataset&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#34;train&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; eval_dataset&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#34;train&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokenizer&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;tokenizer,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; compute_metrics&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;compute_metrics
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;train()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;evaluate()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;model_directory 是模型存储路径，data是数据。&lt;/p&gt;</description></item><item><title>2022-12-10 HuggingFace的Dataset的使用</title><link>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 10 Dec 2022 18:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;h2 id="hub上的数据集"&gt;hub上的数据集&lt;a name="datasets from the hub"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;（这里不是互联网上任意的数据集，专指Huggingface的hub上面的，就是可以用关键字直接下载的）&lt;/p&gt;
&lt;p&gt;数据集可以在&lt;a href="https://huggingface.co/datasets" target="_blank" rel="noopener"&gt;https://huggingface.co/datasets&lt;/a&gt;
 找到，另外也可以用**&lt;code&gt;datasets.list_datasets()&lt;/code&gt;
来看有什么数据集，然后通过关键字下载。&lt;/p&gt;</description></item><item><title>2022-10-24 在程序里起名有很多要注意的</title><link>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</link><pubDate>Mon, 24 Oct 2022 20:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</guid><description>&lt;p&gt;最近检查以前写的代码，发现我给不同的功能函数或者变量起的名不是很精确。 比如数据处理这个阶段，就很容易取 &lt;code&gt;data_process&lt;/code&gt;， &lt;code&gt;get_data&lt;/code&gt;，&lt;code&gt;process_data&lt;/code&gt;，&lt;code&gt;data_preprocess&lt;/code&gt;，&lt;code&gt;deal_with_data&lt;/code&gt; 这些名字。再比如很多类的主入口，我经常会写 &lt;code&gt;run()&lt;/code&gt;、&lt;code&gt;xx_driver()&lt;/code&gt; 等等。&lt;/p&gt;</description></item><item><title>2022-08-02 用 HanLP 分词时如何自定义词典</title><link>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</link><pubDate>Tue, 02 Aug 2022 17:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</guid><description>&lt;p&gt;在分词的过程中，碰到一个这样的句子：&lt;/p&gt;
&lt;p&gt;&amp;lsquo;&lt;code&gt;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&lt;/code&gt;&amp;rsquo;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; hanlp
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tok &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; hanlp&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;load(hanlp&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pretrained&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;COARSE_ELECTRA_SMALL_ZH)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sentence &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sen_list &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; tok(sentence)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(sen_list)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[&lt;span style="color:#f1fa8c"&gt;&amp;#39;公司&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;产品&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;品质&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;持续&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;提升&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;，&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;单晶&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;硅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;片&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;用&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;料&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;比例&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;大幅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;高于&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;行业&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;平均&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;，&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;单晶&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;硅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;料&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;价格&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;上涨&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;。&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看出来，这里“单晶硅片”，“单晶硅料”， 被分为了“单晶”“硅”“料”和“单晶”“硅”“片”。&lt;/p&gt;</description></item><item><title>2022-07-19 Thomas 拍的烂尾楼</title><link>https://huizhixu.github.io/chs/life/20220719thomas%E6%8B%8D%E7%9A%84%E7%83%82%E5%B0%BE%E6%A5%BC/</link><pubDate>Tue, 19 Jul 2022 19:50:22 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20220719thomas%E6%8B%8D%E7%9A%84%E7%83%82%E5%B0%BE%E6%A5%BC/</guid><description>&lt;p&gt;我很喜欢的摄影家 Thomas 最近发了一组照片&lt;a href="https://mp.weixin.qq.com/s/0fXR0oElN94qWOQdw3L6oQ" target="_blank" rel="noopener"&gt;《烂尾楼里面的微光》&lt;/a&gt;
 ，拍的是西安的两幢烂尾楼，这两幢楼都烂尾好几年了，没有人管。可能是迫于生存压力，某些业主在没通水电的情况下依然住进去了。&lt;/p&gt;</description></item><item><title>2022-07-07 新现实是活在当下</title><link>https://huizhixu.github.io/chs/life/20220707%E6%96%B0%E7%8E%B0%E5%AE%9E%E6%98%AF%E6%B4%BB%E5%9C%A8%E5%BD%93%E4%B8%8B/</link><pubDate>Thu, 07 Jul 2022 14:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20220707%E6%96%B0%E7%8E%B0%E5%AE%9E%E6%98%AF%E6%B4%BB%E5%9C%A8%E5%BD%93%E4%B8%8B/</guid><description>&lt;p&gt;过去的一个礼拜的上海是今年最漂亮的上海，随便刷一刷小红书，就可以看见满屏的”绝美晚霞“，“火烧云”，”绝美朝霞“，”绝美天空“， ”感觉在欧洲“。欧洲的风景那么美丽，除了历史的沉淀，蓝天白云的加分也是不少。第一次意识到上海也可以像欧洲那么美丽，哈哈。&lt;/p&gt;</description></item><item><title>2022-06-29 今日上海</title><link>https://huizhixu.github.io/chs/life/20220629%E4%BB%8A%E6%97%A5%E4%B8%8A%E6%B5%B7/</link><pubDate>Wed, 29 Jun 2022 19:22:05 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20220629%E4%BB%8A%E6%97%A5%E4%B8%8A%E6%B5%B7/</guid><description>&lt;p&gt;高温黄色警报 &lt;br&gt;
雷电黄色警报 &lt;br&gt;
暴雨蓝色警报 &lt;br&gt;
大风黄色警报 &lt;br&gt;
冰雹黄色警报&lt;/p&gt;
&lt;p&gt;但是今日出现了彩虹&lt;/p&gt;</description></item><item><title>2022-03-02 开始学习 FastAPI 了</title><link>https://huizhixu.github.io/chs/life/20220302%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0fastapi%E4%BA%86/</link><pubDate>Wed, 02 Mar 2022 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20220302%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0fastapi%E4%BA%86/</guid><description>&lt;p&gt;最近工作中要用到FastAPI，于是昨天下午在学习FastAPI，我告诉自己，把这个教程（&lt;a href="https://fastapi.tiangolo.com/zh/tutorial/body/" target="_blank" rel="noopener"&gt;https://fastapi.tiangolo.com/zh/tutorial/body/&lt;/a&gt;
 ） 学完，我就会了。&lt;/p&gt;
&lt;p&gt;学着学着突然就emo了，觉得在互联网行业一直要学习新的东西，这个过程是无休止的，何时是个头啊。&lt;/p&gt;</description></item><item><title>2022-01-10 开始对拍照产生兴趣</title><link>https://huizhixu.github.io/chs/life/20220110%E5%BC%80%E5%A7%8B%E5%AF%B9%E6%8B%8D%E7%85%A7%E4%BA%A7%E7%94%9F%E5%85%B4%E8%B6%A3/</link><pubDate>Mon, 10 Jan 2022 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20220110%E5%BC%80%E5%A7%8B%E5%AF%B9%E6%8B%8D%E7%85%A7%E4%BA%A7%E7%94%9F%E5%85%B4%E8%B6%A3/</guid><description>&lt;p&gt;从12月底，就开始对摄影产生了一点兴趣。这种兴趣的由来，其实是有迹可循的。来上海四个月，每个礼拜出门都是去商场吃饭，然后逛逛。时间久了，就觉得周末的生活很乏味，开始讨厌起逛商场来。&lt;/p&gt;</description></item><item><title>2021-12-28 重新学习深度学习的感想</title><link>https://huizhixu.github.io/chs/life/20211228%E4%B8%A4%E5%91%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B0%9D%E8%AF%95/</link><pubDate>Tue, 28 Dec 2021 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20211228%E4%B8%A4%E5%91%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B0%9D%E8%AF%95/</guid><description>&lt;h1 id="重新学习深度学习的感想"&gt;重新学习深度学习的感想&lt;/h1&gt;
&lt;p&gt;由于项目上我们需要用深度学习的模型来完成一个功能，于是最近两周我又复习了下深度学习的知识。&lt;/p&gt;
&lt;p&gt;学习机器学习的课程是17/18年的事情，当时上这门课让我非常suffer。一方面，机器学习代表着高大上的人工智能，让人忍不住探索它为什么这么神奇，于是我花了很多时间去搞懂机器学习到底是在干嘛，AI又是怎么一回事。另一方面，真的非常痛苦。上课时教授轻飘飘的几句话，背后是及其复杂的数学原理和计算，记得这门课的参考书是Pattern Classification，第二章朴素贝叶斯我看了一个月才看懂。而且作业超级多，占分数比又很重，每个周末都和小伙伴在TEL楼写作业写到深夜。&lt;/p&gt;</description></item><item><title>2021-12-27 圣诞节来了</title><link>https://huizhixu.github.io/chs/life/20211227%E5%9C%A3%E8%AF%9E%E8%8A%82%E6%9D%A5%E4%BA%86/</link><pubDate>Mon, 27 Dec 2021 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20211227%E5%9C%A3%E8%AF%9E%E8%8A%82%E6%9D%A5%E4%BA%86/</guid><description>&lt;p&gt;上海真的有圣诞气氛呀~&lt;/p&gt;
&lt;p&gt;才12月初，各个办公楼就开始装饰圣诞树了。我们楼一楼和二楼各有一颗圣诞树，白天唱Jingle Bells， 晚上还唱不一样的歌。圣诞树装饰好的那两天，觉得太温馨了，感动地拍了两张照片。一楼的那颗圣诞树好大呀，很漂亮。当然同事上去摸了摸，发现不是真的树哈哈。在听了三个星期的jingle bells 之后，每天习以为常，总觉得圣诞节已经过去很久了。&lt;/p&gt;</description></item><item><title>2021-11-26 接手维保项目</title><link>https://huizhixu.github.io/chs/life/20211126%E6%8E%A5%E6%89%8B%E7%BB%B4%E4%BF%9D%E9%A1%B9%E7%9B%AE/</link><pubDate>Fri, 26 Nov 2021 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20211126%E6%8E%A5%E6%89%8B%E7%BB%B4%E4%BF%9D%E9%A1%B9%E7%9B%AE/</guid><description>&lt;p&gt;上上周做了入职三个月的转正述职报告。趁着这个机会总结一下试用期的经历。&lt;/p&gt;
&lt;p&gt;8月份“14+7”隔离结束后，我马上就入职了。&lt;/p&gt;
&lt;p&gt;我一入职，就接手了一个项目。这个项目开发已经完成，一年维保期限。以前经常看到网上别人吐槽接手项目的事情，吐槽的方面大概就是这几个方面：&lt;/p&gt;</description></item><item><title>2021-10-30 回国内卷</title><link>https://huizhixu.github.io/chs/life/20211031%E5%9B%9E%E5%9B%BD%E5%86%85%E5%8D%B7/</link><pubDate>Sat, 30 Oct 2021 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20211031%E5%9B%9E%E5%9B%BD%E5%86%85%E5%8D%B7/</guid><description>&lt;p&gt;回国后，我如愿以偿的成为了一名又苦又累的Python后端开发工程师。一眨眼，入职已经两个多月了。我只能说，路是自己选的，苦也是自己选的，人生无非是苦中作乐。&lt;/p&gt;</description></item><item><title>关于我</title><link>https://huizhixu.github.io/chs/page/about/</link><pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate><guid>https://huizhixu.github.io/chs/page/about/</guid><description>&lt;p&gt;你好，很高兴遇到你。&lt;/p&gt;
&lt;p&gt;我是一个对技术热忱，喜欢阅读，喜欢思考的工程师。&lt;/p&gt;
&lt;p&gt;我的优点是：执行力强&lt;/p&gt;
&lt;p&gt;我的缺点是：执行力弱&lt;/p&gt;
&lt;p&gt;人就是这么矛盾！&lt;/p&gt;</description></item><item><title>2019-02-02 柏林电影节《地久天长》观后感</title><link>https://huizhixu.github.io/chs/life/20190202%E6%9F%8F%E6%9E%97%E7%94%B5%E5%BD%B1%E8%8A%82%E5%9C%B0%E4%B9%85%E5%A4%A9%E9%95%BF%E8%A7%82%E5%90%8E%E6%84%9F/</link><pubDate>Sat, 02 Feb 2019 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20190202%E6%9F%8F%E6%9E%97%E7%94%B5%E5%BD%B1%E8%8A%82%E5%9C%B0%E4%B9%85%E5%A4%A9%E9%95%BF%E8%A7%82%E5%90%8E%E6%84%9F/</guid><description>&lt;p&gt;《地久天长》主要讲了这样一个故事：&lt;/p&gt;
&lt;p&gt;上世纪八十年代，刘耀军家和沈英明家是好友，两人的妻子王丽云和李海燕在同一家工厂上班，两家的孩子在同一天出生甚至一起庆祝生日，两家相处和睦友好。&lt;/p&gt;</description></item><item><title>2018-09-01 八月的柏林，热情似火——记在欧洲锦标赛当志愿者的经历</title><link>https://huizhixu.github.io/chs/life/20180901%E8%AE%B0%E5%9C%A8%E6%AC%A7%E6%B4%B2%E9%94%A6%E6%A0%87%E8%B5%9B%E5%BD%93%E5%BF%97%E6%84%BF%E8%80%85%E7%9A%84%E7%BB%8F%E5%8E%86/</link><pubDate>Sat, 01 Sep 2018 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20180901%E8%AE%B0%E5%9C%A8%E6%AC%A7%E6%B4%B2%E9%94%A6%E6%A0%87%E8%B5%9B%E5%BD%93%E5%BF%97%E6%84%BF%E8%80%85%E7%9A%84%E7%BB%8F%E5%8E%86/</guid><description>&lt;p&gt;&lt;img src="../img/20180901/1.jpeg" alt="1"&gt;&lt;/p&gt;
&lt;p&gt;柏林这周真是太热情了！！！&lt;/p&gt;
&lt;p&gt;为啥这么说呢，因为，一向冷酷的柏林在本周三气温达到了史无前例的37度。啊啊啊啊啊！&lt;/p&gt;
&lt;p&gt;大家都说，气温这么高，是因为柏林要迎接最近在这儿举办的欧洲田径锦标赛。&lt;/p&gt;</description></item><item><title>2018-03-04 Non multa, sed multum</title><link>https://huizhixu.github.io/chs/life/20180304non-multa-sed-multum/</link><pubDate>Sun, 04 Mar 2018 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20180304non-multa-sed-multum/</guid><description>&lt;p&gt;今天看的一篇论文里面，有一页引用了一句拉丁语： “ Non multa, sed multum”。&lt;/p&gt;
&lt;p&gt;我搜了一下，发现这句话翻译过来是 &amp;ldquo;Not many, but much&amp;rdquo;，意思就是——我追求不是数量，我追求的是简单概念深层的含义和内在的真理。&lt;/p&gt;</description></item><item><title>2017-12-09 柏林初雪</title><link>https://huizhixu.github.io/chs/life/20171209%E6%9F%8F%E6%9E%97%E5%88%9D%E9%9B%AA/</link><pubDate>Sat, 09 Dec 2017 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20171209%E6%9F%8F%E6%9E%97%E5%88%9D%E9%9B%AA/</guid><description>&lt;p&gt;亲爱的小二，&lt;/p&gt;
&lt;p&gt;最近好吗？一眨眼到了12月，2017年的最后一个月啦。&lt;/p&gt;
&lt;p&gt;今天柏林下雪啦，早上出门，在地铁站看着跨施普雷河的轨道，听着风声夹着雪花飘落，偶尔火车的长鸣传来，空气清冷，我缩了缩脖子，掖了掖围巾，很冷，但觉得很欢喜。下午在家，打算无论如何要给你写这封信，絮叨一下最近的心情，希望你不要嫌我啰嗦。&lt;/p&gt;</description></item><item><title>2017-09-24 【英文观止】光阴养成的贵族 Of Nobility</title><link>https://huizhixu.github.io/chs/life/20170924%E8%8B%B1%E6%96%87%E8%A7%82%E6%AD%A2%E5%85%89%E9%98%B4%E5%85%BB%E6%88%90%E7%9A%84%E8%B4%B5%E6%97%8F-of-nobility/</link><pubDate>Sun, 24 Sep 2017 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20170924%E8%8B%B1%E6%96%87%E8%A7%82%E6%AD%A2%E5%85%89%E9%98%B4%E5%85%BB%E6%88%90%E7%9A%84%E8%B4%B5%E6%97%8F-of-nobility/</guid><description>&lt;p&gt;这个讲解出自齐文昱老师的【英文观止】系列英美文学讲解，我把每一句都记录下来了。下面是正文。&lt;/p&gt;
&lt;p&gt;这篇文章的作者是Francis Bacon，他是英国文学史上最著名的作家之一。关于这个作家呢，之前我们讲过他的一些文章。关于培根，以前讲过他的哪篇文章啊？讲过他的一篇最著名的，of study， 叫《论学》，还有呢，还有一篇文章跟一朵花，跟字面有关系，叫Narcissus，自恋的文章，对吧。那我们看一下培根这个人，他的肖像已经见过无数次了，对吧？他的生卒年份是1561-1626年。那么，有几个问题呢，大家需要去搞得很清楚啊，第一个问题呢，很重要。我们知道英国文学的文学史很长，那么在英国文学史上，培根具有什么样的地位呢？有一个非常非常著名的，关于他定位的定义的：He has been assuming as the central role in the history literature. 他在英国文学史上，特别是散文史上，它所具有的是核心的位置，叫central role，这是第一个问题。那么第二个问题呢？我们要聊一些每个作家他背后的养成的风格，往往需要花很多时间来回望他一生中走过的路，经历过的事，和他见过的人。那么，培根出生在一个什么样的家庭呢？是平民家庭呢还是贵族家庭呢？他出生在一个非常显赫的贵族的门第，这一点非常非常关键。他爸爸呢，很胖，给了他童年当中很多很多貌似最自然最不受雕琢的，但其实对一生影响最深远的教化。1603年，它具有了骑士资格。再往下，其实他的一生哈，跟北宋苏东坡很相似。在官场上曾经具有高位，但后来呢，又曾遭遇不幸。培根生平中遭遇过什么样的变故呢？1621年，受到多项指控，指控和他的贪污受贿有关，从此，人生陷入低谷之中。那么，他被判罪之后，他的人生又经历了哪些东西呢？ 三部曲哈，fining，罚金，罚款，然后呢，in prison，牢狱之灾，然后呢，force from office官也做不成了。他这时发现，他可能更适合去做研究而不是在官场上左右逢迎。所以，晚年，它会以更为平和的心态和更平和的内心去写作。所以他也成为英国文学史的一代宗师。那么，再往下，让我们来看一下，他基本的语言风格。培根的语言风格是什么样的？我们知道，他在散文方面是有很多借鉴的，他呢，有一个文学偶像，或者说文学前辈啊，是个法国人，叫蒙田。蒙田呢是最早用法语来写散文的一个人。蒙田的文风呢，特别的亲切自然，培根呢，像他一样，写了很多短小但却充满哲理，充满智慧这样的文字，但是文风完全不同。培根的文风，It’s kind of witty and cruel，是非常非常的有wit,有智慧，同时又冷峻一些。再往下，培根一生中，说过的最牛的一句话是什么？我们知道，培根不仅仅是个文学家对吧，那个年代的人，一般都博学多才，能同时驾驭很多很多不同的领域。那么，除了做一个文学家之外，培根还做什么研究啊？简单来讲是哲学和科学两个方面。所以培根一生当中说的最著名的一句话，是哪一句话呢？国外的文学大戏一讲到培根，必引用这句话，这句话是这样的：He had knowledge of precise，叫“我以天下学问为己任”。他觉得，如果你只研究某一个门类，某一个学科，这个太狭隘了。天下所有的事情，只要是学问，没有它不研究的。I have take all knowledges to be fierce, fierce的意思是 范畴的意思。培根是在17世纪初，1606年结婚，他的妻子叫Alice，结婚的时候呢，他的妻子很年轻哈，只有14岁。这个基本是关于培根的一生，以及培根的文风，甚至包括培根的婚姻，我们做了一个简短的介绍。跟你们互动三个问题，然后我们进入文章正文。&lt;/p&gt;</description></item><item><title>2017-08-28 你过了一个美好的夏天了吗</title><link>https://huizhixu.github.io/chs/life/20170828%E4%BD%A0%E8%BF%87%E4%BA%86%E4%B8%80%E4%B8%AA%E7%BE%8E%E5%A5%BD%E7%9A%84%E5%A4%8F%E5%A4%A9%E4%BA%86%E5%90%97/</link><pubDate>Mon, 28 Aug 2017 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20170828%E4%BD%A0%E8%BF%87%E4%BA%86%E4%B8%80%E4%B8%AA%E7%BE%8E%E5%A5%BD%E7%9A%84%E5%A4%8F%E5%A4%A9%E4%BA%86%E5%90%97/</guid><description>&lt;p&gt;亲爱的小二，&lt;/p&gt;
&lt;p&gt;最近好吗?&lt;/p&gt;
&lt;p&gt;六月份的一天，Skam第四季播完，里面那个清秀帅气有着可爱小虎牙的Josef跟Sana说，祝你有一个美好的夏天。&lt;/p&gt;
&lt;p&gt;大概所有的粉丝都自动接收了这条讯息吧，因为我看完之后想着，恩，一定要过一个美好的夏天。&lt;/p&gt;</description></item><item><title>2017-08-24 星期六的摄影活动</title><link>https://huizhixu.github.io/chs/life/20170824%E6%98%9F%E6%9C%9F%E5%85%AD%E7%9A%84%E6%91%84%E5%BD%B1%E6%B4%BB%E5%8A%A8/</link><pubDate>Thu, 24 Aug 2017 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20170824%E6%98%9F%E6%9C%9F%E5%85%AD%E7%9A%84%E6%91%84%E5%BD%B1%E6%B4%BB%E5%8A%A8/</guid><description>&lt;p&gt;星期六晚上，我参加了一次摄影活动。&lt;/p&gt;
&lt;p&gt;摄影的主题是长曝，地点在波茨坦广场附近。&lt;/p&gt;
&lt;p&gt;组织者说要带中性滤镜，三脚架，无线控制器，闪光灯，小灯，以及相机。&lt;/p&gt;
&lt;p&gt;我没有中性滤镜，所以去家附近的Mall of Berlin 的Saturn看了看，店员说没有。所以我又跑到亚历山大广场的Saturn，终于买到了。在此之前我不知道中性滤镜是干什么的，后来在出发之前看了两个视频才大概知道在什么时候用。&lt;/p&gt;</description></item><item><title>2017-08-02 Enduring Delicacy 精致英伦 风雅中国</title><link>https://huizhixu.github.io/chs/life/20170802%E7%B2%BE%E8%87%B4%E8%8B%B1%E4%BC%A6%E9%A3%8E%E9%9B%85%E4%B8%AD%E5%9B%BDenduringdelicacy/</link><pubDate>Wed, 02 Aug 2017 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20170802%E7%B2%BE%E8%87%B4%E8%8B%B1%E4%BC%A6%E9%A3%8E%E9%9B%85%E4%B8%AD%E5%9B%BDenduringdelicacy/</guid><description>&lt;p&gt;今天看了一节网课，是齐文昱老师的英美文学课堂，主要内容是”为什么读英文经典？“。&lt;/p&gt;
&lt;p&gt;下面是正文。&lt;/p&gt;
&lt;p&gt;我开始是从培训做起的。一开始做应试的培训，比如说，跟留学有关的，像托福考试，像SAT，SAT是美国的高考，这样一些考试。但后来我发现啊，我们有一个更便捷的方便法门，让中国人在学英语当中，少一些痛苦，少一些郁闷，和彷徨在里面。那么这个方便法门是什么呢？&lt;/p&gt;</description></item><item><title>2016-11-24《你永远不会独行》读书笔记</title><link>https://huizhixu.github.io/chs/life/20161124%E4%BD%A0%E6%B0%B8%E8%BF%9C%E4%B8%8D%E4%BC%9A%E7%8B%AC%E8%A1%8C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Thu, 24 Nov 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20161124%E4%BD%A0%E6%B0%B8%E8%BF%9C%E4%B8%8D%E4%BC%9A%E7%8B%AC%E8%A1%8C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;颜强是一个足球记者，是一个阿森纳球迷，他以细腻的笔触写下了他在英国的关于足球的所见所闻。看完这本书，我才了解到何为“英国足球文化”。&lt;/p&gt;
&lt;p&gt;1.文化的起源往往和时代的政治经济的发展息息相关。&lt;/p&gt;</description></item><item><title>2016-11-11《云雀叫了一整天》——木心很可爱啊</title><link>https://huizhixu.github.io/chs/life/20161111%E4%BA%91%E9%9B%80%E5%8F%AB%E4%BA%86%E4%B8%80%E6%95%B4%E5%A4%A9%E6%9C%A8%E5%BF%83%E5%BE%88%E5%8F%AF%E7%88%B1%E5%95%8A/</link><pubDate>Fri, 11 Nov 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20161111%E4%BA%91%E9%9B%80%E5%8F%AB%E4%BA%86%E4%B8%80%E6%95%B4%E5%A4%A9%E6%9C%A8%E5%BF%83%E5%BE%88%E5%8F%AF%E7%88%B1%E5%95%8A/</guid><description>&lt;p&gt;这是我第一次主动读木心的作品，读之前在担心，会有很多读不懂吧，会有很多典故吧，诗的语言一向简练，我不一定能体会到作者想传达的感情吧。&lt;/p&gt;
&lt;p&gt;但是，完全不是这样的呢。&lt;/p&gt;</description></item><item><title>2016-10-10《钓鱼的男孩》——今年看过的最棒的故事</title><link>https://huizhixu.github.io/chs/life/20161010%E9%92%93%E9%B1%BC%E7%9A%84%E7%94%B7%E5%AD%A9%E4%BB%8A%E5%B9%B4%E7%9C%8B%E8%BF%87%E7%9A%84%E6%9C%80%E6%A3%92%E7%9A%84%E6%95%85%E4%BA%8B/</link><pubDate>Mon, 10 Oct 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20161010%E9%92%93%E9%B1%BC%E7%9A%84%E7%94%B7%E5%AD%A9%E4%BB%8A%E5%B9%B4%E7%9C%8B%E8%BF%87%E7%9A%84%E6%9C%80%E6%A3%92%E7%9A%84%E6%95%85%E4%BA%8B/</guid><description>&lt;p&gt;很难想象《钓鱼的男孩》是一个作家的处女作，我看了这个故事，就爱上了这个故事。这个叫奇戈希·奥比奥玛的作家，真叫人惊叹啊！&lt;/p&gt;
&lt;p&gt;故事发生在一九九六年的尼日利亚。主人公的父亲因工作调动不得不离开家，家里的几个男孩子由于无聊成立了一个“钓鱼男孩帮”，在钓鱼的过程中，疯子阿布鲁的预言（大哥会被渔人夺去性命）使大哥伊肯纳心生恐惧，对兄弟手足不再有往日亲密之情，家庭的变故也从此开始。二哥波贾受不了大哥对家人的精神折磨，将其杀死，自己也投井身亡。三哥和“我”去找阿布鲁报仇并成功，但自己也得承受牢狱之灾。父亲为我们规划过未来的蓝图，他一心想让我们接受西方教育，变成医生、飞行员、教授和律师，并为此几次想送我们去加拿大学习，但他的希望凋零了。最后，出狱后，这一家人终于获得了救赎，主人公最小的弟弟妹妹戴维和恩肯是家里的希望，像白鹭一样，暴风雨过后，他们出现在天空中，展翅翱翔。&lt;/p&gt;</description></item><item><title>2016-08-14德国超级杯</title><link>https://huizhixu.github.io/chs/life/20160814%E5%BE%B7%E5%9B%BD%E8%B6%85%E7%BA%A7%E6%9D%AF/</link><pubDate>Sun, 14 Aug 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20160814%E5%BE%B7%E5%9B%BD%E8%B6%85%E7%BA%A7%E6%9D%AF/</guid><description>&lt;p&gt;好棒！我终于去看了一次拜仁的比赛。尽管大家都说超级杯很鸡肋，但我还是很开心啊，这是我迷上足球以来第一次在现场看球。&lt;/p&gt;
&lt;p&gt;威斯特法伦球场好大呀，不同的区有不同的入口。搞笑的是我和小伙伴从火车站台出来，跟着人流走，走着走着我就发现自己在一片很黄的颜色中特别显眼，而且发现有个女生盯着我看了很久，我心里一边想，有什么不对吗，一边朝四周观望，后来我终于知道了，我穿着拜仁球衣，排在进入南看台的队伍中！而南看台，是为BVB死忠准备的，是永远只有黄黑的！等我们意识到后简直尴尬地落荒而逃。&lt;/p&gt;</description></item><item><title>2016-07-07 星光</title><link>https://huizhixu.github.io/chs/life/20160707%E6%98%9F%E5%85%89/</link><pubDate>Thu, 07 Jul 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20160707%E6%98%9F%E5%85%89/</guid><description>&lt;p&gt;星光&lt;/p&gt;
&lt;p&gt;遍布眼前&lt;/p&gt;
&lt;p&gt;静谧、浪漫&lt;/p&gt;
&lt;p&gt;一年一梦&lt;/p&gt;
&lt;p&gt;一梦一年&lt;/p&gt;
&lt;p&gt;此刻&lt;/p&gt;
&lt;p&gt;不仅是圆梦&lt;/p&gt;
&lt;p&gt;而是重拾少年时&lt;/p&gt;
&lt;p&gt;最美好的信任&lt;/p&gt;
&lt;p&gt;不像盛夏的萤火虫&lt;/p&gt;
&lt;p&gt;隐隐约约&lt;/p&gt;
&lt;p&gt;晕黄的光&lt;/p&gt;
&lt;p&gt;回忆中的星光&lt;/p&gt;
&lt;p&gt;总是在藏蓝色天空&lt;/p&gt;
&lt;p&gt;用力 用力&lt;/p&gt;
&lt;p&gt;蹦蹦跳跳&lt;/p&gt;
&lt;p&gt;像钻石般闪耀&lt;/p&gt;
&lt;p&gt;真是漂亮&lt;/p&gt;</description></item><item><title>2016-04-17莱比锡大堡礁</title><link>https://huizhixu.github.io/chs/life/20160417%E8%8E%B1%E6%AF%94%E9%94%A1%E5%A4%A7%E5%A0%A1%E7%A4%81/</link><pubDate>Sun, 17 Apr 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20160417%E8%8E%B1%E6%AF%94%E9%94%A1%E5%A4%A7%E5%A0%A1%E7%A4%81/</guid><description>&lt;p&gt;昨天坐了两个小时车，去莱比锡。&lt;/p&gt;
&lt;p&gt;莱比锡这个城市很静谧，大片绿草地的公园和音乐家的雕塑无处不在，比较有特色的是墙上大片大片的广告。&lt;/p&gt;
&lt;p&gt;尽管莱比锡是瓦格纳和门德尔松的故乡，也是巴赫待了28年的地方，音乐气息很浓厚，但我们不是为他们而来，而是特意来看澳大利亚大堡礁360全景这个展。展览位于莱比锡郊区的一个圆形大厅里，一看就是废弃工厂改造而成。&lt;/p&gt;</description></item><item><title>2016-01-20 柏林亚洲艺术博物馆</title><link>https://huizhixu.github.io/chs/life/20160120%E6%9F%8F%E6%9E%97%E4%BA%9A%E6%B4%B2%E8%89%BA%E6%9C%AF%E5%8D%9A%E7%89%A9%E9%A6%86/</link><pubDate>Wed, 20 Jan 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20160120%E6%9F%8F%E6%9E%97%E4%BA%9A%E6%B4%B2%E8%89%BA%E6%9C%AF%E5%8D%9A%E7%89%A9%E9%A6%86/</guid><description>&lt;p&gt;我比较常用的一个关于博物馆的 App 是 iMuseum，它的主页面有当下的全世界的展览的介绍，按照时间顺序排列。它的另一个栏目是“同城”，通过选择城市就可以看到所在城市最近的展览是什么，但城市的涵盖范围不是很广，主要包括国内的一线城市和国外的一线城市。欧洲的城市有8个，分别是伦敦，巴黎，柏林，苏黎世，日内瓦，罗马，佛罗伦萨，威尼斯。尽管柏林在里面，但其实我觉得柏林的博物馆是“还好”型而不是“惊艳”型，他的展比北京上海少多了，比伦敦巴黎少更多了。说到这儿我就特别想去巴黎，特别特别想去，我甚至想去那儿住一段时间。&lt;/p&gt;</description></item><item><title>2016-01-10 堆雪人儿</title><link>https://huizhixu.github.io/chs/life/20160110%E5%A0%86%E9%9B%AA%E4%BA%BA%E5%84%BF/</link><pubDate>Sun, 10 Jan 2016 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20160110%E5%A0%86%E9%9B%AA%E4%BA%BA%E5%84%BF/</guid><description>&lt;p&gt;今天早上出门，看天气预报，说下雪概率为0%。朝窗外看了看，雪后晴天，阳光映着白的雪，清爽极了。但我心里不禁感到遗憾，还没有去拍一些下雪时候的照片呢！&lt;/p&gt;</description></item><item><title>2015-06-01 夏季Exkursion</title><link>https://huizhixu.github.io/chs/life/20150601%E5%A4%8F%E5%AD%A3exkursion/</link><pubDate>Mon, 01 Jun 2015 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20150601%E5%A4%8F%E5%AD%A3exkursion/</guid><description>&lt;p&gt;还记得我上次加入的那个协会ETG吗？她又举行活动啦！这次是为期3天的电气类以及化工类的公司参观。参观的学生一共17个人，这次中国小伙伴比较多，有7个呢！&lt;/p&gt;</description></item><item><title>2015-05-03 快乐五一</title><link>https://huizhixu.github.io/chs/life/20150503%E5%BF%AB%E4%B9%90%E4%BA%94%E4%B8%80/</link><pubDate>Sun, 03 May 2015 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20150503%E5%BF%AB%E4%B9%90%E4%BA%94%E4%B8%80/</guid><description>&lt;p&gt;来了这么久，我认识的外国人也不是很多，fb上的好友才40个。一个原因是我有口语障碍。尽管德语证书保证我有念大学上课做实验的资格，但是日常生活中，我很多次都遇到想表达却不知道用哪个词和怎么表达更地道的问题。也就是说，我没办法和德国人一起轻松的谈天说地，因为我总在绞尽脑汁的想词想表达方法。另一个原因是中国学生很多，特别是电气机械汽车这种热门专业，在一些很多专业都要学的课上中国人甚至可以坐满教室的前三排。大家又彼此很照顾，互相讲题啦，一起自习啦，周末出去玩啦，在一起就不说德语。但是我心中是有些慌乱的，我还是想尽量利用这几年的时间让自己的口语变得流利的。于是就有了下面这次经历。&lt;/p&gt;</description></item><item><title>2015-01-24 新年假过后</title><link>https://huizhixu.github.io/chs/life/20150124%E6%96%B0%E5%B9%B4%E5%81%87%E8%BF%87%E5%90%8E/</link><pubDate>Sat, 24 Jan 2015 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20150124%E6%96%B0%E5%B9%B4%E5%81%87%E8%BF%87%E5%90%8E/</guid><description>&lt;p&gt;放完圣诞和新年假后，埃朗根有了新的变化。&lt;/p&gt;
&lt;p&gt;第一是下雪啦，雪中的小城市真的很漂亮。其实南德在假期一直下雪，可惜我去了北德，没有见到雪花飞舞的场景。但幸运的是我回来的那天，火车一路南下，我欣赏到了艳阳高照到大雪纷飞变化的景象。&lt;/p&gt;</description></item><item><title>2014-03-03 人人都有一个软肋</title><link>https://huizhixu.github.io/chs/life/20140303%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%9C%89%E4%B8%80%E4%B8%AA%E8%BD%AF%E8%82%8B/</link><pubDate>Mon, 03 Mar 2014 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20140303%E4%BA%BA%E4%BA%BA%E9%83%BD%E6%9C%89%E4%B8%80%E4%B8%AA%E8%BD%AF%E8%82%8B/</guid><description>&lt;p&gt;人人都有一个软肋。&lt;/p&gt;
&lt;p&gt;最近重温《金枝欲孽》，很想写一写我喜欢的玉莹小主。&lt;/p&gt;
&lt;p&gt;黎姿扮演的玉莹是剧中最漂亮的女人，肌肤胜雪，明眸皓齿，浑身散发出光芒。她作为秀女被招进宫，本以为可以蒙圣宠，上金枝。可是在入京途中她和其他秀女就陷入了你死我活的斗争之中。她开始和尔淳义结金兰，是因为她从一开始就意识到了尔淳是她的对手。对于其他人，她是没放在眼里的。&lt;/p&gt;</description></item><item><title>2013-11-10 不用悲秋</title><link>https://huizhixu.github.io/chs/life/20131110%E4%B8%8D%E7%94%A8%E6%82%B2%E7%A7%8B/</link><pubDate>Sun, 10 Nov 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20131110%E4%B8%8D%E7%94%A8%E6%82%B2%E7%A7%8B/</guid><description>&lt;p&gt;大连今天下午，下了一场小小小雪。也就意味着，秋天过去啦。好像这是本科时代的最后一个秋天哦，明年的这个时候，我就不在这儿啦。&lt;/p&gt;
&lt;p&gt;很忙，在大工银杏最漂亮的时候没有来得及去拍一些照片，只能在某个实验上完了还有空闲时间随便拍两张作为回忆的凭证。但是也不错啦，不管怎么样，总之，亲爱的Sophia，觉得自己不愧对于这段路程就OK啦。&lt;/p&gt;</description></item><item><title>2013-11-03 当年的愿望</title><link>https://huizhixu.github.io/chs/life/20131103%E5%BD%93%E5%B9%B4%E7%9A%84%E6%84%BF%E6%9C%9B/</link><pubDate>Sun, 03 Nov 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20131103%E5%BD%93%E5%B9%B4%E7%9A%84%E6%84%BF%E6%9C%9B/</guid><description>&lt;p&gt;刚刚上课回来，打开邮箱，收到大二的班级的一个男生的一封名为“当年的愿望”的邮件，内容写着“今天收拾抽屉的时候发现的它。不忍丢弃，代为珍藏。愿你保持永远年轻，永远热泪盈眶。”附件就是下面这张图。&lt;/p&gt;</description></item><item><title>2013-09-27 大四第一个月的流水账</title><link>https://huizhixu.github.io/chs/life/20130927%E5%A4%A7%E5%9B%9B%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%88%E7%9A%84%E6%B5%81%E6%B0%B4%E8%B4%A6/</link><pubDate>Fri, 27 Sep 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130927%E5%A4%A7%E5%9B%9B%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%9C%88%E7%9A%84%E6%B5%81%E6%B0%B4%E8%B4%A6/</guid><description>&lt;p&gt;以下纯属毫无营养的流水帐——&lt;/p&gt;
&lt;p&gt;乱乱的大四，就这样开始了。&lt;/p&gt;
&lt;p&gt;第一周去上了一节课，第二周没有去。这个礼拜也只有一节课。大四的课好少啊。&lt;/p&gt;
&lt;p&gt;最近一直在准备APS的审核材料。审核部办事严谨，高中毕业证，初中毕业证，连小学毕业证都要，选修课缺考成绩为零但不影响毕业的证明要，去交流的证明也要，我去~~~~~~~~&lt;/p&gt;</description></item><item><title>2013-09-03 大四开始啦</title><link>https://huizhixu.github.io/chs/life/20130903%E5%A4%A7%E5%9B%9B%E5%BC%80%E5%A7%8B%E5%95%A6/</link><pubDate>Tue, 03 Sep 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130903%E5%A4%A7%E5%9B%9B%E5%BC%80%E5%A7%8B%E5%95%A6/</guid><description>&lt;h3 id="一"&gt;一&lt;/h3&gt;
&lt;p&gt;今天是13年交流生报道的日子，社团迎新。&lt;/p&gt;
&lt;p&gt;这是个公益类社团，全凭着我们的志愿和热情组建。今天的迎新的工作人员是去年去别的学校交流今年回来的交流生，几乎所有的我都只在人人上或QQ上和他们有联系，开学之前没有见过面。但是我跟他们说今天迎新的事，他们很愿意过来看能不能帮点忙。&lt;/p&gt;</description></item><item><title>2013-08-13 813柏林墙的修建</title><link>https://huizhixu.github.io/chs/life/20130813%E6%9F%8F%E6%9E%97%E5%A2%99%E7%9A%84%E4%BF%AE%E5%BB%BA/</link><pubDate>Tue, 13 Aug 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130813%E6%9F%8F%E6%9E%97%E5%A2%99%E7%9A%84%E4%BF%AE%E5%BB%BA/</guid><description>&lt;p&gt;说起来真的特别巧，今天老师刚好给我们讲柏林这一个城市。说到柏林，大家肯定都能够想到柏林墙。而我们的今天学的课文中刚好有这样一句话：&lt;/p&gt;
&lt;p&gt;13.August 1961: Ost-Berlin beginnt mit dem Mauerbau.&lt;/p&gt;</description></item><item><title>2013-07-15 学期终结</title><link>https://huizhixu.github.io/chs/life/20130715%E5%AD%A6%E6%9C%9F%E7%BB%88%E7%BB%93/</link><pubDate>Mon, 15 Jul 2013 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130715%E5%AD%A6%E6%9C%9F%E7%BB%88%E7%BB%93/</guid><description>&lt;p&gt;终于把立场文件给发过去了，呼呼~~&lt;/p&gt;
&lt;p&gt;先说3个大事：&lt;/p&gt;
&lt;p&gt;NO.1:姐姐有宝宝了。好吧，她告诉我的时候我尖叫起来，然后使劲的“哈哈哈”，室友们纳闷我这么反常。&lt;/p&gt;</description></item><item><title>2013-05-24 《小豆豆的童年》读书笔记</title><link>https://huizhixu.github.io/chs/life/20130524-%E5%B0%8F%E8%B1%86%E8%B1%86%E7%9A%84%E7%AB%A5%E5%B9%B4%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Fri, 24 May 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130524-%E5%B0%8F%E8%B1%86%E8%B1%86%E7%9A%84%E7%AB%A5%E5%B9%B4%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;看一个人，就看他的童年。&lt;/p&gt;
&lt;p&gt;我觉得读此书的人，一定都羡慕小豆豆的那段童年。&lt;/p&gt;
&lt;p&gt;故事发生在二战时期的日本，小豆豆是一名小学一年级学生，孩子的天性让她对所有碰到的东西好奇，同时也没有防备心理。最初她在一所学校上学，因为老师忍受不了她的“奇思妙想”，她被劝退。&lt;/p&gt;</description></item><item><title>2013-04-16 终于做了决定</title><link>https://huizhixu.github.io/chs/life/20130416%E7%BB%88%E4%BA%8E%E5%81%9A%E4%BA%86%E5%86%B3%E5%AE%9A/</link><pubDate>Tue, 16 Apr 2013 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130416%E7%BB%88%E4%BA%8E%E5%81%9A%E4%BA%86%E5%86%B3%E5%AE%9A/</guid><description>&lt;p&gt;当看到今年去CSU交流的学弟传到空间的学校开的玉兰花那一刻，我无比想念南方的那个春天。我甚至可以想像那儿是怎样一个让人喜爱的春天。&lt;/p&gt;
&lt;p&gt;可惜，我在这儿，不是那儿。&lt;/p&gt;</description></item><item><title>2013-03-13 三月读书笔记</title><link>https://huizhixu.github.io/chs/life/20130313%E4%B8%89%E6%9C%88%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Wed, 13 Mar 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130313%E4%B8%89%E6%9C%88%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;整理一下这个月：&lt;/p&gt;
&lt;p&gt;1、读的书：《罗生门》（芥川龙之介）&lt;/p&gt;
&lt;p&gt;《三十而立》（王小波）&lt;/p&gt;
&lt;p&gt;《哈佛乱翻书》（陈菊红）&lt;/p&gt;
&lt;p&gt;《秦俑》（李碧华）&lt;/p&gt;
&lt;p&gt;《可爱的洪水猛兽》（韩寒）&lt;/p&gt;
&lt;p&gt;And then there were none （阿加莎?克里尤斯）&lt;/p&gt;</description></item><item><title>2013-02-19 渡边淳一《复乐园》读书笔记</title><link>https://huizhixu.github.io/chs/life/20130219%E6%B8%A1%E8%BE%B9%E6%B7%B3%E4%B8%80%E5%A4%8D%E4%B9%90%E5%9B%AD%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 19 Feb 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130219%E6%B8%A1%E8%BE%B9%E6%B7%B3%E4%B8%80%E5%A4%8D%E4%B9%90%E5%9B%AD%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;书的封页上写着：《复乐园》的来栖与麻子，在旁观他人的幸福与自己经历的感情之后，明白了爱情可以在婚姻，在长相厮守中更为深远，更为温暖，从而回到了乐园，收复了乐园。&lt;/p&gt;</description></item><item><title>2013-01-08 《半生缘》读书笔记</title><link>https://huizhixu.github.io/chs/life/20130108%E5%8D%8A%E7%94%9F%E7%BC%98%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Tue, 08 Jan 2013 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20130108%E5%8D%8A%E7%94%9F%E7%BC%98%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;＂太阳底下没有新鲜的事。＂于是一些事情被重复说，命运被重复演，我们却不觉得腻。好像没有谁真正与众不同，可以去过一种别样的人生。超然世外的人也得做一些琐事吧，也抵不过时间老人的脚吧。室长说我老爱想这些问题，我不是有意的。整天看程序真的要闷死人，不然像《半生缘》这样悲苦的小说谁愿意看。&lt;/p&gt;</description></item><item><title>2012-12-05 English Corner in DUT</title><link>https://huizhixu.github.io/chs/life/20121205englishcorner_in_dut/</link><pubDate>Wed, 05 Dec 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20121205englishcorner_in_dut/</guid><description>&lt;p&gt;大连晴一天雨一天好久了，终于换口味，大雾天了啊。 不管是晴天还是阴天还是雨天还是雾天，每天的内容都是一样的：白天上课，晚上背课文背单词记语法。日复一日。 但是一点都不感到无聊，一心一意做一样东西的乐趣真是让我非常满足。 还有我们的老师，超级有语言天分，当然也很幽默。&lt;/p&gt;</description></item><item><title>2012-11-18 美国文学课上的测试</title><link>https://huizhixu.github.io/chs/life/20121111%E7%BE%8E%E5%9B%BD%E6%96%87%E5%AD%A6%E8%AF%BE%E4%B8%8A%E7%9A%84%E6%B5%8B%E8%AF%95/</link><pubDate>Sun, 18 Nov 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20121111%E7%BE%8E%E5%9B%BD%E6%96%87%E5%AD%A6%E8%AF%BE%E4%B8%8A%E7%9A%84%E6%B5%8B%E8%AF%95/</guid><description>&lt;p&gt;昨天上《美国文学》课，老师在刚上课时让我们想一下什么是我们生命中最重要的，于是我们开始了那个老掉牙的游戏：写5样你认为最重要的东西或人，然后往回删，最后只剩2样。&lt;/p&gt;</description></item><item><title>2012-10-19 《梁启超家书》读书笔记</title><link>https://huizhixu.github.io/chs/life/20121019%E6%A2%81%E5%90%AF%E8%B6%85%E5%AE%B6%E4%B9%A6%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Fri, 19 Oct 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20121019%E6%A2%81%E5%90%AF%E8%B6%85%E5%AE%B6%E4%B9%A6%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;在豆瓣上看见一篇书评《宝贝，你们好吗》，评论的是《梁启超家书》。我看到题目时吓了一大跳。梁任公是著述家，是心系天下，以天下为己任的爱国志士，他的主张曾影响了鲁迅等人，他的《少年中国说》鼓舞了很多年轻人，包括我。而关于他对家庭的关注，我只在《林徽因传》里读过他写给梁思成和林徽因的信。所以在我心目中，梁任公这样对国事及其热忱的人，想当然是不太有时间过问家事的。&lt;/p&gt;</description></item><item><title>2012-09-24 泛读</title><link>https://huizhixu.github.io/chs/life/20120924%E6%B3%9B%E8%AF%BB/</link><pubDate>Mon, 24 Sep 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20120924%E6%B3%9B%E8%AF%BB/</guid><description>&lt;p&gt;一、苏力《大学致辞》&lt;/p&gt;
&lt;p&gt;看讲稿老是没有听到声音兴奋，不过还是摘录了两句话，告诫自己。&lt;/p&gt;
&lt;p&gt;“你的胸襟气度，为人处世，言谈举止，规矩方圆，而不只是你的知识，同样推动全面社会的转型，同样构成一个大国的软实力。”&lt;/p&gt;</description></item><item><title>2012-09-23 《周国平人文讲演录》读书笔记</title><link>https://huizhixu.github.io/chs/life/20120923%E5%91%A8%E5%9B%BD%E5%B9%B3%E4%BA%BA%E6%96%87%E8%AE%B2%E6%BC%94%E5%BD%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 23 Sep 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20120923%E5%91%A8%E5%9B%BD%E5%B9%B3%E4%BA%BA%E6%96%87%E8%AE%B2%E6%BC%94%E5%BD%95%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;我把周先生看成作家。或许可以看成哲学思考者，但的确不是哲学家。&lt;/p&gt;
&lt;p&gt;《人文讲演录》很空泛，大道理一堆。他只是率性的提出了自己的观点，引用很多名家的话，并没有多少批判精神和哲学思考方法。这样的工作，很多人都做得来。&lt;/p&gt;</description></item><item><title>2012-08-15 我要把头发留长了</title><link>https://huizhixu.github.io/chs/life/20120815%E6%88%91%E8%A6%81%E6%8A%8A%E5%A4%B4%E5%8F%91%E7%95%99%E9%95%BF%E4%BA%86/</link><pubDate>Wed, 15 Aug 2012 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20120815%E6%88%91%E8%A6%81%E6%8A%8A%E5%A4%B4%E5%8F%91%E7%95%99%E9%95%BF%E4%BA%86/</guid><description>&lt;p&gt;从湘西木耳村支教回来了 很难忘的一段经历 这几天在家里休息&lt;/p&gt;
&lt;p&gt;跟家人在一起   永远是最舒服最自然的感觉&lt;/p&gt;
&lt;p&gt;弟弟买了我们一家人的家庭装   他是个爱家庭的好孩子是不&lt;/p&gt;
&lt;p&gt;他给我看他做的视频和PPT&lt;/p&gt;</description></item><item><title>2012-05-02 《巨婴国》读书笔记</title><link>https://huizhixu.github.io/chs/life/20120502%E5%B7%A8%E5%A9%B4%E5%9B%BD%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Wed, 02 May 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20120502%E5%B7%A8%E5%A9%B4%E5%9B%BD%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;有个前辈推荐《巨婴国》，我就去看了看。看完后，尽管满满都是槽点，但我还是把它推荐给了一些朋友。&lt;/p&gt;
&lt;p&gt;是的，有时我也受不了二十大几三十大几的人自称“宝宝”，有时也觉得在很多恋爱中女生想要的是“全方位照顾她像照顾婴儿”一样的人，而且“萌”的过度流行，有时候挺让我着急的，觉得大家喜欢弱小无力量的生物，只因为对自己没有威胁。&lt;/p&gt;</description></item><item><title>2012-03-18 《一个人的好天气》读书笔记</title><link>https://huizhixu.github.io/chs/life/20120318%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E5%A5%BD%E5%A4%A9%E6%B0%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link><pubDate>Sun, 18 Mar 2012 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20120318%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%9A%84%E5%A5%BD%E5%A4%A9%E6%B0%94%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid><description>&lt;p&gt;昨晚看完青山七惠的《一个人的好天气》，讲的是一个二十一岁的女生知寿的矛盾青春。尽管是一个未写完的故事，看似有着不明不白的结局，但是，那种把握不住生活的淡淡哀愁还是笼罩全书。&lt;/p&gt;</description></item><item><title>2011-09-09 一起开始的旅程</title><link>https://huizhixu.github.io/chs/life/20110909%E4%B8%80%E8%B5%B7%E5%BC%80%E5%A7%8B%E7%9A%84%E6%97%85%E7%A8%8B/</link><pubDate>Fri, 09 Sep 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110909%E4%B8%80%E8%B5%B7%E5%BC%80%E5%A7%8B%E7%9A%84%E6%97%85%E7%A8%8B/</guid><description>&lt;p&gt;中南的生活正式开启，我多了两个小伙伴——周和邦邦，不禁让人想到《一起开始的旅程》这首歌，这首歌很适合我们现在，歌词如下：&lt;/p&gt;
&lt;p&gt;一起开始的旅程 这几个字有种温暖的气氛 如果用来形容我们　是不是很巧妙传神 
从没想过事情会这样发生　原本陌生的人闯进了人生 从此生命中多出你们　也多出无限可能 
一起作伴　一起游玩　一起分享青春的宝藏 一起前进　一起转弯　一起想下一个梦想 &lt;/p&gt;</description></item><item><title>2011-08-02 我知道你离我不远</title><link>https://huizhixu.github.io/chs/life/20110802%E6%88%91%E7%9F%A5%E9%81%93%E4%BD%A0%E7%A6%BB%E6%88%91%E4%B8%8D%E8%BF%9C/</link><pubDate>Tue, 02 Aug 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110802%E6%88%91%E7%9F%A5%E9%81%93%E4%BD%A0%E7%A6%BB%E6%88%91%E4%B8%8D%E8%BF%9C/</guid><description>&lt;p&gt;想要贴一首歌的歌词&lt;/p&gt;
&lt;p&gt;我知道你离我不远&lt;/p&gt;
&lt;p&gt;歌者：陈楚生&lt;/p&gt;
&lt;p&gt;你是否曾经像我一样&lt;/p&gt;
&lt;p&gt;安静地坐在黑暗里&lt;/p&gt;
&lt;p&gt;看到一千个盲目的自己&lt;/p&gt;
&lt;p&gt;等待温暖的黎明带来人和风的声音&lt;/p&gt;
&lt;p&gt;我知道你　离我不远&lt;/p&gt;
&lt;p&gt;我可以感觉到你&lt;/p&gt;</description></item><item><title>2011-08-01 在回岳阳的车开往长沙的路上</title><link>https://huizhixu.github.io/chs/life/20110801%E5%9C%A8%E5%9B%9E%E5%B2%B3%E9%98%B3%E7%9A%84%E8%BD%A6%E5%BC%80%E5%BE%80%E9%95%BF%E6%B2%99%E7%9A%84%E8%B7%AF%E4%B8%8A/</link><pubDate>Mon, 01 Aug 2011 03:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110801%E5%9C%A8%E5%9B%9E%E5%B2%B3%E9%98%B3%E7%9A%84%E8%BD%A6%E5%BC%80%E5%BE%80%E9%95%BF%E6%B2%99%E7%9A%84%E8%B7%AF%E4%B8%8A/</guid><description>&lt;p&gt;现在是凌晨三点。我在Z17的车上，软座。车上开了空调，很冷。 我在听《因为爱情》，我喜欢这首歌。&lt;/p&gt;
&lt;p&gt;昨晚当我还不是很想睡的时候，我在因为爱情的歌声中思索了一遍我的大二。马上就要去中南大学交流一年了，别的方面都差不多有一个大致的方向，唯有爱情这方面，是最没有方向的。没有悬念的我不会恋爱。我不会弄个异地恋来给自己添堵。&lt;/p&gt;</description></item><item><title>2011-07-15 你不要哭 这样不漂亮</title><link>https://huizhixu.github.io/chs/life/20110715%E4%BD%A0%E4%B8%8D%E8%A6%81%E5%93%AD%E8%BF%99%E6%A0%B7%E4%B8%8D%E6%BC%82%E4%BA%AE/</link><pubDate>Fri, 15 Jul 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110715%E4%BD%A0%E4%B8%8D%E8%A6%81%E5%93%AD%E8%BF%99%E6%A0%B7%E4%B8%8D%E6%BC%82%E4%BA%AE/</guid><description>&lt;p&gt;又来帝都，无谓追梦，黯然感受，留白嘘叹。&lt;/p&gt;
&lt;p&gt;北京这几天天气好的不像样，30度的温度，多云的天空。尽管在湖南长大，知道这与岳阳的三十七八度比起来简直是小巫见大巫。可是刚刚在L城待了6个月的我一下子不习惯这儿的燥热。L城，有干净的街道，时尚的市民，各种节日各种展览，美丽的星海湾，以及可能会抱怨却不会不喜欢的气候。我真不舍得离开那儿。&lt;/p&gt;</description></item><item><title>2011-04-22 天气回暖</title><link>https://huizhixu.github.io/chs/life/20110422%E5%A4%A9%E6%B0%94%E5%9B%9E%E6%9A%96/</link><pubDate>Fri, 22 Apr 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110422%E5%A4%A9%E6%B0%94%E5%9B%9E%E6%9A%96/</guid><description>&lt;p&gt;天气晴朗，有风，但还是不适宜户外运动。&lt;/p&gt;
&lt;p&gt;学校整个体育馆都在维修，学弟学妹们的游泳课乒乓球课瑜伽课都被改成了网球课足球课篮球课，体育场外面的小房子被刷成黄色。&lt;/p&gt;</description></item><item><title>2011-03-01 链接到一个博客</title><link>https://huizhixu.github.io/chs/life/20110301%E9%93%BE%E6%8E%A5%E5%88%B0%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/</link><pubDate>Tue, 01 Mar 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110301%E9%93%BE%E6%8E%A5%E5%88%B0%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/</guid><description>&lt;p&gt;下午四点多，在糖姐姐博客上又链接到一个好博客Autumn，就一直看一直看。令希图书馆离五食堂好远啊，想着今天上午吃了很多东西，中午吃了很多东西，还不太饿，就说服自己，看完再去吃饭吧。&lt;/p&gt;</description></item><item><title>2011-01-24 过小年咯</title><link>https://huizhixu.github.io/chs/life/20110124%E8%BF%87%E5%B0%8F%E5%B9%B4%E5%92%AF/</link><pubDate>Mon, 24 Jan 2011 22:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/life/20110124%E8%BF%87%E5%B0%8F%E5%B9%B4%E5%92%AF/</guid><description>&lt;p&gt;过小年咯，小年真的是小孩子过的年吗？以前家里就是这样跟我说的，后来我发现他们大人也过小年，就产生了怀疑，当我长成大人的时候，我也还在过，爸妈也还给我压岁钱，真是想不明白呐！&lt;/p&gt;</description></item></channel></rss>