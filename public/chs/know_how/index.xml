<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KNOW HOW on 徐慧志的个人博客</title>
    <link>https://huizhixu.github.io/chs/know_how/</link>
    <description>Recent content in KNOW HOW on 徐慧志的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>chs</language>
    <lastBuildDate>Sat, 25 May 2024 16:01:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/know_how/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>用大模型理解爆火的KAN网络</title>
      <link>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</link>
      <pubDate>Sat, 25 May 2024 16:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</guid>
      <description>五一假期的时候，KAN突然成为了热门话题。虽然最初我并没有计划弄懂它，但在老板的要求下，我还是探索了一下。 一、KAN是什么？ Kolmogorov-Arnold 定理是数学领域</description>
    </item>
    
    <item>
      <title>大型语言模型在「想」什么呢？ — 浅谈大型语言模型的可解释性</title>
      <link>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</link>
      <pubDate>Mon, 13 May 2024 19:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</guid>
      <description>Explainable和Interpretable的区别： Explainable： 事物本身是黑箱，我们尝试去解释它的行为或输出。 Interp</description>
    </item>
    
    <item>
      <title>用大语言模型打造AI Agent</title>
      <link>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</link>
      <pubDate>Mon, 22 Apr 2024 23:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</guid>
      <description>人类需要的不仅仅是大模型，而是能做复杂的多步骤的任务的大模型，Agent因此诞生了。 知名的AI Agent 1. AutoGPT: https://github.com/Significant-Gravitas/AutoGPT AutoGPT是一个由Signific</description>
    </item>
    
    <item>
      <title>让AI村民组成虚拟村庄会发生什么事</title>
      <link>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</link>
      <pubDate>Sun, 14 Apr 2024 19:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</guid>
      <description>去年Agent很火的时候，就知道有斯坦福出的这个虚拟小镇的论文了，当时大家都很好奇，怎么能够让大语言模型来操纵agent做出非常复杂的行为呢</description>
    </item>
    
    <item>
      <title>大型语言模型修炼史(第三阶段)</title>
      <link>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</link>
      <pubDate>Sat, 13 Apr 2024 19:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</guid>
      <description>第三阶段：参与实战，打磨技巧 如何克服第二阶段的局限性呢？ 关键是用第一阶段的参数作为初始参数。 （贝叶斯定理这不就来了嘛！） 所以第三阶段是由第一</description>
    </item>
    
    <item>
      <title>大型语言模型修炼史（第一、二阶段）</title>
      <link>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</link>
      <pubDate>Fri, 05 Apr 2024 20:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</guid>
      <description>背景知识 大模型的本质是文字接龙。输入一个未完成的句子，输出这个未完成的句子的下一个token。 大模型可以看成是一个函数。$$ f(未完成的句子</description>
    </item>
    
    <item>
      <title>改进量的期望 Expected Improvement</title>
      <link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link>
      <pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid>
      <description>在看正文之前，先复习一下期望（Expectation）： 在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。 对于一个连续随机变量</description>
    </item>
    
    <item>
      <title>Bayesian Optimization</title>
      <link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link>
      <pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid>
      <description>贝叶斯优化有重要的两步步： 构造代理模型（surrogate model） 由获取函数（acquisition function）来生成采样建议 贝叶</description>
    </item>
    
    <item>
      <title>grobid的使用</title>
      <link>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>最近被文本分块虐得不轻，看到有人介绍grobid，赶紧用上了。 1. Grobid 介绍 Grobid 的全称是Generation of Bibliographic Data。它用机器学习来解析、提取文</description>
    </item>
    
    <item>
      <title>Gaussian Process Regression with GPyTorch</title>
      <link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link>
      <pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid>
      <description>这个例子主要是利用GPytorch，来实现高斯过程回归。 计算Mean zero mean function gpytorch.means.ZeroMean() constant mean function gpytorch.means.ConstantMean() linear mean function gpytorch.means.LinearMean() 计算Covariance RBFKernel gpytorch.kernels.RBFKernel() adding a scaling coefficient: kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) 一般会在核</description>
    </item>
    
    <item>
      <title>Gaussian Process in Practice 高斯过程实践</title>
      <link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link>
      <pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid>
      <description>这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。 1. 先验分布 1.1 多变量高斯分布 创建一个包含n个候</description>
    </item>
    
    <item>
      <title>Kernel Function 核函数</title>
      <link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link>
      <pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid>
      <description>这篇文章主要解决三个问题： 正态分布的表示 核函数是什么，有什么类型 已知先验知识，如何计算后验分布 1. 正态分布的表示 正态分布一般表示为$f \sim N(0</description>
    </item>
    
    <item>
      <title>书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title>
      <link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link>
      <pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid>
      <description>1. 理解covariance matrix Gaussian Process is a stochastic process used to characterize the distribution over function. GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。 假设</description>
    </item>
    
    <item>
      <title>论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title>
      <link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link>
      <pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid>
      <description>Abstract types 第一种分类 data uncertainty (measurement noise) model uncertainty ( limited data) 第二种分类 epistemic uncertainty 认知上的不确定性，通常是由于没有足够的知识（数据）而产生 can be reducible 分为两类 model-form uncertainty 由于模型的选择导致，</description>
    </item>
    
    <item>
      <title>2023-07-20Redash V10安装（在Ubuntu系统上用docker部署安装）</title>
      <link>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</link>
      <pubDate>Thu, 20 Jul 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</guid>
      <description>市面上的Redash教程太混乱了，官方发布了不同的安装方式，但是写得不是很明白。基本上都会有一个重复安装和卸载的过程，是正常的。 这次安装的经</description>
    </item>
    
    <item>
      <title>2023-07-19Ubuntu上安装Docker</title>
      <link>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</link>
      <pubDate>Wed, 19 Jul 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</guid>
      <description>一、设置Docker Repository 升级apt-get到最新 sudo apt-get update sudo apt-get install ca-certificates curl gnupg 添加Docker的官方GPG key sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg 设置仓库</description>
    </item>
    
    <item>
      <title>2023-04-27GPU运行LLaMa模型——用HF的方式推理</title>
      <link>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Thu, 27 Apr 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</guid>
      <description>在GPU上运行中文LLaMa模型，主要是按照 https://github.com/ymcui/Chinese-LLaMA-Alpaca 这个仓库的方法。 中文LLaMa模型和中文Alpaca的区别是：中文LLaMa在英文llama的</description>
    </item>
    
    <item>
      <title>2023-03-05用随机梯度下降来优化人生【转载】</title>
      <link>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</link>
      <pubDate>Sun, 05 Mar 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</guid>
      <description>要有目标。 你需要有目标。短的也好，长的也好。认真定下的也好，别人那里捡的也好。就跟随机梯度下降需要有个目标函数一样。 目标要大。 不管是人生目标</description>
    </item>
    
    <item>
      <title>2023-03-01我都用chatGPT干了啥【汇总】</title>
      <link>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</link>
      <pubDate>Wed, 01 Mar 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</guid>
      <description>写诗 帮我写程序 帮我debug 帮我构造数据 帮我优化Resume 梳理NLP知识时，解释不清晰的名词，并给出例子</description>
    </item>
    
    <item>
      <title>2023-02-20 chatGPT有可能是个骗局吗</title>
      <link>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</link>
      <pubDate>Mon, 20 Feb 2023 20:07:58 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</guid>
      <description>昨天读了一篇文章：ChatGPT is a blurry JPEG of the web 。中文翻译在这：ChatGPT是网上所有文本的模糊图像 ，无比同意这篇文章说的，&amp;ldquo;有</description>
    </item>
    
    <item>
      <title>2023-02-16 如何理解Seq2seq</title>
      <link>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</link>
      <pubDate>Thu, 16 Feb 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</guid>
      <description>先搞清楚几个基本概念： Seq2seq是一个概念，它的表现形式就是有encoder和decoder的一个结构。换言之，有encoder和dec</description>
    </item>
    
    <item>
      <title>2023-02-13 chatGPT 在攻陷所有人</title>
      <link>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</link>
      <pubDate>Mon, 13 Feb 2023 20:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</guid>
      <description>承认吧，现在全世界最火就是chatGPT。 去参加了王建硕老师那边组织的关于chatGPT的讨论。 会上的讨论：对新技术进行哲学思考无疑是最让我</description>
    </item>
    
    <item>
      <title>2023-02-09 如何理解自注意力机制</title>
      <link>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Thu, 09 Feb 2023 08:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid>
      <description>理解输入与输出 输入有可能是一个 vector，有可能是多个 vector 输出： 一个序列对应一个 label。the whole sequence has a label 例子：在情感分析里面，This is</description>
    </item>
    
    <item>
      <title>2023-01-31 如何用HuggingFace对不均衡类别进行分类</title>
      <link>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</link>
      <pubDate>Tue, 31 Jan 2023 19:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</guid>
      <description>数据均衡 做文本分类时，如果类别数量差别不大，可以用hugging face的Trainer类，训练代码如下： model = BertForSequenceClassification.from_pretrained(&amp;#34;bert-base-chinese&amp;#34;, num_labels=len(labels), problem_type=&amp;#34;multi_label_classification&amp;#34;, id2label=id2label, label2id=label2id) tokenizer = BertTokenizerFast.from_pretrained(&amp;#34;bert-base-chinese&amp;#34;) def compute_metrics(p): preds = p.predictions[0] if isinstance(p.predictions,</description>
    </item>
    
    <item>
      <title>2022-12-10 HuggingFace的Dataset的使用</title>
      <link>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 10 Dec 2022 18:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>hub上的数据集 （这里不是互联网上任意的数据集，专指Huggingface的hub上面的，就是可以用关键字直接下载的） 数据集可以在https</description>
    </item>
    
    <item>
      <title>2022-10-24 在程序里起名有很多要注意的</title>
      <link>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</link>
      <pubDate>Mon, 24 Oct 2022 20:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</guid>
      <description>最近检查以前写的代码，发现我给不同的功能函数或者变量起的名不是很精确。 比如数据处理这个阶段，就很容易取 data_process， get_da</description>
    </item>
    
    <item>
      <title>2022-08-02 用 HanLP 分词时如何自定义词典</title>
      <link>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</link>
      <pubDate>Tue, 02 Aug 2022 17:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</guid>
      <description>在分词的过程中，碰到一个这样的句子： &amp;lsquo;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;rsquo; import</description>
    </item>
    
  </channel>
</rss>
