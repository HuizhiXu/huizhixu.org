<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>KNOW HOW on 徐慧志的个人博客</title>
    <link>https://huizhixu.github.io/chs/know_how/</link>
    <description>Recent content in KNOW HOW on 徐慧志的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>chs</language>
    <lastBuildDate>Tue, 05 Mar 2024 20:01:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/know_how/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>改进量的期望 Expected Improvement</title>
      <link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link>
      <pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid>
      <description>在看正文之前，先复习一下期望（Expectation）：
在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。
对于一个连续随机变量X，其期望值可以通过以下公式计算：
$$ \mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot p(x)dx $$
x 是随机变量 X 的取值。 p(x) 是随机变量 X 的概率密度函数，它描述了 X 取特定值 x 的概率。 积分是在整个实数域上进行的，即从负无穷到正无穷。 进入正文。
获取函数（Acquisition function）在多个方面存在差异，包括效用函数的选择、前瞻步骤的数量、风险厌恶或偏好的程度等。
效用函数的意思是数据的有用性，它可以是目标函数的值，可以是协方差，可以是平均值。
常用的Acquisition function有 EI，PI，UCB等。
EI（Expected Improvement） 是指在选取新的点的时候，用已有数据(observations)的最大值作为benchmark，它会计算已有数据的最大值和新观察值之间的期望差，让这个期望差越大越好。
记住，在Expected Improvement (EI) 中，我们通常对目标函数$f(x)$ 的改进感兴趣，而不是随机变量本身的期望值。
假设观测到的数据集为$D_n = {x_{1:n}, y_{1:n}}$，其中${y_1, &amp;hellip;, y_n}$表示为在相应位置${x_1, &amp;hellip;, x_n}$收集到的观测值值。在无噪声的情况下，实际观测值是准确的，即${y_1, &amp;hellip;, y_n} = {f_1, &amp;hellip;, f_n}$。 utility可以表示为 $u(D_n) = max{f_{1:n}} = f_n^*$ 。
如果选择一个新的点${x_{n+1},y_{n+1}}$，那么此时的 utility 为$u(D_{n+1}) = u(D_n \cup {x_{n+1}, f_{n+1}} )=max{f_{1+n}, f_n^*}$。</description>
    </item>
    
    <item>
      <title>Bayesian Optimization</title>
      <link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link>
      <pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid>
      <description>贝叶斯优化有重要的两步步：
构造代理模型（surrogate model） 由获取函数（acquisition function）来生成采样建议 贝叶斯优化中，因为不知道目标函数的closed-form，所以需要构造一个代理模型（surrogate model）来近似目标函数。记住，代理模型对目标函数的潜在分布进行建模。通常用gaussian process来作为代理模型，也可以用random forest来作为代理模型。（任何模型，只要它为函数提供后验估计，可以用来作为surrogate model）。
有了后验估计之后，就可以用获取函数Acquisition Function来生成采样建议。
获取函数，经典的方法有EI 和 upper confidence bound，新的方法有safe constraint。
获取函数是用来找到全局最优解，好的获取函数会尽可能快地找到全局最优解。
序列决策 Sequential Decision-Making 在贝叶斯优化中，是通过一次又一次地做序列决策来达到优化的目的的。
基于特定的策略，优化器将收集观察到的数据点，更新潜在的函数的后验信念，给出下一个采样点进行探索，不断重复迭代以上过程。通常设置最大值/最小值来寻找最优值。
贝叶斯优化可以看作是一个 sequential decision process under uncertainty的过程。
这个过程具体来说是这样的：
优化器收集观测数据（observed data），基于特定的策略（policy），更新函数概率分布的后验信念（posterior belief），提出下一个采样点（next sampling）来进行探索，在提议的位置收集额外的数据点并重复。 不断地收集新的数据点，我们对函数知道的越来越多。 注意，上述过程包含很多东西，每一块都有研究者深入研究。
收集观测数据：收集观测数据一般会用到observation model。Observation model就是我们对数据的采样方法（比如说Sobol或Latin hypercube），这里的目的就是希望每次训练模型的时候可以给训练算法present一些最有代表性的数据。 策略（policy）是指在贝叶斯优化中用于选择下一个采样点的决策规则。如何选择下一个点，就是说我们想对什么东西做优化——这里可以是最优的expected结果（expected improvement）或者是探索空间（expected hypervolume）等。策略也需要决定何时终止探索过程。 优化器（Optimizer）在贝叶斯优化中是整个流程的一个统称。 策略和优化器在贝叶斯优化中紧密配合。策略指导优化器选择下一个采样点，而优化器根据观测数据和模型更新概率分布。 更新函数概率分布的后验信念，通常需要一个surrogate model。包括高斯过程优化（Gaussian Process Optimization）、序列模型优化（Sequential Model-based Optimization）等。高斯过程使用高斯过程模型来建模，序列模型优化使用随机森林等算法来建模。 除此之外，还有外循环和内循环的概念。
外循环：返回最佳点的位置或者最佳值本身。这个额外的点通常可以加入到已有的数据集来迭代下一轮。
内循环：返回采样位置候选。通常通过最大化获取函数来完成。
寻求最佳Policy 获取函数是一个打分器，它对每个候选位置打分，选取最大得分位置。
如果获取函数有解析表达式，可以进行求gradient操作，那么可以将对目标函数的全局优化，转化成对获取函数的优化。
如果获取函数无法微分，可以使用Monte Carlo Approximation来近似计算。</description>
    </item>
    
    <item>
      <title>grobid的使用</title>
      <link>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>最近被文本分块虐得不轻，看到有人介绍grobid，赶紧用上了。
1. Grobid 介绍 Grobid 的全称是Generation of Bibliographic Data。它用机器学习来解析、提取文档。
2. Grobid 安装 用docker安装有两个版本，机器内存大用docker pull grobid/grobid:0.8.0（需要10GB），有crf和deep learning两种模型，内存小用docker pull lfoppiano/grobid:0.8.0（需要300MB），只有crf模型。
m1芯片需要JVM 这里有解决办法 我在本地安装的是小模型版本。
docker pull lfoppiano/grobid:0.8.0 docker run --rm --init --ulimit core=0 -p 8070:8070 lfoppiano/grobid:0.8.0 运行上面两条命令之后就可以在http://localhost:8070/ 看到官网的经典页面了。（官网demo：https://kermitt2-grobid.hf.space/）
3. Grobid 使用 3.1 Web 端 web端的使用很简单，在http://localhost:8070/上传文档，点submit就可以了，还能下载TEI结果。（TEI是Text Encoding Initiative， 规定了电子文档的结构。）
3.2 API 调用 如果想使用API调用，有Node.js、Jave、Python三种方式。
我选择的是Python调用。GitHub Repo在此：https://github.com/kermitt2/grobid_client_python
git clone https://github.com/kermitt2/grobid_client_python cd grobid_client_python python3 setup.py install 运行
from grobid_client.grobid_client import GrobidClient client = GrobidClient(config_path=&amp;#34;./config.json&amp;#34;) client.process(&amp;#34;processFulltextDocument&amp;#34;, &amp;#34;/mnt/data/covid/pdfs&amp;#34;, n=20) 4.</description>
    </item>
    
    <item>
      <title>Gaussian Process Regression with GPyTorch</title>
      <link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link>
      <pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid>
      <description>这个例子主要是利用GPytorch，来实现高斯过程回归。
计算Mean zero mean function gpytorch.means.ZeroMean() constant mean function gpytorch.means.ConstantMean() linear mean function gpytorch.means.LinearMean() 计算Covariance RBFKernel gpytorch.kernels.RBFKernel() adding a scaling coefficient: kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) 一般会在核函数的输出上添加缩放系数。
在核函数的输出上添加缩放系数是为了调整核函数的影响力。
例如，如果我们希望某个核函数的输出对预测结果的贡献更大，我们可以使用较大的缩放系数。相反，如果我们希望某个核函数的输出对预测结果的贡献较小，我们可以使用较小的缩放系数。
通过在核函数的输出上应用kernels.ScaleKernel()，我们可以乘以一个固定的缩放因子，以增加或减小核函数的输出。
exact GP and approximate GP Exact inference applies when the closed-form expression of the posterior is available. We can simple and quick to compute the posterior distribution using gpytorch.models.ExactGP. Approximate inference applies when the posterior distribution involves high-dimensional integrals. It is difficult and time-consuming to compute.</description>
    </item>
    
    <item>
      <title>Gaussian Process in Practice 高斯过程实践</title>
      <link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link>
      <pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid>
      <description>这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。
1. 先验分布 1.1 多变量高斯分布 创建一个包含n个候选输入位置的列表${x_i，i=1,&amp;hellip;,n}$ 初始化均值向量μ和协方差矩阵K（含n x n个元素） 假设x_1和x_2是多维的矩阵。x_1是一个 m* d的矩阵，x_2是一个nd的矩阵，那么K是一个mn的矩阵，$K[i,j] = k(x_1[i,:], x_2[j,:])$ 执行Cholesky分解K=LL T来获得L 通过LN（0,I）获得N（0,K）上的一个样本并存储在f_prior中 multivariante_samples01 和multivariante_samples02 这两个function的作用是一样的，只不过有两种写法。
1.2 看图可知 从先验过程采样的五个例子，其中大多数函数的值落在95%的可信区间内。 import numpy as np from matplotlib import pyplot as plt %matplotlib inline # 设置随机种子以确保重复性 np.random.seed(8) def plot_gp(mu, cov, title_str, X, X_train=None, Y_train=None, samples=[] ): X = X.ravel() # X.ravel()用于将多维数组X展平为一维数组。 mu = mu.ravel() uncertainty = 1.96 * np.sqrt(np.diag(cov)) # 通过计算协方差矩阵的对角线元素的平方根，可以得到每个参数的标准差。乘以 1.96，可以得到一个置信区间，表示该参数的不确定性范围。 plt.fill_between(X, mu + uncertainty, mu - uncertainty, alpha=0.</description>
    </item>
    
    <item>
      <title>Kernel Function 核函数</title>
      <link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link>
      <pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid>
      <description>这篇文章主要解决三个问题：
正态分布的表示 核函数是什么，有什么类型 已知先验知识，如何计算后验分布 1. 正态分布的表示 正态分布一般表示为$f \sim N(0,K)$，书上写作 $p(f|x) = N(f|0,K)$。
为啥要多写一个f呢？
因为这个分布是针对f的分布，换句话说这里的随机变量是f，再换句话就是说这个随机变量f遵守一个正态分布。
2. 核函数是什么，有什么类型 核函数就是协方差。
核函数$K(x_i, x_j)$
它计算在输入空间中任意两个点的相似度，可以用欧式距离表示。 它度量输入空间中两点$x_i$和$x_j$之间的统计关系。 它量化$x_j$的变化和$x_i$的相应变化之间的相关性。 选择不同核函数，表示数据点之间的相关性被用不同方式来衡量。
有几种常见的核：
高斯核 Gaussian kernel 1.1 常见的高斯核 $$ K_{ij} = k(x_i,x_j) = e^{-||X_i-X_j||^2}$$
这里把负平方距离的指数作为距离度量。当x_i和x_j距离非常远，我们有x_i-x_j 趋向于无穷大，此时k_{ij}趋向于0。当x_i和x_j相等，k_{ij}等于1。K是一个介于0和1之间的数，由此就可以表现点之间的相关性。
1.2 可调节参数的高斯核，又被叫做isotropic squared exponential kernel $$K_{ij} = k(x_i,x_j) = \sigma_f^2e^{-\frac{1}{2l^2}||X_i-X_j||^2}$$ 2. 略(以后补充，暂时不是重点)
3. 已知先验知识，如何计算后验分布 假设我们有三个无噪声观测值，$ D = {(x_1,f(x_1)), (x_2, f(x_2)),(x_3, f(x_3))}$。我们需要对这三个随机变量进行建模。假设mean vector 为 $\mu$， covariance matrix为$K$。
这三个变量遵循多元变量的高斯分布
基于这个数据集D，假设我们现在想知道另一个变量$x_4$（它对应的f值用$f_*(x_4)$表示）在其他位置的均值和方差的的分布。
问题：f 和f* 是同一个分布吗？ 不是，用不同的字母表示不同的分布。
f和f*的分布为</description>
    </item>
    
    <item>
      <title>书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title>
      <link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link>
      <pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid>
      <description>1. 理解covariance matrix Gaussian Process is a stochastic process used to characterize the distribution over function.
GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。
假设我们有两个变量，X1和X2，它俩符合multivariate Gaussian distribution。
一个高斯分布可以用mean vector 和covariance matrix来表示。均值向量描述了从高斯分布重复采样的集中趋势，协方差矩阵描述了点之间的相关性。（The mean vector describes the central tendency if we were to sample from the Gaussian distribution repeatedly, and the covariance matrix describes how the features of the data are related to each other）
假设mean vector matrix K为：
K 可以告诉我们，当x1增加的时候，x2变化的大小和方向是如何变化的。K用点积来衡量x1维和x2维的相似性。
$$\sigma_{11}^2 = var(x_1) = E[(x_1-E[x_1])^2] = E[(x_1)^2]$$
$$\sigma_{12}^2 = \sigma_{21}^2 = E[(x_1-E[x_1])(x_2-E[x_2])] = E[x_1x_2]$$</description>
    </item>
    
    <item>
      <title>论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title>
      <link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link>
      <pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid>
      <description>Abstract
types 第一种分类 data uncertainty (measurement noise) model uncertainty ( limited data) 第二种分类 epistemic uncertainty 认知上的不确定性，通常是由于没有足够的知识（数据）而产生 can be reducible 分为两类 model-form uncertainty 由于模型的选择导致，例如architectures, activation functions or kernel functions parameter uncertainty 在训练过程产生，由于数据不够导致 aleatory uncertainty stems from physical systems, 具有随机性, cannot be reducible e.g. noises 这种类型的不确定性在ML模型里面被看成是似然函数的一部分(a part of the likelihood function) 也被叫做data uncertainty 捕捉这种不确定性的方式有：同方差 homoscedastic和异方差 heteroscedastic 例子： test data和train data不同分布：epistemic uncertainty (model performs poorer in extrapolation than in interpolation) 测量数据由仪器导致的误差是aleatory Unc， 大试如果由于精度原因导致，则属于epistemic unc，因为提高精度可以减少这个误差 causes methods: Gaussian process regression a ML method with UQ capability 一般不用来quantify uncertainty of a final surrogate 一般用来在高度不确定的采样空间里采样，来减少训练样本的数量 to build an accurate surrogate within some lower and upper bounds of input variables to find a globally optimally design for black-box objective function 一般不评估GPR的UQ质量 因为预测一般在pre-defined design bounds Bayesian neural network Monte Carlo dropout as an alternative to traditional Bayesian neural network neural network ensemble neural network ensemble consisting of multiple neural networks deterministic UQ methods metrics classification probability can be viewed as uncertainty regression confidence interval : 没看懂： prediction may be 120 ± 15, in weeks, which represents a two-sided 95% confidence interval (i.</description>
    </item>
    
    <item>
      <title>2023-07-20Redash V10安装（在Ubuntu系统上用docker部署安装）</title>
      <link>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</link>
      <pubDate>Thu, 20 Jul 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</guid>
      <description>市面上的Redash教程太混乱了，官方发布了不同的安装方式，但是写得不是很明白。基本上都会有一个重复安装和卸载的过程，是正常的。
这次安装的经验就是：
千万不要从Redash的Github Master分支上拉代码，比较痛苦。
考虑用不用Docker部署的条件是：看需不需要进行二次开发，不需要就可以进行Docker部署
CentOS也是一个类Linux的系统，和Ubuntu一样。注意它不是指mac的操作系统。
一、配置环境 系统环境（这个仅供参考） 系统版本： Ubuntu-22.04 目标安装目录： /opt/redash Postgresql账号/密码： postgres/abcdef123456 环境变量env文件： /opt/redash/.env 配置docker环境 #将当前用户加入docker组 sudo usermod -aG docker $USER #启动docker服务并配置自启 sudo systemctl start docker &amp;amp;&amp;amp; sudo systemctl enable docker 二、安装Redash 选定安装目录，这里是/opt/redash sudo mkdir /opt/redash sudo chown -R ${USER} /opt/redash cd /opt/redash 创建env文件，写入下列内容 #/opt/redash/env/内容 PYTHONUNBUFFERED=0 REDASH_LOG_LEVEL=INFO REDASH_REDIS_URL=redis://redis:6379/0 POSTGRES_PASSWORD=aaa123456 REDASH_COOKIE_SECRET=wo3urion23i4un2l34jm2l34k REDASH_SECRET_KEY=u2o34nlfksjelruirk REDASH_DATABASE_URL=&amp;#34;postgresql://postgres:abcdef123456@postgres/postgres&amp;#34; ORACLE_HOME=&amp;#34;/usr/lib/oracle/12.2/client64&amp;#34; LD_LIBRARY_PATH=&amp;#34;/usr/lib/oracle/12.2/client64/lib&amp;#34; REDASH_FEATURE_ALLOW_CUSTOM_JS_VISUALIZATIONS=&amp;#34;true&amp;#34; REDASH_ADDITIONAL_QUERY_RUNNERS=&amp;#34;redash.query_runner.oracle,redash.query_runner.python&amp;#34; 创建docker-compose.yml，写入下列内容 这里我只改了image的内容:image: redash/redash:10.1.0.b50633，这个image是在github的release分支上 找到的。
version: &amp;#34;2&amp;#34; x-redash-service: &amp;amp;redash-service #现在image的值为中文开源版的tag如果要使用官方的镜像，在docker hub上查看官方tag，然后替换。 image: image: redash/redash:10.</description>
    </item>
    
    <item>
      <title>2023-07-19Ubuntu上安装Docker</title>
      <link>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</link>
      <pubDate>Wed, 19 Jul 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</guid>
      <description>一、设置Docker Repository 升级apt-get到最新 sudo apt-get update sudo apt-get install ca-certificates curl gnupg 添加Docker的官方GPG key sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg 设置仓库 echo \ &amp;#34;deb [arch=&amp;#34;$(dpkg --print-architecture)&amp;#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \ &amp;#34;$(. /etc/os-release &amp;amp;&amp;amp; echo &amp;#34;$VERSION_CODENAME&amp;#34;)&amp;#34; stable&amp;#34; | \ sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null 二、安装Docker Engine 升级apt-get到最新 sudo apt-get update 安装最新版本的Docker Engine， containerd和Docker Compose sudo apt-get install docker-ce docker-ce-cli containerd.</description>
    </item>
    
    <item>
      <title>2023-04-27GPU运行LLaMa模型——用HF的方式推理</title>
      <link>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F-copy/</link>
      <pubDate>Thu, 27 Apr 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F-copy/</guid>
      <description>在GPU上运行中文LLaMa模型，主要是按照 https://github.com/ymcui/Chinese-LLaMA-Alpaca 这个仓库的方法。 中文LLaMa模型和中文Alpaca的区别是：中文LLaMa在英文llama的基础上扩充了中文词表并且使用了中文数据进行二次训练。中文LLaMa只能进行单轮问答。中文Alpaca经过instruct-tuning 生成，可以进行多轮问答。本次实验主要是针对中文LLaMa模型。
文档 模型部署和推理有四种方法，我选择的是用HF的inference接口来进行推理。
https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/使用Transformers推理 这里详细讲了用scripts/inference_hf.py来启动模型。
原则上非常简单，直接运行下列的脚本，就可以进行推理。
CUDA_VISIBLE_DEVICES={device_id} python scripts/inference_hf.py \\ --base_model path_to_original_llama_hf_dir \\ --lora_model path_to_chinese_llama_or_alpaca_lora \\ --with_prompt \\ --interactive 对参数进行解释：
base_model是Meta发布的原生llama模型 lora_model是 这个是LoRa生成的模型，可以在网盘下载，也可以用HF的模型调用（例如ziqingyang/chinese-llama-lora-7b）。模型调用比较简单推荐使用。 with_prompt 是否将输入与prompt模版进行合并。 interactive 以交互方式启动，以便进行多次单轮问答。 在实验之前，首先要搞清楚一些概念：
LoRa和Alpaca模型是无法单独完成推理的，需要和META的原生LLAMA结合才能运行。 远程LLAMA模型META提供，LoRa和Alpaca模型这个项目提供。 为什么不能用lora模型单独推理，以我浅显的理解，它freeze了原来的模型，单独加了一些层，后续的中文训练都在这些层上做，所以需要进行模型融合。
用huggingface的推理脚本，需要将模型转换成HF支持的格式。（Don’t worry 作者把脚本都写好了） 实践 下面用步骤的形式记录一下整个过程。
1. 克隆项目 git clone git@github.com:ymcui/Chinese-LLaMA-Alpaca.git cd Chinese-LLaMA-Alpaca 2. 安装环境 pip install -r requirements.txt 这一步出现了ERROR: No matching distribution found for peft==0.3.0dev
解决：最后安装了peft==0.2.0
3. 下载meta发布的原生的Llama模型 可以下载泄露版本，需要用磁力链下载 。 泄露地址在这 也可以用HuggingFace上的7B模型 mkdir -p models/7B/ wget -P models/7B/ &amp;lt;https://huggingface.</description>
    </item>
    
    <item>
      <title>2023-03-05用随机梯度下降来优化人生【转载】</title>
      <link>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</link>
      <pubDate>Sun, 05 Mar 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</guid>
      <description>要有目标。 你需要有目标。短的也好，长的也好。认真定下的也好，别人那里捡的也好。就跟随机梯度下降需要有个目标函数一样。
目标要大。 不管是人生目标还是目标函数，你最好不要知道最后可以走到哪里。如果你知道，那么你的目标就太简单了，可能是个凸函数。你可以在一开始的时候给自己一些小目标，例如期末考个80分，训练一个线性模型。但接下来得有更大的目标，财富自由也好，100亿参数的变形金刚也好，得足够一颗赛艇。
坚持走。 不管你的目标多复杂，随机梯度下降都是最简单的。每一次你找一个大概还行的方向（梯度），然后迈一步（下降）。两个核心要素是方向和步子的长短。但最重要的是你得一直走下去，能多走几步就多走几步。
痛苦的卷。 每一步里你都在试图改变你自己或者你的模型参数。改变带来痛苦。但没有改变就没有进步。你过得很痛苦不代表在朝着目标走，因为你可能走反了。但过得很舒服那一定在原地踏步。需要时刻跟自己作对。
可以躺平。 你用你内心的激情来迈步子。步子太小走不动，步子太长容易过早消耗掉了激情。周期性的调大调小步长效果挺好。所以你可以时不时休息休息。
四处看看。 每一步走的方向是你对世界的认识。如果你探索的世界不怎么变化，那么要么你的目标太简单，要么你困在你的舒适区了。随机梯度下降的第一个词是随机，就是你需要四处走走，看过很多地方，做些错误的决定，这样你可以在前期迈过一些不是很好的舒适区。
快也是慢。 你没有必要特意去追求找到最好的方向和最合适的步子。你身边当然会有幸运之子，他们每一步都在别人前面。但经验告诉我们，随机梯度下降前期进度太快，后期可能乏力。就是说你过早的找到一个舒适区，忘了世界有多大。所以你不要急，前面徘徊一段时间不是坏事。成名无需太早。
赢在起点。 起点当然重要。如果你在终点附近起步，可以少走很多路。而且终点附近的路都比较平，走着舒服。当你发现别人不如你的时候，看看自己站在哪里。可能你就是运气很好，赢在了起跑线。如果你跟别人在同一起跑线，不见得你能做更好。
很远也能到达。 如果你是在随机起点，那么做好准备前面的路会非常不平坦。越远离终点，越人迹罕见。四处都是悬崖。但随机梯度下降告诉我们，不管起点在哪里，最后得到的解都差不多。当然这个前提是你得一直按照梯度的方向走下去。如果中间梯度炸掉了，那么你随机一个起点，调整步子节奏，重新来。
独一无二。 也许大家有着差不多的目标，在差不多的时间毕业买房结婚生娃。但每一步里，每个人内心中看到的世界都不一样，导致走的路不一样。你如果跑多次随机梯度下降，在各个时间点的目标函数值可能都差不多，但每次的参数千差万别。不会有人关心你每次训练出来的模型里面参数具体是什么值，除了你自己。
简单最好。 当然有比随机梯度下降更复杂的算法。他们想每一步看想更远更准，想步子迈最大。但如果你的目标很复杂，简单的随机梯度下降反而效果最好。深度学习里大家都用它。关注当前，每次抬头瞄一眼世界，快速做个决定，然后迈一小步。小步快跑。只要你有目标，不要停，就能到达。
转自知乎 </description>
    </item>
    
    <item>
      <title>2023-03-01我都用chatGPT干了啥【汇总】</title>
      <link>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</link>
      <pubDate>Wed, 01 Mar 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</guid>
      <description> 写诗 帮我写程序 帮我debug 帮我构造数据 帮我优化Resume 梳理NLP知识时，解释不清晰的名词，并给出例子 </description>
    </item>
    
    <item>
      <title>2023-02-20 chatGPT有可能是个骗局吗</title>
      <link>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</link>
      <pubDate>Mon, 20 Feb 2023 20:07:58 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</guid>
      <description>昨天读了一篇文章：ChatGPT is a blurry JPEG of the web 。中文翻译在这：ChatGPT是网上所有文本的模糊图像 ，无比同意这篇文章说的，&amp;ldquo;有一种模糊是可以接受的，那就是用不同的词重新陈述信息；对于完全捏造的模糊，当我们寻找事实时，我们认为这是不可接受的&amp;rdquo;。这就是我使用chatGPT的感受。
昨天和同事A和B闲聊，我和他们说起我调试chatGPT帮我写代码的事，我表示这个过程无比艰辛，因为它总是丢三落四的，提示了这个又忘记了那个，教了它很久，太累了。但是chatGPT总体来说还是让人很欣喜，因为它真的很聪明。
同事A就说到，如果他是openAI老板，一定要请一些人工来选择这些答案，让这些答案更好更有人情味。同事B就表示，人少访问还可以这样做，但是现在全球有上亿用户，人工如何忙得过来，而且还有不同语言的问题，上哪去找这么多qualified的人。
我也不相信这个后面是人工调试展示答案，但是又有一丝怀疑。每次输完问题等待答案的时候，会缓冲一些时间，然后答案里面的字一个个地出现在我眼前。这种情景就像有人在电脑对面和我交流，在打字。”字一一个个打印“，让人想起《流浪地球2》里面Moss明明已经知道三万个密码，本可以一秒钟填充，却还是要丫丫一个数字一个数字说出来。这里是不是巧合呢？
同事A又说到，他以前在国外读博的时候，他们所里有个postdoc说某个软件可以感知到你的情绪并且显示出来，屏幕上会出现笑脸和哭脸。大家都竖大拇指，然而实际上，是有人在后面观察帮忙看着调按钮。
同事B也补充说，人工智能的水分还是很大的。Siri刚出来的时候特别聪明，后来被爆出来后面是人工在接听和回应，后来去掉人工之后就很蠢了。
我没有用过特别聪明的Siri，我用的时候siri就是傻傻的，除了定闹钟和成语接龙外其他功能都很少用。
我们老板有句名言，”有多少人工就有多少智能“。如果chatGPT不开源，真的是雇了人只圈钱呢？
哈哈那是不可能的。</description>
    </item>
    
    <item>
      <title>2023-02-16 如何理解Seq2seq</title>
      <link>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</link>
      <pubDate>Thu, 16 Feb 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</guid>
      <description>先搞清楚几个基本概念：
Seq2seq是一个概念，它的表现形式就是有encoder和decoder的一个结构。换言之，有encoder和decoder就可以说这是一个Seq2seq模型。编码器或者解码器具体可以用CNN、RNN、LSTM或者attention来构建。
transformer是一种基于Attention的Seq2seq。
Seq2seq input是一个sequence， output也是一个sequence，但是维度由模型决定。 例子： 语音辨识：一串语音转为”今晚吃什么？“几个文字。 机器翻译 语音翻译：输入machine learning，输出”机器学习”。 为何不将”语音辨识“和”机器翻译“结合起来，因为有的语言没有文字 结构和原理 Seq2seq由一个encoder和一个decoder决定
Encoder input是一个sequence， output也是一个sequence。 input vector加上positional encoding，然后经过multi-head attention，然后进行residual + layer normalization，然后经过FC，再做一次Add&amp;amp;Norm，是这个encoder的输出。这个过程会重复。 更细节的设计： input vector进来之后，经过self-attention，input和output相加，然后进行一层layer normalization。然后进入FC层，再进行一次Add&amp;amp;Norm（和自己相加&amp;amp;Normalization），这个输出就是一个block的输出。 residual connection：输入与输出相加，防止层级过高导致的梯度消失。 layer normalization： 输入一个向量，输出一个向量，不需要考虑batch中其他的向量。 对同一个feature，同一个example不同的dimension去计算。（这里feature就是example） 做法：计算它 的mean $m$和standard deviation $\sigma$ $$ x_i^\prime =\frac {x_i - m} {\sigma} $$
batch normalization： 对同一个dimension，不同的example，不同的feature去计算mean和standard deviation Decoder decoder有两种，一种叫auto-regressive。这里讲的都是auto-regressive。 decoder的输入： 在前边先加一个特殊的符号：BOS。 每个输入可以表示成一个one hot vector。例如”机器学习“加上BOS就是5个one hot vector。 decoder的输出： 想好decoder输出的单位是什么，假设我们做的是中文的语音辨识，那么decoder输出的就是中文，那么vocabulary就是中文的数目，常用4000个字。不同的语言输出的单位不一样，英文可以输出字母，word， subword作为单位。
1个Input vector进去之后，出来1个output vector，它的长度和vocabulary的size是一样的。他会给vocabulary的每一个单位一个分数，分数最高的就是最后的输出。5个input vector，出来n个output vector。(n需要decoder自己决定)
decoder看到的输入，其实就是前一个时间自己的输出。
这里有一个问题，如果输出错误，那么输入也会错误，会造成error propagation。 Decoder和Encoder对比 decoder与encoder结构类似 decoder有一层masked multi-head attention 之前的self-attention，都要看过完整的input之后才做决定。$b^1$是由$a^1$到$a^4$一起决定的。</description>
    </item>
    
    <item>
      <title>2023-02-13 chatGPT 在攻陷所有人</title>
      <link>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</link>
      <pubDate>Mon, 13 Feb 2023 20:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</guid>
      <description>承认吧，现在全世界最火就是chatGPT。
去参加了王建硕老师那边组织的关于chatGPT的讨论。
会上的讨论：对新技术进行哲学思考无疑是最让我震撼的。正因为他们进行深度思考，才能真正看到事物的本质，才能正确判断事物的走向。 从心理学和教育学来看，也开拓了我的眼界。 从高效使用和商业化来看，它无疑会改变很多人的生活。 chatGPT的使用感受很不错。
我试用的方面主要在让它生成一些小功能的代码，例如爬虫，处理数据，修bug等。之前google copilot出来的时候，我的感觉没有那么惊艳。copilot可以补全代码，但是很奇怪，它经常显示大段我不需要的代码，看着闹心。 如何让chatGPT有更好的效果呢？那就是写更好的prompt，也就是清晰简洁聚焦的提问。 昨天看了好几篇关于prompt的技术文章，原来国外的prompt的技术已经发展得很厉害了。 看了一些好的prompt的例子，给我一种扑面而来的熟悉感，这不就是高中时候老师出的题嘛。&amp;ldquo;请用XX写一篇关于XX的文章，文体限制在议论文，不超过800字。&amp;rdquo; 随着chatGPT兴起，产生了一种新的职业，叫做prompt engineer，他们的工作是研发出更好的提问方式，引导chatGPT给出的答案更符合用户的预期。 很多人的感受是和chatGPT对话，就像和一个小朋友交流。你不能给它一个宏大的问题，让它去解决。但是可以一步一步引导它，告诉它每一步做什么，最后达成自己的目标。 晚上我又看了几个chatGPT的应用，我看到的最惊艳的两个应用有两个。 第一个是语言学习，例如和azure结合起来，练习口语。或者让chatGPT修改文章，斟酌字词，问chatGPT某句话的某个词是什么意思，怎么理解。这个应用基本上是全世界人民的需求。只要有沟通和交流的需求在，就会想要学习新的语言。 试想一下，如果你有了语音版chatGPT，相当于你有了一个24小时的外教。当然openai和azure都需要api key，需要花一些钱。
第二个是用chatGPT生成文本，然后把这些文本用AI工具转成图片，最后形成动画或视频。现在很多人在做的抖音号视频号（其实就是垃圾营销）是可以用这种方式生成的。 当然作为一个技术人员，我肯定对底层原理感兴趣。最主要的创新点在于in-context learning、强化学习以及庞大的数据输入。公司在年前就请某个大佬在公司做了chatGPT的介绍，不得不说公司领导的嗅觉还是很灵敏的。 搞了几年互联网和AI，大家最后发现，科技的前沿还是在美国。国内大小厂只能跟在国际大厂的屁股后面。 它的缺点在于：
它的结果不准确。大量的例子表明它不擅长计算，并且文章写得稀里糊涂。所以它的结果是否是正确的，需要用户有能力做出判断。 模型未开源，可能永远也不会开源。 去年年底Notion推出Notion AI的时候，我就报名了。这个月7号收到官方的邮件说我可以使用了。我用Notion AI的感受也非常好。 它只要在notion里面打一个&amp;rsquo;/&amp;lsquo;就可以了。
它的功能有很多：
写博客、写文章 写诗 写文章总结 发朋友圈 翻译 改变文字的语气（严肃、轻松、正式、自信等） 所有的文章都可以变长变短 有一天晚上我给室友演示Notion AI，她是做别的行业，不太懂AI这些。那天晚上我刚好吃了咖喱牛腩，就让Notion AI以&amp;quot;咖喱牛腩&amp;quot;写一篇文章。 看着文字逐渐出来的时候，她不禁激动起来，惊呼&amp;quot;大厉害了，要是我有这样一个助手就好了&amp;quot;！ 有点感动，AI真的在改变我们的生活吧！</description>
    </item>
    
    <item>
      <title>2023-02-09 如何理解自注意力机制</title>
      <link>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Thu, 09 Feb 2023 08:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid>
      <description>理解输入与输出 输入有可能是一个 vector，有可能是多个 vector 输出： 一个序列对应一个 label。the whole sequence has a label 例子：在情感分析里面，This is good 对应的输入是多个 vector，输出为 positive，是一个vector。 一个 vector 对应一个 label。一个序列对应多个 label。 例子：在词性标注里面，This is good 对应的输入是多个 vector，输出为 代词，动词，形容词。 模型决定 label 的个数。seq2seq 任务 例子：在机器翻译里面，This is good 对应的输入是3个 vector，中文翻译是”不错“，输出为2个 vector。 一个vector对应一个label的情况，即输入和输出一样多，也叫做sequence labeling 例子： I saw a saw 如何解决 sequence labeling 的问题：用 fully connected network 对每一个 input vector 进行作用 弊端： 用 fully connected network 来输出，假设对 I saw a saw 做词性标注。对于 FC 层来说，两个 saw没有什么不同，但是他们实际上一个是动词，一个是名词。 解决思路：考虑更多的上下文。每一个 fc 层，都对所有的输入作用。或者给他一个 window，作用于相邻的几个 input vector。但是作用还是有限，计算也很复杂。 我们想考虑整个 sequence，但是不想把 sequence 所有的数据都包括在里面，就有了 self-attention。</description>
    </item>
    
    <item>
      <title>2023-01-31 如何用HuggingFace对不均衡类别进行分类</title>
      <link>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</link>
      <pubDate>Tue, 31 Jan 2023 19:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</guid>
      <description>数据均衡 做文本分类时，如果类别数量差别不大，可以用hugging face的Trainer类，训练代码如下：
model = BertForSequenceClassification.from_pretrained(&amp;#34;bert-base-chinese&amp;#34;, num_labels=len(labels), problem_type=&amp;#34;multi_label_classification&amp;#34;, id2label=id2label, label2id=label2id) tokenizer = BertTokenizerFast.from_pretrained(&amp;#34;bert-base-chinese&amp;#34;) def compute_metrics(p): preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions result = multi_label_metrics( predictions=preds, labels=p.label_ids) return result training_args = TrainingArguments( output_dir=model_directory, learning_rate=5e-5, per_device_train_batch_size=2, per_device_eval_batch_size=2, num_train_epochs=3, dataloader_drop_last=True, weight_decay=0.01, save_steps=50, logging_steps=50 ) trainer = Trainer( model=model, args=training_args, train_dataset=data[&amp;#34;train&amp;#34;], eval_dataset=data[&amp;#34;train&amp;#34;], tokenizer=tokenizer, compute_metrics=compute_metrics ) trainer.train() trainer.evaluate() model_directory 是模型存储路径，data是数据。
数据不均衡 如果类别数据不均衡时，例如 class A有1000个数据，class B有100个数据，也可以用上面的训练代码，但是预测B的效果不会很好。
要解决数据不均衡的问题，可以考虑加一个class weight。加class weight的意思是给class B一个更高的权重，让模型预测的时候多考虑一下class B，方向往class B偏离。
官网给了一个例子，需要我们继承Trainer类，自定义一个类，也就是这里的CustomTrainer，重写compute_loss 这个方法。</description>
    </item>
    
    <item>
      <title>2022-12-10 HuggingFace的Dataset的使用</title>
      <link>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 10 Dec 2022 18:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</guid>
      <description>hub上的数据集 （这里不是互联网上任意的数据集，专指Huggingface的hub上面的，就是可以用关键字直接下载的）
数据集可以在https://huggingface.co/datasets 找到，另外也可以用**datasets.list_datasets() 来看有什么数据集，然后通过关键字下载。
from datasets import list_datasets list_datasets(with_community_datasets = True, with_detaikls = False) 很多例子演示的时候，都是直接用hub上的数据集演示，但是我不知道这个数据集里面的构造，尽管照着例子运行成功了，但往往一头雾水。
此时我要看看这个数据集里面到底有啥东西，可以导入dataset builder来看看。（这个例子里面我们导入的数据集是”rotten_tomatoes”）。
!pip install datasets from datasets import load_dataset_builder ds_builder = load_dataset_builder(&amp;#34;rotten_tomatoes&amp;#34;) ds_builder.info.description Movie Review Dataset. This is a dataset of containing 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie reviews. This data was first used in Bo Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</description>
    </item>
    
    <item>
      <title>2022-10-24 在程序里起名有很多要注意的</title>
      <link>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</link>
      <pubDate>Mon, 24 Oct 2022 20:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</guid>
      <description>最近检查以前写的代码，发现我给不同的功能函数或者变量起的名不是很精确。 比如数据处理这个阶段，就很容易取 data_process， get_data，process_data，data_preprocess，deal_with_data 这些名字。再比如很多类的主入口，我经常会写 run()、xx_driver() 等等。
想一个名字看起来简单，但是新建文件那一刻抓耳挠腮肚子里墨水空空，想不到好名字，无奈最后写下写了很多遍的 get_data 。于是学习给不同的功能函数或者变量取一些适合的名字迫在眉睫。
今天看了关于两篇起名建议的文章，一篇是《变量名不要起得他妈的那么长》，链接在这 。 我跟着这篇文章反省了一下，有时候为了区分不同情况，我就会用下划线连接好几个单词，这样的话总体长度很长，不是很 pythonic。
作者给了几个建议：
不要容易看出类型的名字后面加上类型，例如 name 就不要叫 namestring。
写复数，不要用单数加 collection。例如 holidays 比 holiday_list 好些。
我这个问题还挺严重的，因为我很喜欢写 xx_list，yy_dict 等。
在写 func 的名字的时候，不需要把参数也写在功能函数名称里面，因为参数列表能够看出来要处理什么参数。例如 merge(table_cells) 比 merge_table_cells(x) 要好。
要精确，不需要把每一个细节都写出。例如 recentlyUpdatedAnnualSalesBid 这里面每一个单词细节都值得推敲，看是不是为了确保独一性而加的，没有就要去掉。
变量名不要包含能从上下文看出来的单词。如果类名里面已经包含的单词，在类方法就不用再写了。
例如类名有 data，已经表明了这个类是和数据相关。那么方法可以直接写 process，不需要写 data_process。
变量名不要包含无意义的单词。 这些单词包括：
data, state, amount, value, manager, engine, object, entity, and instance. Python 里面用类型注释很容易避免这些问题，就算用 results，不用 results_list 也可以很快看出 results 是一个 list，有时候是 list of list。
第二篇文章是这个《起名的那些事儿》，链接在这儿 。
对于起名他给的建议是：
对于类名、接口名： 用名词，不用形容词。</description>
    </item>
    
    <item>
      <title>2022-08-02 用 HanLP 分词时如何自定义词典</title>
      <link>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</link>
      <pubDate>Tue, 02 Aug 2022 17:51:00 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</guid>
      <description>在分词的过程中，碰到一个这样的句子：
&amp;lsquo;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;rsquo;
import hanlp tok = hanlp.load(hanlp.pretrained.tok.COARSE_ELECTRA_SMALL_ZH) sentence = &amp;#39;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;#39; sen_list = tok(sentence) print(sen_list) [&amp;#39;公司&amp;#39;, &amp;#39;产品&amp;#39;, &amp;#39;品质&amp;#39;, &amp;#39;持续&amp;#39;, &amp;#39;提升&amp;#39;, &amp;#39;，&amp;#39;, &amp;#39;单晶&amp;#39;, &amp;#39;硅&amp;#39;, &amp;#39;片&amp;#39;, &amp;#39;用&amp;#39;, &amp;#39;料&amp;#39;, &amp;#39;比例&amp;#39;, &amp;#39;大幅&amp;#39;, &amp;#39;高于&amp;#39;, &amp;#39;行业&amp;#39;, &amp;#39;平均&amp;#39;, &amp;#39;，&amp;#39;, &amp;#39;单晶&amp;#39;, &amp;#39;硅&amp;#39;, &amp;#39;料&amp;#39;, &amp;#39;价格&amp;#39;, &amp;#39;上涨&amp;#39;, &amp;#39;。&amp;#39;] 可以看出来，这里“单晶硅片”，“单晶硅料”， 被分为了“单晶”“硅”“料”和“单晶”“硅”“片”。
如果我们想要把“单晶硅”分出来。可以设置自定义词典。tok下面有两个参数：dict_force和dict_combine，通过设置这两个参数就可以达到自定义词典的效果。
dict_force和dict_combine有什么区别：
dict_force是强制模式，强制模式的优先级高于统计模型。如果强制模式用于所有文本，会对其他句子进行干扰，所以强制模式一般不用于所有文本，但是可以针对某个特定句子打补丁。
dict_combine是合并模式，合并模式的优先级低于统计模型。就是说句子先用统计模型分词，然后在这个分词的基础上，再进行最长匹配并合并。
先看一下dict_combine的例子：
tok.dict_force = None tok.dict_combine = {&amp;#39;单晶硅&amp;#39;} sentence = &amp;#39;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;#39; [&amp;#39;公司&amp;#39;, &amp;#39;产品&amp;#39;, &amp;#39;品质&amp;#39;, &amp;#39;持续&amp;#39;, &amp;#39;提升&amp;#39;, &amp;#39;，&amp;#39;, &amp;#39;单晶硅&amp;#39;, &amp;#39;片&amp;#39;, &amp;#39;用&amp;#39;, &amp;#39;料&amp;#39;, &amp;#39;比例&amp;#39;, &amp;#39;大幅&amp;#39;, &amp;#39;高于&amp;#39;, &amp;#39;行业&amp;#39;, &amp;#39;平均&amp;#39;, &amp;#39;，&amp;#39;, &amp;#39;单晶硅&amp;#39;, &amp;#39;料&amp;#39;, &amp;#39;价格&amp;#39;, &amp;#39;上涨&amp;#39;, &amp;#39;。&amp;#39;] 我们一般会用dict_combine，这样就把“单晶硅”分出来了。</description>
    </item>
    
  </channel>
</rss>
