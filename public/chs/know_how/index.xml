<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KNOW HOW on 徐慧志的个人博客</title><link>https://huizhixu.github.io/chs/know_how/</link><description>Recent content in KNOW HOW on 徐慧志的个人博客</description><generator>Hugo</generator><language>chs</language><lastBuildDate>Thu, 27 Nov 2025 13:55:11 +0000</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/know_how/index.xml" rel="self" type="application/rss+xml"/><item><title>2025-11-27 人脑的记忆和Agent的记忆是完全不同的</title><link>https://huizhixu.github.io/chs/know_how/20251127-%E4%BA%BA%E8%84%91%E7%9A%84%E8%AE%B0%E5%BF%86%E5%92%8Cagent%E7%9A%84%E8%AE%B0%E5%BF%86%E6%98%AF%E5%AE%8C%E5%85%A8%E4%B8%8D%E5%90%8C%E7%9A%84/</link><pubDate>Thu, 27 Nov 2025 13:55:11 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251127-%E4%BA%BA%E8%84%91%E7%9A%84%E8%AE%B0%E5%BF%86%E5%92%8Cagent%E7%9A%84%E8%AE%B0%E5%BF%86%E6%98%AF%E5%AE%8C%E5%85%A8%E4%B8%8D%E5%90%8C%E7%9A%84/</guid><description>&lt;p&gt;最近在看 Agent 记忆的一些设计，调研了4个流行的框架（MEM0、LangGraph、ZeP、ADK）之后，我发现这些框架在记忆部分其实都比较雷同——无论是短期记忆还是长期记忆，本质上都是引入一些外部知识，或者增加一个数据存储层。&lt;/p&gt;
&lt;p&gt;短期记忆一般指当前会话中出现的消息、临时变量和当前状态，它只在当前运行的线程或 session 内有效。&lt;/p&gt;
&lt;p&gt;长期记忆则是经过 LLM 提炼后的一些事实、事件或语义关系，是更持久的信息，对未来其他会话也可见。&lt;/p&gt;
&lt;p&gt;在这个过程中，我比较关注的是短期记忆如何转化为长期记忆。结果发现，最后一步仍然需要依赖大模型来做转换。也就是说，只要明确定义好长期记忆和短期记忆的结构，就可以在对话中实现这种转化。&lt;/p&gt;
&lt;p&gt;之后我又去调研了一下人脑的记忆机制，发现 Agent 的记忆和人脑记忆其实是完全不同的。Agent 的记忆只能说强行模仿人类记忆的分类方式，分为短期和长期，但只是套了个壳子，内部运行机制完全不一样。人脑处理记忆是一个极其复杂的生物学过程，记忆的载体是神经元和突触之间的连接。&lt;/p&gt;
&lt;p&gt;如果人类是唯一有智能的生物，那么 AIGC的路还远着呢！&lt;/p&gt;
&lt;h2 id="一记忆的形成和存储"&gt;一、记忆的形成和存储&lt;/h2&gt;
&lt;p&gt;记忆的形成和存储大致可以分为三个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过编码初步获取信息
编码是记忆形成的第一步，指将外界的感觉信息（视觉、听觉、触觉等）转化为大脑可以处理和存储的神经表征。这个过程是高度选择性的，并不是所有进入感官的信息都会被编码。注意力在其中起到关键作用，它决定了哪些信息能优先进入工作记忆或短期记忆。比如在咖啡馆，你能专注于和朋友的对话，而忽略周围的背景噪音。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;编码的深度和质量会直接影响记忆的强度和持久性。深层次的理解和与已有知识的联系，比机械重复更能促进长期记忆的形成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过巩固来强化记忆
巩固是指新形成的不稳定记忆痕迹逐渐转变为稳定、持久的长期记忆的过程。它分为两个层面：突触巩固和系统巩固。突触巩固发生在学习后的几分钟到几小时内，主要涉及突触连接的局部生化改变，比如长时程增强（LTP）的诱导和维持。系统巩固则更缓慢，可能持续数周到数年，涉及记忆在不同脑区之间的重新组织和转移。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分布式按功能存储记忆
存储是指记忆信息在大脑中被长期保持的过程。记忆并非存储在单一位置，而是分布式地存储于由大量神经元相互连接构成的复杂神经回路中，其核心是突触结构的改变。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，对一个朋友的记忆，可能包括面孔（存储在颞叶的视觉皮层）、名字（存储在语言相关区域）、声音（存储在听觉皮层）以及情感（存储在杏仁核等边缘系统结构）等多个组成部分，它们通过神经连接整合在一起。&lt;/p&gt;
&lt;h2 id="二短期记忆和长期记忆"&gt;二、短期记忆和长期记忆&lt;/h2&gt;
&lt;h3 id="短期记忆"&gt;短期记忆&lt;/h3&gt;
&lt;p&gt;短期记忆是指信息在大脑中保持几秒到一分钟左右的记忆系统。它的容量非常有限，通常认为只能同时存储几个信息单元（如数字、字母等）。短期记忆容量小、持续时间短，容易受干扰，主要作为信息处理的临时工作台，用于暂时保持和操作信息，指导当前的决策和行为。&lt;/p&gt;
&lt;p&gt;比如拨电话时，你会短暂记住一串号码，打完就忘。&lt;/p&gt;
&lt;p&gt;工作记忆是对短期记忆的拓展，它不仅包括信息的暂时存储，还包括对信息的加工和操作，比如心算或逻辑推理。&lt;/p&gt;
&lt;h3 id="长期记忆"&gt;长期记忆&lt;/h3&gt;
&lt;p&gt;长期记忆是指信息在大脑中保持数小时、数天、数年甚至终生的记忆系统。它的容量几乎是无限的，相对稳定，不易受干扰。长期记忆的形成需要将短期记忆中不稳定的神经活动模式转化为持久的、结构性的改变，这个过程就是巩固。&lt;/p&gt;
&lt;p&gt;长期记忆可以分为外显记忆和内隐记忆。外显记忆也叫陈述性记忆，包括对个人经历和事件的情景记忆，以及对事实、概念等知识的语义记忆。内隐记忆则包括程序性记忆（如技能和习惯）、启动效应等。这些不同类型的长期记忆依赖于不同的脑区网络。&lt;/p&gt;
&lt;h3 id="短期记忆是如何转化为长期记忆的"&gt;短期记忆是如何转化为长期记忆的？&lt;/h3&gt;
&lt;p&gt;这个问题本身可能就不太准确，因为长期记忆不一定是短期记忆直接“转化”来的，更准确的说法是长期记忆的巩固。&lt;/p&gt;
&lt;p&gt;2017年MIT的研究表明，在学习事件发生时，记忆痕迹同时在海马体和大脑皮层的长期存储位置形成。但在早期，皮层中的记忆痕迹处于沉默状态，无法被主动提取。只有当这些痕迹逐渐成熟后，才能独立于海马体被提取。这说明记忆巩固不是简单的信息转移，而是海马体和皮层并行处理、相互作用的结果。&lt;/p&gt;
&lt;p&gt;传统的记忆巩固模型认为，新记忆最初依赖于海马体编码和短期存储，然后通过系统巩固逐渐转移到大脑皮层进行长期存储。&lt;/p&gt;
&lt;p&gt;除了海马体，睡眠（特别是慢波睡眠）在记忆巩固中也扮演着重要角色，它通过“重放”白天的学习经历来加强和稳定记忆痕迹。&lt;/p&gt;
&lt;h2 id="agent-记忆借鉴人类记忆的部分"&gt;Agent 记忆借鉴人类记忆的部分&lt;/h2&gt;
&lt;p&gt;那么，Agent 记忆设计到底借鉴了人脑记忆的哪些部分？&lt;/p&gt;
&lt;p&gt;其实主要就是分类方式。Agent 也引入了外显记忆和内隐记忆的概念：外显记忆包括情景记忆和语义记忆，内隐记忆包括程序性记忆、启动效应等。&lt;/p&gt;
&lt;p&gt;情景记忆（Episodic Memory）就是记下某一次具体经历。比如“昨天下午在星巴克和王老师一起喝了杯拿铁”，这个记忆里包含了时间、地点、人物和当时的感受，主要解决When Where Who 这样的问题。&lt;/p&gt;
&lt;p&gt;语义记忆（Semantic Memory）则是关于事实的知识。比如“拿铁是咖啡和牛奶混合的饮料”，这个知识不依赖于某次具体经历，而是作为一个客观事实存在。它回答的是What的问题。这种记忆通常是从多次类似经历中慢慢提炼出来的。&lt;/p&gt;
&lt;p&gt;程序性记忆（Procedural Memory）是关于“怎么做”的记忆。比如你知道怎么冲泡一杯拿铁——怎么操作咖啡机，怎么打奶泡。这种记忆需要反复练习才能形成，但一旦学会了就很难忘记，就像骑自行车一样。它解决How的问题。&lt;/p&gt;
&lt;p&gt;有意思的是，当我们想到“拿铁”这个词的时候，这三种记忆往往会同时被激活：我们知道它是什么（语义记忆），可能想起某次喝拿铁的经历（情景记忆），还知道怎么制作它（程序性记忆）。它们共同构成了我们对一个事物的完整认识。&lt;/p&gt;
&lt;p&gt;我还做了一个思维导图，可以从文件里下载查看。&lt;/p&gt;</description></item><item><title>2025-11-05 从零构建大模型—针对分类的微调</title><link>https://huizhixu.github.io/chs/know_how/20251105%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%92%88%E5%AF%B9%E5%88%86%E7%B1%BB%E7%9A%84%E5%BE%AE%E8%B0%83/</link><pubDate>Wed, 05 Nov 2025 13:54:46 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251105%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%92%88%E5%AF%B9%E5%88%86%E7%B1%BB%E7%9A%84%E5%BE%AE%E8%B0%83/</guid><description>&lt;p&gt;这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。&lt;/p&gt;
&lt;p&gt;微调通常可分为以下三个阶段：&lt;/p&gt;
&lt;p&gt;第一阶段：数据准备&lt;/p&gt;
&lt;p&gt;包括下载数据集、进行数据预处理以及构建数据加载器。&lt;/p&gt;
&lt;p&gt;第二阶段：模型准备&lt;/p&gt;
&lt;p&gt;涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。&lt;/p&gt;
&lt;p&gt;第三阶段：模型微调与部署&lt;/p&gt;
&lt;p&gt;包括执行模型微调、评估微调效果，以及在新数据上进行推理。&lt;/p&gt;
&lt;p&gt;在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&amp;quot;垃圾消息&amp;quot;或&amp;quot;非垃圾消息&amp;quot;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。&lt;/p&gt;
&lt;h2 id="第一阶段准备数据"&gt;第一阶段：准备数据&lt;/h2&gt;
&lt;h3 id="1-下载数据"&gt;1. 下载数据&lt;/h3&gt;
&lt;p&gt;网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。&lt;/p&gt;
&lt;h3 id="2-数据集预处理"&gt;2. 数据集预处理&lt;/h3&gt;
&lt;p&gt;预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; uu &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; encode
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; torch.utils.data &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; Dataset
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; tiktoken
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; pandas &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;SpamDataset&lt;/span&gt;(Dataset):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, csv_file, tokenizer, max_len&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;200&lt;/span&gt;,pad_token_id&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50256&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;csv_file &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; csv_file
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;read_csv(csv_file, sep&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#39;&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;\\&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;t&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;[tokenizer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encode(text) &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; text &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#39;text&amp;#39;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; max_len
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processed_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; encoded &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 截断到最大长度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; truncated &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; encoded[:&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 填充到最大长度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; padded &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; truncated &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; [pad_token_id] &lt;span style="color:#ff79c6"&gt;*&lt;/span&gt; (&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;max_len &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(truncated))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processed_texts&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(padded)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; processed_texts
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__getitem__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, index):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encoded_texts[index]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; label &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;iloc[index][&lt;span style="color:#f1fa8c"&gt;&amp;#39;label&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; (torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tensor(encoded, dtype&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;long), torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tensor(label, dtype&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;long))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__len__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;data)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="3-创建数据加载器"&gt;3. 创建数据加载器&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;train_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(train_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;val_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(val_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;test_loader &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DataLoader(test_dataset, batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;batch_size, shuffle&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;, num_workers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;num_worker)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="第二阶段修改模型"&gt;第二阶段：修改模型&lt;/h2&gt;
&lt;h3 id="1-模型初始化"&gt;1. 模型初始化&lt;/h3&gt;
&lt;p&gt;GPTModel是在《徒手组装GPT》章节中构建好的类。&lt;/p&gt;</description></item><item><title>2025-11-03 读 AutoGen 论文</title><link>https://huizhixu.github.io/chs/know_how/20251103%E8%AF%BB-autogen-%E8%AE%BA%E6%96%87/</link><pubDate>Mon, 03 Nov 2025 13:55:08 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251103%E8%AF%BB-autogen-%E8%AE%BA%E6%96%87/</guid><description>&lt;p&gt;最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。&lt;/p&gt;
&lt;p&gt;最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。&lt;/p&gt;
&lt;h2 id="1-什么是autogen"&gt;1. 什么是AutoGen？&lt;/h2&gt;
&lt;p&gt;简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。&lt;/p&gt;
&lt;h3 id="11-核心需求"&gt;1.1 核心需求&lt;/h3&gt;
&lt;p&gt;AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：&lt;/p&gt;
&lt;p&gt;1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？&lt;/p&gt;
&lt;p&gt;2.如何开发一个能够适应多种智能体对话模式的统一接口？&lt;/p&gt;
&lt;h3 id="12-技术可行性"&gt;1.2 技术可行性&lt;/h3&gt;
&lt;p&gt;AutoGen的提出基于三个关键的技术可行性因素。&lt;/p&gt;
&lt;p&gt;首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。&lt;/p&gt;
&lt;p&gt;其次，智能体能够提供或者接收推理、观察、评价和验证。&lt;/p&gt;
&lt;p&gt;最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。&lt;/p&gt;
&lt;h2 id="2-核心概念"&gt;2. 核心概念&lt;/h2&gt;
&lt;h3 id="21-可定制化智能体customizable-and-conversable-agents"&gt;2.1 可定制化智能体（Customizable and conversable agents）&lt;/h3&gt;
&lt;p&gt;AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。&lt;/p&gt;
&lt;h3 id="22-对话编程范式conversation-programming"&gt;2.2 对话编程范式（Conversation programming）&lt;/h3&gt;
&lt;p&gt;AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：&lt;/p&gt;
&lt;p&gt;1.定义具有特定能力和角色的可对话智能体集合&lt;/p&gt;
&lt;p&gt;2.通过以对话为中心的计算和控制来编程智能体间的交互行为&lt;/p&gt;
&lt;h2 id="3-智能体能力体系"&gt;3. 智能体能力体系&lt;/h2&gt;
&lt;h3 id="31-三大能力来源"&gt;3.1 三大能力来源&lt;/h3&gt;
&lt;p&gt;AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。&lt;/p&gt;
&lt;h3 id="311-大型语言模型能力"&gt;3.1.1 大型语言模型能力&lt;/h3&gt;
&lt;p&gt;基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。&lt;/p&gt;
&lt;h3 id="312-人类参与能力"&gt;3.1.2 人类参与能力&lt;/h3&gt;
&lt;p&gt;AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。&lt;/p&gt;
&lt;h3 id="313-工具执行能力"&gt;3.1.3 工具执行能力&lt;/h3&gt;
&lt;p&gt;工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。&lt;/p&gt;
&lt;h3 id="32-智能体分类体系"&gt;3.2 智能体分类体系&lt;/h3&gt;
&lt;p&gt;AutoGen建立了完整的智能体分类体系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具&lt;/li&gt;
&lt;li&gt;AssistantAgent：ConversableAgent的子类，专门用于AI助手功能&lt;/li&gt;
&lt;li&gt;UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具&lt;/li&gt;
&lt;li&gt;GroupChatManager：用于管理群组对话的专门组件&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="4-对话编程机制"&gt;4. 对话编程机制&lt;/h2&gt;
&lt;h3 id="41-编程模式"&gt;4.1 编程模式&lt;/h3&gt;
&lt;p&gt;对话编程范式需要考虑两个关键维度：&lt;/p&gt;
&lt;p&gt;1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动&lt;/p&gt;
&lt;p&gt;2.控制流（Control Flow）：计算发生的条件&lt;/p&gt;
&lt;h3 id="42-自动回复机制"&gt;4.2 自动回复机制&lt;/h3&gt;
&lt;p&gt;AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。&lt;/p&gt;
&lt;p&gt;智能体自动回复机制是AutoGen的核心特性：&lt;/p&gt;</description></item><item><title>2025-11-01 从零构建大模型—通过微调遵循人类指令</title><link>https://huizhixu.github.io/chs/know_how/20251101-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E5%BE%AE%E8%B0%83%E9%81%B5%E5%BE%AA%E4%BA%BA%E7%B1%BB%E6%8C%87%E4%BB%A4/</link><pubDate>Sat, 01 Nov 2025 13:55:35 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251101-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E5%BE%AE%E8%B0%83%E9%81%B5%E5%BE%AA%E4%BA%BA%E7%B1%BB%E6%8C%87%E4%BB%A4/</guid><description>&lt;p&gt;终于来到这本书的最后一章啦。&lt;/p&gt;
&lt;p&gt;这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）&lt;/p&gt;
&lt;p&gt;当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。&lt;/p&gt;
&lt;p&gt;接下来是本章的内容：&lt;/p&gt;
&lt;p&gt;预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。
但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。&lt;/p&gt;
&lt;p&gt;这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。&lt;/p&gt;
&lt;p&gt;第一阶段：数据准备&lt;/p&gt;
&lt;p&gt;包括下载数据集、进行数据预处理以及构建数据加载器。&lt;/p&gt;
&lt;p&gt;第二阶段：模型微调&lt;/p&gt;
&lt;p&gt;包括加载预训练大语言模型、执行指令微调以及监控模型损失。&lt;/p&gt;
&lt;p&gt;第三阶段：评估大语言模型&lt;/p&gt;
&lt;p&gt;包括提取模型回复、进行量化评估以及对生成内容打分。&lt;/p&gt;
&lt;h2 id="第一阶段数据准备"&gt;第一阶段：数据准备&lt;/h2&gt;
&lt;h3 id="1-下载数据"&gt;1. 下载数据&lt;/h3&gt;
&lt;p&gt;可以使用网上已有的数据集：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;url &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;指令微调所需的数据是“输入-输出”对。例如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {&lt;span style="color:#f1fa8c"&gt;&amp;#39;instruction&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#39;Identify the correct spelling of the following word.&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;input&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#39;Ocassion&amp;#39;&lt;/span&gt;, 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;output&amp;#39;&lt;/span&gt;: &lt;span style="color:#f1fa8c"&gt;&amp;#34;The correct spelling is &amp;#39;Occasion.&amp;#39;&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Below &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt; an instruction that describe a task&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt; Write a response that appropriately
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; complete the request&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Instruction:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Identify the correct spelling of the following word&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Input:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; Ocassion
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;### Output&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The correct spelling &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;Occasion&amp;#39;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-数据集预处理"&gt;2. 数据集预处理&lt;/h3&gt;
&lt;p&gt;数据下载后，需要将样本填充至相同长度，并进行批次处理。&lt;/p&gt;</description></item><item><title>2025-10-28 MiniMax Agent（M2）有惊喜也有失望</title><link>https://huizhixu.github.io/chs/know_how/20251028-minimax-agentm2%E6%9C%89%E6%83%8A%E5%96%9C%E4%B9%9F%E6%9C%89%E5%A4%B1%E6%9C%9B/</link><pubDate>Tue, 28 Oct 2025 13:54:09 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251028-minimax-agentm2%E6%9C%89%E6%83%8A%E5%96%9C%E4%B9%9F%E6%9C%89%E5%A4%B1%E6%9C%9B/</guid><description>&lt;p&gt;MiniMax发布了M2模型，同时限免了Agent。他们Agent之前的Slogan是“Code is cheap, show me the requirement”，擅长的任务包括代码开发、PPT生成等功能。它据说是“国内最好用的Agent”。&lt;/p&gt;
&lt;p&gt;我之前想开会员，但看到最基础的定价一个月39刀，比Codex和Cursor还贵，就放弃了。不过最近MiniMax在M2发布期间限时免费，嘿嘿，所以我又回来用了。&lt;/p&gt;
&lt;h2 id="总结"&gt;总结&lt;/h2&gt;
&lt;p&gt;MiniMax Agent 确实具备完成任务的能力。模型方面既可以选择免费的轻量版本，也可以选用旗舰模型。它的一个显著优点是，在执行任务前会先进行判断——如果任务本身可以由更简单的模型完成，就无需创建复杂计划或委托给其他代理。&lt;/p&gt;
&lt;p&gt;与其他智能体一样，MiniMax 在执行任务时支持实时查看进度，随时调试，也支持下载代码到本地运行，甚至还提供版本回滚功能。&lt;/p&gt;
&lt;p&gt;我对整体功能和完成度是比较满意的。&lt;/p&gt;
&lt;p&gt;不过，它也有一些令人失望的地方。&lt;/p&gt;
&lt;p&gt;对于编码任务，我们为什么不用 Cursor、Codex 或 Trae 这类专门工具呢？在网页上编码和调试非常不便，例如第一个“电子衣橱”任务，反复运行多次，每次都要重新下载代码、安装环境、运行程序，过程相当繁琐。如果能直接在 IDE 中修改，体验会好很多。而在其他任务类型上——比如生成绘本、数据可视化或制作 PPT——这些智能体之间的差距又有多大呢？是否足以让我坚定选择 A 而非 B？目前看来，我并不那么确定，因为它们在表现上似乎相差不大。&lt;/p&gt;
&lt;p&gt;MiniMax 有一个比较有意思的功能是 Gallery 中的“remix”，我可以基于他人已有的代码进行修改和呈现。但问题是，有多少人会和我有同样的需求呢？&lt;/p&gt;
&lt;p&gt;我做了三个测试。&lt;/p&gt;
&lt;h2 id="第一个任务电子衣橱"&gt;第一个任务：电子衣橱&lt;/h2&gt;
&lt;p&gt;第一个任务非常难。最近换季了，我想做一个电子衣橱，用来管理穿衣和搭配。市面上的电子衣橱产品都限制上传张数，不好用。所以我想在本地自己做一个纯自用的产品demo。&lt;/p&gt;
&lt;p&gt;我写了一份产品文档，然后它开始运行。&lt;/p&gt;
&lt;p&gt;这是它的呈现。它的第一步是规划和确认。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/59900dc5.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这里不得不提一个很有用的功能——revert。因为我确认的时候打错了字，小的typo会造成歧义，所以我用这个 restore checkpoint 功能直接回到了“需要确认”这一步，然后输入正确的即可。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/446c18ff.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;任务完成后，它交付给我一个项目代码包，包含各种详细文档和启动代码说明。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/fccee854.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我按照启动代码说明在本地启动，中间没有出现错误。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/ef0707fe.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这是代码启动后的界面，看起来还不错。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/695e32e5.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我点击“添加物品”和“记录穿搭”，里面是空白的，这些功能还没有实现。&lt;/p&gt;
&lt;p&gt;于是我进行了一轮反馈：“添加物品和记录穿搭这两个页面都是空白的，请帮我实现这两页，让我可以真正使用。”然后它开始修复bug。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/85db979f.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;重新下载它交付的代码，运行起来没有问题。点击“添加物品”，这次页面有内容了。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/74a91da4.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我填入了一些信息，发现一个bug导致无法进入下一步，于是进行了第三轮对话，要求修复这个问题。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/29b2808b.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;它调试时的做法还是很清晰的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/190c32b2.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;这里我发现每次下载的文件夹都叫 package.zip，感觉有覆盖的风险。&lt;/p&gt;
&lt;p&gt;再次打开，一切顺利，现在功能有了。但添加物品失败，我又去反馈了，第四轮。修复好后，分类又没了。再次反馈，第五轮。这样来来回回多次之后，还是添加不了物品。&lt;/p&gt;
&lt;h2 id="第二个任务把河童做成绘本"&gt;第二个任务：把《河童》做成绘本&lt;/h2&gt;
&lt;p&gt;第二个测试是把将杨千嬅《河童》做成绘本的prompt直接给MiniMax。&lt;/p&gt;
&lt;p&gt;它先规划步骤，让用户确认。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251028/a8351589.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;在程序运行的过程中，我一张一张查看生成的图片，比较震惊的是发现其中一张与 OK Computer 生成的画面非常相似（这个画面对应的歌词是“令这世界别冻”）。&lt;/p&gt;
&lt;p&gt;这是MiniMax Agent生成的：&lt;/p&gt;</description></item><item><title>2025-10-17 月之暗面的OK Computer还可以更好</title><link>https://huizhixu.github.io/chs/know_how/20251017%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2%E7%9A%84ok-computer%E8%BF%98%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%A5%BD/</link><pubDate>Fri, 17 Oct 2025 12:50:41 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251017%E6%9C%88%E4%B9%8B%E6%9A%97%E9%9D%A2%E7%9A%84ok-computer%E8%BF%98%E5%8F%AF%E4%BB%A5%E6%9B%B4%E5%A5%BD/</guid><description>&lt;p&gt;体验了一下Moonshot新推出的OK computer，这个产品最大的特点是端到端训练，model as agent，在训练时就已经把agent的能力融入到模型里面了。&lt;/p&gt;
&lt;p&gt;OK Computer说自己能够独立完成网站开发、数据分析、图像视频生成及高质量PPT制作。它的定位为“你专属的AI产品与工程团队“，但是交付的形式是产品本身，而不是像TRAE一样交付的是代码。&lt;/p&gt;
&lt;p&gt;我给它的第一个任务是做一个PPT，因为8月份我用过kimi里面的PPT助手，想对比看一下这次的提升。&lt;/p&gt;
&lt;p&gt;8月份那次制作PPT，要自己选择模版、上传文档，而kimi只能大概做一个基础性的框架，内容很少，图片和表格都需要手动补充。&lt;/p&gt;
&lt;p&gt;这一次不需要选择模版，直接上传文档，我给的指令很简单，是“帮我根据文档进行生成PPT”，就开始了。最终生成的6页幻灯片，风格令人惊艳，知识点拆解也重点突出。整体效果比起8月份那次，真的进步太多。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/36797f09.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/e8df851b.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;我给的第二个任务是让它把一段文本做成绘本。&lt;/p&gt;
&lt;p&gt;官网有一个例子是把以前的课文《口技》做成绘本，有图像，也有环境音，感觉很生动。&lt;/p&gt;
&lt;p&gt;我仿照官网案例，尝试将杨千嬅的歌曲《河童》制成一个可交互的水彩风网页绘本。《河童》这首歌有画面，有意境，很适合AI创作。&lt;/p&gt;
&lt;p&gt;我用的提示词是官网的《口技》的例子修改而来。&lt;/p&gt;
&lt;p&gt;虽然这是个网页版agent，但是有一个可视化界面，左边是任务的规划和完成情况，会先创立一个任务列表，然后一项一项的执行，执行完打勾。右边是实时界面，可以看到这个过程生成的所有的文档、图片和音频等。&lt;/p&gt;
&lt;p&gt;任务列表：&lt;/p&gt;
&lt;p&gt;执行过程中中的所有文件都能浏览，最后也可以打包下载。&lt;/p&gt;
&lt;p&gt;最终出来的结果是这样的，看到时我感觉超出了预期。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/c43d9970.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;总的画面是这样的，还是很美的。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/af7fa845.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;第一幕还蛮好的，有画面，有互动，有音乐。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/9e5ba6eb.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;但是接着问题就出现了，点击“下一幕”后，URL显示已进入第二个页面，但画面仍停留在第一个。反馈修复了之后也依然不行。并且发现额度已经用完了。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251017/1785576d.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;OK Computer展现的能力是强大的。生成了详细的任务清单，并逐步执行，最终输出了包括13张插图、13段音效及完整网页代码在内的成品，中间的步骤我看了，它生成的交互文档和专业设计文档都十分全面，任务执行也精准到位。&lt;/p&gt;
&lt;p&gt;唯一遗憾的是，即便遵循了官方优秀案例，最终成品仍存在影响使用的前端Bug，距离完美仅一步之遥。这一步之遥让我纠结这会员到底开还是不开啊。&lt;/p&gt;</description></item><item><title>2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks</title><link>https://huizhixu.github.io/chs/know_how/20251001-%E5%A7%9A%E9%A1%BA%E9%9B%A8%E5%8D%9A%E5%A3%AB%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93-language-agentsbenchmarks-methods-and-frameworks/</link><pubDate>Wed, 01 Oct 2025 14:11:50 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20251001-%E5%A7%9A%E9%A1%BA%E9%9B%A8%E5%8D%9A%E5%A3%AB%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93-language-agentsbenchmarks-methods-and-frameworks/</guid><description>&lt;p&gt;不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。&lt;/p&gt;
&lt;p&gt;视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4&lt;/p&gt;
&lt;p&gt;注：文中所有的图都来自上面视频链接，文中不再注明&lt;/p&gt;
&lt;h1 id="概览"&gt;概览&lt;/h1&gt;
&lt;p&gt;Agent：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Rule-based agents: manual design 人工写规则&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learning-based agents: trial-and-error 靠试错学习&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Language agents: reasoning to act 先用语言推理，再行动
Environment：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with humans/physical world 与人交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with games/simulation 与游戏交互&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Interact with the digital world (Internet) 与互联网交互
Challenges:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Accessible methods for general agents&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Scalable benchmarks for practical tasks
主要的研究：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 1: Benchmarking agents via digital automation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 2: Building language agents that reason to act&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part 3: Principled framework for language agents&lt;/p&gt;</description></item><item><title>2025-09-21 从零构建大模型—文本生成策略</title><link>https://huizhixu.github.io/chs/know_how/20250921%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5/</link><pubDate>Sun, 21 Sep 2025 13:55:34 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250921%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5/</guid><description>&lt;p&gt;在解码的时候，生成的词元是从词汇表的所有词元中选择概率分数最大的那一个，也就是argmax最大的词元id，但是这种形式让大模型失去丰富性，因为多次运行大模型生成的文本是相同的。&lt;/p&gt;
&lt;p&gt;两种技术（温度缩放和Top-k采样）可以用于文本生成的优化。&lt;/p&gt;
&lt;h2 id="温度缩放"&gt;温度缩放&lt;/h2&gt;
&lt;p&gt;用一个从概率分布（这里是大语言模型在每个词元生成步骤为每个词汇条目生成的概率分数）中采样的函数来取代argmax。&lt;/p&gt;
&lt;p&gt;这个概率采样函数Multinomial按照词汇表的概率分数采样下一个词元。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;argmax 永远挑概率最大的那个；&lt;/li&gt;
&lt;li&gt;multinomial 按概率分布随机抽签——大概率事件只是“中签率高”，并非 100 %。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;torch.manual_seed(123)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;next_token_id = torch.multinomial(probas, num_samples=1).item()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(inverse_vocab[next_token_id])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过一个称为温度缩放的概念，可以进一步控制分布和选择过程。温度缩放指的是将logits除以一个大于0的数。温度大于1会导致词元概率更加均匀分布，而小于1的温度将导致更加自信（更尖锐或更陡峭）的分布。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def softmax_with_temperature(logits, temperature):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; scaled_logits = logits / temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return torch.softmax(scaled_logits, dim=0)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用非常小的温度（如0.1）会导致更集中的分布，使得multinomial函数几乎100%选择最可能的词元，接近于argmax函数的行为。温度增大会导致更均匀的分布，使得其他词元更容易被选中。这可以为生成的文本增加更多变化，但也更容易生成无意义的文本。&lt;/p&gt;
&lt;h3 id="设置温度"&gt;设置温度&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;vocab = {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;closer&amp;#34;: 0,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;every&amp;#34;: 1,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;effort&amp;#34;: 2,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;forward&amp;#34;: 3,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;inches&amp;#34;: 4,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;moves&amp;#34;: 5,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;pizza&amp;#34;: 6,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;toward&amp;#34;: 7,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;you&amp;#34;: 8,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;inverse_vocab = {v: k for k, v in vocab.items()}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;next_token_logits = torch.tensor(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def softmax_with_temperature(logits, temperature):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; scaled_logits = logits / temperature
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return torch.softmax(scaled_logits, dim=0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;probas = softmax_with_temperature(next_token_logits, temperature=5)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def print_sampled_tokens(probas):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; torch.manual_seed(123)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sample = [torch.multinomial(probas, num_samples=1).item()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for i in range(1_000)]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sampled_ids = torch.bincount(torch.tensor(sample))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for i, freq in enumerate(sampled_ids):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; print(f&amp;#34;{freq} x {inverse_vocab[i]}&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print_sampled_tokens(probas)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="top-k-采样"&gt;Top K 采样&lt;/h2&gt;
&lt;p&gt;较高的温度值会让下一个词元的概率分布更加均匀，从而产生更加多样化的输出。但是有时候会产生语法不正确或者完全无意义的输出。&lt;/p&gt;</description></item><item><title>2025-09-14 从零构建大模型—在无监督数据上进行预训练</title><link>https://huizhixu.github.io/chs/know_how/20250914%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%97%A0%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E9%A2%84%E8%AE%AD%E7%BB%83/</link><pubDate>Sun, 14 Sep 2025 13:54:05 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250914%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9C%A8%E6%97%A0%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E9%A2%84%E8%AE%AD%E7%BB%83/</guid><description>&lt;p&gt;这一章主要分为以下三个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;评估生成文本的质量&lt;/li&gt;
&lt;li&gt;训练函数&lt;/li&gt;
&lt;li&gt;对大模型进行预训练&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="一前情提要"&gt;一、前情提要&lt;/h1&gt;
&lt;h2 id="文本生成前几章讲过的"&gt;文本生成（前几章讲过的）&lt;/h2&gt;
&lt;p&gt;步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分词器将输入文本转换成一系列词元ID&lt;/li&gt;
&lt;li&gt;模型接收词元ID，并生成相应的logits&lt;/li&gt;
&lt;li&gt;这些logits被转换回词元ID，分词器会将其解码为人类可读的文本
logits是表示词汇表中每个词元的概率分布的向量。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;logits 怎么理解：&lt;/p&gt;
&lt;p&gt;logits 是“未归一化”的概率分数向量。经过 softmax 后，logits 变成“概率分布”。&lt;/p&gt;
&lt;p&gt;logits 的用途：&lt;/p&gt;
&lt;p&gt;在推理阶段，取 logits 的 argmax 即可得到每个位置最可能的词元；也可以对 logits 应用温度缩放、Top-K、核采样等技术，再做 multinomial 采样，以平衡多样性与一致性。&lt;/p&gt;
&lt;h2 id="权重参数"&gt;权重参数&lt;/h2&gt;
&lt;p&gt;权重参数指的是在训练过程调整的参数。&lt;/p&gt;
&lt;p&gt;PyTorch允许通过model.parameters()方法直接访问模型的所有可训练参数（包括Weights和Biases）&lt;/p&gt;
&lt;h1 id="二评估文本生成"&gt;二、评估文本生成&lt;/h1&gt;
&lt;h2 id="初始化"&gt;初始化&lt;/h2&gt;
&lt;p&gt;用GPT_CONFIG_124M字典初始化GPTModel类，注意这里只是搭了个框架，随机初始化权重，所以模型生成的文本也是随机生成。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;from gpt2_module.gpt2 import GPTModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;GPT_CONFIG_124M ={
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;vocab_size&amp;#34;:50257,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;context_length&amp;#34;:1024,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;emb_dim&amp;#34;:768,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;n_heads&amp;#34;:12,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;n_layers&amp;#34;:12,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;drop_rate&amp;#34;:0.1,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &amp;#34;qkv_bias&amp;#34;:False
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def generate_text_simple(model, idx, max_new_tokens, context_size):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; for _ in range(max_new_tokens):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 将当前文本截断至大模型支持的长度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx_cond = idx[:, -context_size:]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; with torch.no_grad():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits = model(idx_cond)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 仅关注最后一个时间步的logits
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits = logits[:, -1, :]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 转换为概率分布
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; probs = torch.softmax(logits, dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 采样下一个token
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx_next = torch.argmax(probs, dim=-1, keepdim=True)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; # 拼接采样的token
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx = torch.cat((idx, idx_next), dim=1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return idx
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def text_to_token_ids(text, tokenizer):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded = tokenizer.encode(text, allowed_special={&amp;#39;&amp;lt;|endoftext|&amp;gt;&amp;#39;})
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoded_tensor = torch.tensor(encoded).unsqueeze(0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return encoded_tensor
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def token_ids_to_text(token_ids, tokenizer):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; flat = token_ids.squeeze(0)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; return tokenizer.decode(flat.tolist())
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;start_context = &amp;#34;Every effort moves you&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tokenizer = tiktoken.get_encoding(&amp;#34;gpt2&amp;#34;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model = GPTModel(GPT_CONFIG_124M)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;token_ids = generate_text_simple(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model=model,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; idx=text_to_token_ids(start_context, tokenizer),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_new_tokens=10,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; context_size=GPT_CONFIG_124M[&amp;#34;context_length&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(token_ids_to_text(token_ids, tokenizer))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="交叉熵损失的计算"&gt;交叉熵损失的计算&lt;/h2&gt;
&lt;p&gt;模型训练的目标是增大与正确目标词元ID对应的索引位置的softmax概率，也就是最大化正确词元的可能性。&lt;/p&gt;</description></item><item><title>2025-09-11 Anthropic 做 Multi Agent 系统的工程经验（下）</title><link>https://huizhixu.github.io/chs/know_how/20250911anthropic-%E5%81%9A-multi-agent-%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8B/</link><pubDate>Thu, 11 Sep 2025 12:50:53 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250911anthropic-%E5%81%9A-multi-agent-%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8B/</guid><description>&lt;p&gt;这一篇写Anthropic的智能体评估、生产可靠性和工程挑战。&lt;/p&gt;
&lt;h1 id="智能体评估"&gt;智能体评估&lt;/h1&gt;
&lt;p&gt;如何做智能体评估呢？传统的做法是“给定输入 X，必须走步骤 Y，才能得到正确输出 Z”。但是多智能体不能这样做，因为它没有固定唯一的、可预先写死的解题路径。&lt;/p&gt;
&lt;h2 id="评估什么"&gt;评估什么&lt;/h2&gt;
&lt;p&gt;不要去检查是否走了预设的路径，而要判断是否有合理的过程和正确的结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;结果导向：最终答案是否正确、是否满足用户需求。&lt;/li&gt;
&lt;li&gt;过程合理性：虽然允许路径变化，但要确保路径在逻辑、效率、成本、可靠性上“说得通”。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="从小样本集上就开始做评估"&gt;从小样本集上就开始做评估&lt;/h2&gt;
&lt;p&gt;不要等数据量大时才开始做评估，在小样本的时候就开始做评估&lt;/p&gt;
&lt;h2 id="llm-as-judge"&gt;LLM AS JUDGE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;研究输出的评估难题：研究输出通常是自由形式的文本，很难通过程序化的方法进行评估，因为它们很少有唯一正确的答案。&lt;/li&gt;
&lt;li&gt;LLM作为评判工具的适用性：LLM 由于其强大的语言理解和生成能力，非常适合用于评估这种复杂的研究输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="打分规则"&gt;打分规则&lt;/h3&gt;
&lt;p&gt;Anthropic 制定了一些打分规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事实准确性（说法是否与来源一致？）&lt;/li&gt;
&lt;li&gt;引用准确性（引用来源是否真的支撑该说法？）&lt;/li&gt;
&lt;li&gt;完整性（是否涵盖了所有要求的内容？）&lt;/li&gt;
&lt;li&gt;来源质量（是否优先使用了高质量的一手资料，而不是低质量的二手资料？）&lt;/li&gt;
&lt;li&gt;工具效率（是否用了恰当的工具、调用次数是否合理？）
评分方式：LLM评判工具会根据上述标准对每个输出进行评分，评分范围为0.0到1.0，并给出通过或不通过的等级。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验与优化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多评委实验：最初尝试使用多个LLM评判工具来评估每个标准，但发现这种方法不够一致，与人类评判结果的对齐度也不够高。&lt;/li&gt;
&lt;li&gt;单评委优化：最终发现，使用单个LLM评判工具，通过一个单一的提示（prompt）来输出评分和通过/不通过的等级，是最一致且与人类评判结果最接近的方法。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="人工评估的重要性"&gt;人工评估的重要性&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;自动化评估的局限性：
自动化评估工具（如LLM评判工具）虽然高效，但可能会遗漏一些边缘情况（edge cases）。这些情况包括：&lt;/li&gt;
&lt;li&gt;人工评估的优势：&lt;/li&gt;
&lt;li&gt;多智能体系统的复杂性&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="生产可靠性和工程挑战"&gt;生产可靠性和工程挑战&lt;/h1&gt;
&lt;p&gt;在传统软件里，一个小 bug 可能仅仅让功能崩溃、性能下降或触发一次故障。&lt;/p&gt;
&lt;p&gt;而在agentic 系统里，微小的改动会像滚雪球一样放大，引发巨大的行为漂移——这使得为那些需要在长时间运行中保持状态的复杂智能体编写可靠代码变得异常困难。&lt;/p&gt;
&lt;h2 id="1-增加故障点原地恢复的功能"&gt;1. 增加故障点原地恢复的功能&lt;/h2&gt;
&lt;p&gt;智能体可能长时间运行，在多次工具调用之间持续保持状态。这意味者必须保证代码的持久执行，并在每一步都能妥善处理错误。&lt;/p&gt;
&lt;p&gt;出错时，不能简单地“重启”：重启太昂贵了。所以Anthropic 构建了一套可从故障点原地恢复的系统，并加上了重试逻辑和定期快照来保证断点恢复的功能。&lt;/p&gt;
&lt;h2 id="2-开发全链路追踪"&gt;2. 开发全链路追踪&lt;/h2&gt;
&lt;p&gt;在传统软件里，同样的输入基本会得到同样的输出，可 AI 智能体是“动态、非确定性”的——同一套提示词跑两次，内部决策路径都可能不同，于是调试难度成倍上升。 举个例子：用户投诉“智能体连显而易见的资料都找不到”。光凭日志根本看不出问题出在哪——是它生成了糟糕的搜索关键词？还是选到了垃圾网页？还是工具本身调用失败？&lt;/p&gt;
&lt;p&gt;Anthropic 引入了一套“全链路追踪（full production tracing）”，记录每一次调用、每一个决策节点（关键词→结果→评分→下一步动作），但不记录对话正文，保证用户隐私。&lt;/p&gt;
&lt;p&gt;好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能一眼看出“哦，原来失败都是因为它把 PDF 当网页解析导致失败”之类的根本原因；&lt;/li&gt;
&lt;li&gt;能发现“两个子智能体反复互相踢皮球”这种事先没想到的异常协作；&lt;/li&gt;
&lt;li&gt;把常见失败归纳成模式后，就可以系统性地修 bug、改提示、补工具，而不是靠猜。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="3-部署的时候要考虑用户正在使用"&gt;3. 部署的时候要考虑用户正在使用&lt;/h2&gt;
&lt;p&gt;考虑到无论什么时候发布更新都有可能有用户在使用智能体，Anthropic 采用“彩虹部署（rainbow deployments）”：旧版本和新版本同时在线，逐步将流量从旧实例切到新实例，从而避免打断正在运行的智能体。&lt;/p&gt;
&lt;h2 id="4-同步执行与异步执行"&gt;4. 同步执行与异步执行&lt;/h2&gt;
&lt;h3 id="同步执行优点"&gt;同步执行优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;流程简洁：主智能体按固定顺序等待全部子智能体返回即可，调度与调试成本较低。&lt;/li&gt;
&lt;li&gt;状态一致：所有子任务一次性完成，输出天然对齐，无需额外的合并步骤。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="同步执行挑战"&gt;同步执行挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;吞吐受限：任一子智能体延迟即拖慢全局，系统整体并行度受限。&lt;/li&gt;
&lt;li&gt;缺乏弹性：主智能体无法在运行过程中动态修正子智能体的目标；子智能体之间亦无法实时共享信息或协同。&lt;/li&gt;
&lt;li&gt;资源闲置：当大部分子智能体已结束而少数仍在执行时，算力与带宽均被阻塞，利用率下降。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="异步执行优点"&gt;异步执行优点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;并行度显著提升，各子智能体可独立推进并按需衍生新任务；&lt;/li&gt;
&lt;li&gt;主智能体可实时接收中间结果，及时重定向或终止子任务，实现精细化控制；&lt;/li&gt;
&lt;li&gt;子智能体之间可通过消息机制即时协作，提高整体效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="异步执行挑战"&gt;异步执行挑战&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;结果汇总：需额外机制对无序到达的结果进行排序、去重与聚合；&lt;/li&gt;
&lt;li&gt;状态一致：分布式快照或事务协议保障全局视图同步，增加系统复杂度；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="5-上下文管理"&gt;5. 上下文管理&lt;/h2&gt;
&lt;p&gt;当 AI 代理需要与用户进行几百轮对话时，如何让它“记住”前面发生的事，又不会因为上下文窗口塞不下而失效呢？&lt;/p&gt;</description></item><item><title>2025-09-10 Anthropic 做 Multi Agent系统的工程经验（上）</title><link>https://huizhixu.github.io/chs/know_how/20250910anthropic-%E5%81%9A-multi-agent%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8A/</link><pubDate>Wed, 10 Sep 2025 12:50:47 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250910anthropic-%E5%81%9A-multi-agent%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E7%A8%8B%E7%BB%8F%E9%AA%8C%E4%B8%8A/</guid><description>&lt;p&gt;从ChatGPT时代到现在，大家逐渐达成共识：大模型的应用核心不是算法问题，而是工程问题。大模型本身作为基础设施已经就位，关键在于如何通过工程手段解决记忆存储、上下文管理、工具调用和提示词优化等实际问题。&lt;/p&gt;
&lt;p&gt;最近读了Anthropic关于多智能体系统的工程实践， 感觉很有意思，所以分享出来。这一篇将解析：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Multi Agent的架构设计（Orchestrator-Worker模式）&lt;/li&gt;
&lt;li&gt;Multi Agent的优劣势&lt;/li&gt;
&lt;li&gt;提示工程实践（8条 Anthropic 核心经验）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下一篇写Anthropic的智能体评估、产品可靠性和工程挑战。&lt;/p&gt;
&lt;h1 id="multi-agent-的架构"&gt;Multi Agent 的架构&lt;/h1&gt;
&lt;h3 id="orchestrator-worker模式解析"&gt;Orchestrator-Worker模式解析&lt;/h3&gt;
&lt;p&gt;Anthropic采用orchestrator-worker架构模式。&lt;/p&gt;
&lt;p&gt;在AI的论文中经常可以看见orchestrate这个单词。orchestrator的本义是是管弦乐的编曲者，是把一首乐曲改编成适合管弦乐队演奏、并为每种乐器分配合适声部和旋律的人。&lt;/p&gt;
&lt;p&gt;在这里orchestrator 引申为“负责总体调度、协调、编排所有子任务的组件，又叫lead agent（主智能体）。 worker是执行子任务的智能体，又叫subagent（子智能体）。&lt;/p&gt;
&lt;p&gt;主智能体作为系统的&amp;quot;指挥中心&amp;quot;，其核心职责包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任务分解与分配&lt;/li&gt;
&lt;li&gt;资源协调与调度&lt;/li&gt;
&lt;li&gt;结果整合与决策
子智能体则专注于执行特定子任务，彼此并行工作，通过分工协作提升系统整体效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="架构图"&gt;架构图&lt;/h3&gt;
&lt;p&gt;下面是研究系统的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250910/69ac33e7.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;如图所示，当用户提交查询时，主智能体会进行分析，制定策略，通过子智能体迭代使用搜索工具收集信息，然后将信息返回给主智能体，最后汇总成最终答案。&lt;/p&gt;
&lt;p&gt;多智能体与RAG的不同：&lt;/p&gt;
&lt;p&gt;检索增强生成 (RAG) 一种静态检索，它们会获取与输入查询最相似的一组词块，并使用这些词块生成响应。而多智能体架构采用多步骤搜索，可以动态地查找相关信息，适应新的发现，并分析结果以生成高质量的答案。&lt;/p&gt;
&lt;h3 id="交互流程"&gt;交互流程&lt;/h3&gt;
&lt;p&gt;下面是多智能体系统的交互流程，这里可以看出，除了不同的智能体、还有Memory模块和Citation Agent。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250910/0c84baf9.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当用户提交查询时，系统会创建一个 LeadResearcher（主研智能体），它进入迭代式研究循环。&lt;/li&gt;
&lt;li&gt;主研先思考整体方案，并把计划写入 Memory（记忆模块），以保证上下文被持久化——因为上下文窗口一旦超过 20 万 token 就会被截断，保留计划至关重要。&lt;/li&gt;
&lt;li&gt;主研创建若干专门的 Subagent（分研智能体，图中示例为 2 个，实际数量可任意），各自领取具体的子任务。&lt;/li&gt;
&lt;li&gt;每个分研独立执行网页搜索，并用“Interleaved thinking”的方式评估工具返回结果，随后将发现返回给主研。&lt;/li&gt;
&lt;li&gt;主研汇总这些结果，并判断是否需要继续研究；&lt;/li&gt;
&lt;li&gt;如需继续，它可以再创建新的分研或调整策略。当信息足够后，系统退出研究循环，把所有发现交给 CitationAgent（引用智能体）。&lt;/li&gt;
&lt;li&gt;引用智能体对文档和研究报告进行处理，为每一处需要引用的内容定位具体来源，确保所有结论都能追溯到出处。最终，带完整引用的研究结果返回给用户。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;值得一提的是，这里说到Interleaved thinking 是指交错思考。&lt;/p&gt;
&lt;p&gt;Claude 4 模型在调用工具（tool calls）时，不把“思考过程”一次性打包完，而是在每次得到工具返回结果之后，再插入一段新的思考（reasoning），然后再决定下一步要不要继续调用工具、调用哪一个工具。&lt;/p&gt;
&lt;p&gt;整个“思考—调用工具—再思考—再调用……”的流程像齿轮交错一样穿插进行，而不是传统的“先一口气想好所有步骤，再连续执行”。&lt;/p&gt;
&lt;h1 id="multi-agent的优劣势"&gt;Multi Agent的优劣势&lt;/h1&gt;
&lt;h3 id="为什么研究性的工作适合用multi-agent-来做"&gt;为什么研究性的工作适合用Multi Agent 来做？&lt;/h3&gt;
&lt;p&gt;因为研究工作主要涉及开放性的问题，研究者会根据在研究过程中出现的线索，持续更新自己的研究方法。&lt;/p&gt;</description></item><item><title>2025-08-27 TRAE Agent 基于Agent的编程补丁生成与选择框架</title><link>https://huizhixu.github.io/chs/know_how/20250827trae-agent%E5%9F%BA%E4%BA%8Eagent%E7%9A%84%E7%BC%96%E7%A8%8B%E8%A1%A5%E4%B8%81%E7%94%9F%E6%88%90%E4%B8%8E%E9%80%89%E6%8B%A9%E6%A1%86%E6%9E%B6/</link><pubDate>Wed, 27 Aug 2025 14:11:46 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250827trae-agent%E5%9F%BA%E4%BA%8Eagent%E7%9A%84%E7%BC%96%E7%A8%8B%E8%A1%A5%E4%B8%81%E7%94%9F%E6%88%90%E4%B8%8E%E9%80%89%E6%8B%A9%E6%A1%86%E6%9E%B6/</guid><description>&lt;p&gt;最近几个月我都在使用Trae。它更新很频繁，中间经历了一次大改——Logo由橙色改为绿色，以及数不清的小版本迭代。基本上每天打开电脑TRAE都在提示更新。我挺好奇他们是怎么开发Agent的，最近就去看了他们的一些博客和论文。&lt;/p&gt;
&lt;p&gt;Trae用的是agent-first架构。它的核心是Agent，而不是那种通用的聊天模型。也就是说，用户的查询会直接交给一个或一组最合适的Agent来处理。在Trae里，MCP不再直接和用户打交道，而是在底层发挥作用，就像Agent之间以及Agent和外部工具之间沟通和协调的“管道”或“神经系统”。&lt;/p&gt;
&lt;p&gt;论文和博客里讲的都是怎么实现这个编程Agent的。具体来说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;真实场景中，修复缺陷往往涉及多个文件和模块，需要跨文件推理、感知上下文，并在整个代码库中验证补丁的正确性。Trae Agent研发了一种基于agent的集合推理框架，能够解决仓库级别的问题。&lt;/li&gt;
&lt;li&gt;Trae Agent的工作分为三个阶段：
&lt;img src="https://uvidumfqwzk.feishu.cn/space/api/box/stream/download/asynccode/?code=YWIzOWViOTgwZDVmOThhYjIzYjU2YzMxMDI4ZWQzMzFfd3B5eVVSR2FRbzNxbldjcjhxbXhRWjc3WFZBblUyZmlfVG9rZW46RUlFd2JXUlkzb3FGZWZ4TFk0OWNJbkRSbkFiXzE3NTYzMDI3NTI6MTc1NjMwNjM1Ml9WNA" alt=""&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（图源于论文：Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling ）&lt;/p&gt;
&lt;h2 id="三个阶段对应三个agent"&gt;三个阶段对应三个Agent&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Coder Agent：并行生成候选补丁，通过提高温度和多模型轮询（如Gemini 2.5 Pro、Claude 3.7 Sonnet和GPT-4.1）来增加多样性。&lt;/li&gt;
&lt;li&gt;Tester Agent：自动提取并执行回归测试，过滤掉错误的补丁。&lt;/li&gt;
&lt;li&gt;Selector Agent：对剩余补丁进行仓库级静态和动态分析，通过投票选出最终补丁。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="生态工具"&gt;生态工具&lt;/h1&gt;
&lt;p&gt;TRAE建立了一个工具生态，包含以下四种工具，这些工具在三个阶段中都会被应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文件编辑工具：查看文件和目录结构，创建和编辑文件。&lt;/li&gt;
&lt;li&gt;Bash工具：提供持久的命令执行接口，让Agent能够与系统交互，捕获输出和错误信息。&lt;/li&gt;
&lt;li&gt;顺序思考工具：将复杂问题拆解，进行迭代式思考和修正，提出假设并验证，提供结构化的问题解决和分析能力。&lt;/li&gt;
&lt;li&gt;任务完成工具：发出任务结束信号，给出最终结果和总结。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="阶段一补丁生成"&gt;阶段一：补丁生成&lt;/h1&gt;
&lt;p&gt;这个阶段主要是采用多个主流大语言模型根据描述生成候选补丁。这个阶段主要由Coder Agent完成，它遵循以下多步流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;分析问题描述，理解要解决的问题是什么；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;探索代码库，定位与问题相关的文件；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复现 bug，验证其表现；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过代码审查诊断根本原因；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生成代码补丁以修复已识别的缺陷；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重新运行复现测试，验证补丁的正确性；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;总结整个工作流程，模拟真实的commit message。
为了增加候选结果的多样性，采取了以下措施：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在运行Coder Agent时提高温度，增加多样性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引入Mixture设置，以轮询方式调用三种LLM生成补丁。
此外，为了实现可观测性，轨迹记录系统会详细记录每一步的信息，包括与LLM的交互、Agent的具体步骤、元数据以及错误追踪。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="阶段二补丁修剪"&gt;阶段二：补丁修剪&lt;/h1&gt;
&lt;p&gt;这个阶段由Tester Agent完成，它会自动从原始项目代码库中检索与问题描述相关的回归测试，并过滤掉不正确的补丁。具体做法如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用Python的unidiff库实现补丁解析器，将原始补丁转换为结构化表示。&lt;/li&gt;
&lt;li&gt;通过补丁归一化移除语义无关的元素，如多余空格、换行和注释。&lt;/li&gt;
&lt;li&gt;无法解析的补丁被视为无效并直接丢弃。&lt;/li&gt;
&lt;li&gt;对归一化后的补丁进行等价检测，若多条候选补丁的归一化结果完全相同，则判定其语义等价，仅保留其一。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="阶段三补丁选择"&gt;阶段三：补丁选择&lt;/h2&gt;
&lt;p&gt;这个阶段由Selector Agent完成，它会进行以下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于语法的投票：Selector agent 首先执行基于语法的投票，通过对候选补丁进行语法等价聚类，并选择出现频率最高的聚类作为潜在解决方案。其原理是，如果多个 Coder agent 独立生成了严格语法等价的补丁，则表明存在强烈共识，暗示这些高度一致的补丁更有可能是正确的&lt;/li&gt;
&lt;li&gt;多重选择投票：先对补丁进行去重。然后多个selector agent对去重后的补丁进行投票，选出最可能正确的补丁。如果票数分布均匀会增加投票轮数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="如何评估trae-agent"&gt;如何评估TRAE Agent：&lt;/h2&gt;
&lt;p&gt;TRAE Agent的性能通过与四种最新的集成推理基线方法（Augment、Augment w/ Pruning、DeiBase和DeiBase w/ Pruning）在三种主流LLM（Gemini 2.5 Pro、Claude 3.7 Sonnet和GPT-4.1）上进行对比评估。评估指标包括：&lt;/p&gt;</description></item><item><title>2025-08-24 从零构建大模型-徒手组装GPT</title><link>https://huizhixu.github.io/chs/know_how/20250824-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E5%BE%92%E6%89%8B%E7%BB%84%E8%A3%85gpt/</link><pubDate>Sun, 24 Aug 2025 13:55:15 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250824-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B-%E5%BE%92%E6%89%8B%E7%BB%84%E8%A3%85gpt/</guid><description>&lt;p&gt;《从零构建大模型》8周学习计划（按周打卡！）
1️⃣ 数据预处理✅
2️⃣ 注意力机制✅
3️⃣ 徒手组装GPT✅
4️⃣ 徒手训练GPT
5️⃣ 微调：分类
6️⃣ 微调：SFT
7️⃣-8️⃣ 缓冲周&lt;/p&gt;
&lt;h2 id="gpt的几个概念"&gt;GPT的几个概念：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;参数：指模型的可训练权重，本质是模型的内部变量。在训练过程中通过调整和优化来最小化特定的损失函数来学习。&lt;/li&gt;
&lt;li&gt;GPT-2和GPT3：架构基本相同，训练的数据量不同，参数量不同。GPT-2的权重公开，GPT-3的权重没有。&lt;/li&gt;
&lt;li&gt;GPT2的config
vocab_size表示使用50257个token组成的词汇表。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;context_length指的是模型一次输入的最大token 数量。&lt;/p&gt;
&lt;p&gt;emb_dim表示嵌入维度大小。&lt;/p&gt;
&lt;p&gt;n_heads表示多头注意力机制中注意力头的数量。&lt;/p&gt;
&lt;p&gt;n_layers表示模型中的Transformer块数量。&lt;/p&gt;
&lt;p&gt;drop_rate表示表示有10%的隐藏单元被随机丢弃，以防止过拟合。&lt;/p&gt;
&lt;p&gt;qkv_bias指的是是否在多头注意力机制的线性层中添加一个偏置向量，用于查询、键和值的计算。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;GPT_CONFIG_124M &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;50257&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;context_length&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;1024&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;768&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;n_heads&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;12&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;n_layers&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;12&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;drop_rate&amp;#34;&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;0.1&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;qkv_bias&amp;#34;&lt;/span&gt;:&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol&gt;
&lt;li&gt;GPT大语言模型的组件：嵌入层、Transformer块、输出层。&lt;/li&gt;
&lt;li&gt;Transformer块包括层归一化，GELU激活函数、前馈神经网络、残差链接和多头注意力模块。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250824/668b362d.png" alt=""&gt;&lt;/p&gt;
&lt;h2 id="一打好框架构建dummy类"&gt;一、打好框架：构建Dummy类&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;这里的Dummy类只用于结构完整性，并不是具体真实的实现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据在模型中的处理流程：它首先计算输入索引的词元和位置嵌入，然后应用dropout，接着通过Transformer块处理数据，再应用归一化，最后使用线性输出层生成logits。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码理解：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nn.Embedding 的本质是创建一个权重矩阵，是把词表里的每一个 token_id 映射成一个向量。&lt;/li&gt;
&lt;li&gt;self.tok_emb = nn.Embedding(config[&amp;ldquo;vocab_size&amp;rdquo;], config[&amp;ldquo;emb_dim&amp;rdquo;])—— 在 &lt;strong&gt;init&lt;/strong&gt; 里建表，告诉模型：词表有多大，每个 token 要映射成多少维的向量。这一步只发生一次，把权重矩阵（形状 [vocab_size, emb_dim]）存到 self.tok_emb 里。&lt;/li&gt;
&lt;li&gt;tok_emb = self.tok_emb(in_idx)—— 在 forward 里查表（把输入的 token_id 拿去这张表里查对应的向量）。这一步每次前向传播都会调用，输入是形状 [batch, seq_len] 的整数张量，输出是 [batch, seq_len, emb_dim] 的嵌入张量。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; torch.nn &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; nn
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyTransformerBlock&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, config) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyLayerNorm&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, normalized_shape, eps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1e-5&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, x):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; x
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;DummyGPTModel&lt;/span&gt;(nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Module):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, config) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;super&lt;/span&gt;()&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;&lt;span style="color:#50fa7b"&gt;__init__&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Embedding(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pos_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Embedding(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;context_length&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;drop &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Dropout(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;drop_rate&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;transformer_blocks &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Sequential(&lt;span style="color:#ff79c6"&gt;*&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; DummyTransformerBlock(config) &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; _ &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;range&lt;/span&gt;(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;n_layers&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ]) &lt;span style="color:#6272a4"&gt;# 使用占位符替换TransformerBlock&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;final_norm &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; DummyLayerNorm(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;out_head &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; nn&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Linear(config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;emb_dim&amp;#34;&lt;/span&gt;], config[&lt;span style="color:#f1fa8c"&gt;&amp;#34;vocab_size&amp;#34;&lt;/span&gt;], bias&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;forward&lt;/span&gt;(&lt;span style="font-style:italic"&gt;self&lt;/span&gt;, in_idx):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; batch_size, seq_len &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; in_idx&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;shape
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tok_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok_emb(in_idx)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; pos_emb &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pos_emb(torch&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;arange(seq_len, device&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;in_idx&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;device))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; tok_emb &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; pos_emb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;drop(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;transformer_blocks(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; x &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;final_norm(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logits &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="font-style:italic"&gt;self&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;out_head(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; logits
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="二层归一化"&gt;二、层归一化&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;层归一化指调整神经网络层的输出，使其均值为0且方差为1。&lt;/li&gt;
&lt;li&gt;为什么要层归一化：使训练稳定，加速权重收敛。&lt;/li&gt;
&lt;li&gt;什么时候用：多头注意力的前后；最终输出层之前&lt;/li&gt;
&lt;li&gt;LayerNorm 沿着列方向（hidden_size） 做归一化&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码理解：&lt;/p&gt;</description></item><item><title>2025-08-22 罗永浩和李想的视频对谈</title><link>https://huizhixu.github.io/chs/know_how/20250822-%E7%BD%97%E6%B0%B8%E6%B5%A9%E5%92%8C%E6%9D%8E%E6%83%B3%E7%9A%84%E8%A7%86%E9%A2%91%E5%AF%B9%E8%B0%88/</link><pubDate>Fri, 22 Aug 2025 13:54:01 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250822-%E7%BD%97%E6%B0%B8%E6%B5%A9%E5%92%8C%E6%9D%8E%E6%83%B3%E7%9A%84%E8%A7%86%E9%A2%91%E5%AF%B9%E8%B0%88/</guid><description>&lt;p&gt;昨晚下班后我看了罗永浩和李想的视频播客，我之前只知道李想是理想的创办者，也是汽车之家的创办者，但是我对他的具体的经历不是很了解。&lt;/p&gt;
&lt;p&gt;他首先讲了自己的童年和青少年时期，他跟着底色善良的姥姥姥爷长大，父母上过大学，非常开明，他的童年幸福到罗永浩都忍不住羡慕。&lt;/p&gt;
&lt;p&gt;后面他就谈起自己的创业历程。在初中时，他就显露出商业头脑。&lt;/p&gt;
&lt;p&gt;小时候，他会从漫画批发市场把漫画书批发回来，然后卖给同学挣些钱。初中时，他正式接触电脑，当时他非常痴迷学电脑，但那时他没有电脑，只能看书学习。不过，在这个过程中，他在电脑的世界里找到了归属感。&lt;/p&gt;
&lt;p&gt;后来他真正有了电脑，上手非常快，因为之前的基本功已经相当扎实。他说基本上用了一天时间，就把很多问题都解决了。那时他暑假到买电脑的商家那里帮忙组装电脑，这不仅让他赚到了钱，也让他明确了以后想从事的道路。&lt;/p&gt;
&lt;p&gt;高三时，他自己做了一个“显卡之家”，也很成功。他很有头脑，除了自己写代码，还招了两个人一起写。&lt;/p&gt;
&lt;p&gt;从高中开始，他从这种正向反馈里形成了对自己的认知，即：掌控自己的命运，挑战成长的极限。他从来没有经历过青春期的迷茫，一路走来都很顺利。接触电脑书、打好基础、实践操作快、获得正向反馈、写稿件、建立“显卡之家”。&lt;/p&gt;
&lt;p&gt;高中毕业之后，他跟父母提出不想去上大学，想去创业。他说服父母的理由是，自己高中时就已经赚到钱，已经证明了自己的能力（他高三的月收入就有两万多，是他父母的十几倍）。&lt;/p&gt;
&lt;p&gt;他聊到后面做汽车之家，其实他们汽车之家已经做到了垂直领域最好，他们的技术、内容和产品都非常强，整个商业体系也很强，但是他们只把业务放在一个垂直网站上面，所以他对这一点比较遗憾。这里能看出李想是想要普世大成功的那种人。&lt;/p&gt;
&lt;p&gt;他还说做硬件和做软件的公司，组织方式是不一样的。从科技公司的角度来说，全世界最成功的组织方式有两大类。一大类是有特别严格的流程，因为可能这个品类很复杂，遵循木桶理论，比如手机、终端、操作系统，一个环节出问题就不行。华为和IBM就是这种，这是第一类企业，以流程为主。但这类企业的问题在于做互联网和人工智能会稍微弱一点，因为存在组织适配性的问题。&lt;/p&gt;
&lt;p&gt;另外一类公司，像字节和谷歌，这两类公司不依赖流程，而是依赖更高的人才密度，并用OKR这样的工具把大家连接在一起，所以对人才密度要求非常高。这类企业做平台、做创新、做技术研究都非常好，但去做一些复杂的硬件时就会弱一些。&lt;/p&gt;</description></item><item><title>2025-08-17 从零构建大模型——注意力机制</title><link>https://huizhixu.github.io/chs/know_how/20250817%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link><pubDate>Sun, 17 Aug 2025 13:55:21 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250817%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid><description>&lt;h2 id="背景"&gt;背景&lt;/h2&gt;
&lt;h3 id="编码器-解码器"&gt;编码器-解码器&lt;/h3&gt;
&lt;p&gt;编码器将源语言的一串词元序列作为输入，并通过隐藏状态（一个中间神经网络层）编码整个输入序列的压缩表示（可以理解为嵌入）。然后，解码器利用其当前的隐藏状态开始逐个词元进行解码生成。&lt;/p&gt;
&lt;p&gt;编码器-解码器RNN的缺陷：在解码阶段，RNN无法直接访问编码器中的早期隐藏状态，它只能依赖当前的隐藏状态。这可能导致上下文丢失，特别是在依赖关系可能跨越较长的距离的句子中。&lt;/p&gt;
&lt;h2 id="构建大语言模型的三个阶段"&gt;构建大语言模型的三个阶段&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250817/bb022129.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;（图来源于书籍）&lt;/p&gt;
&lt;p&gt;这张图画得很清晰，第三章的主要学习注意力机制。&lt;/p&gt;
&lt;h2 id="学习目标"&gt;学习目标&lt;/h2&gt;
&lt;p&gt;实现4种注意力机制&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简化版的自注意力机制&lt;/li&gt;
&lt;li&gt;加入可训练的权重的自注意力机制&lt;/li&gt;
&lt;li&gt;因果注意力机制&lt;/li&gt;
&lt;li&gt;多头注意力机制&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="简化版的自注意力机制"&gt;简化版的自注意力机制&lt;/h2&gt;
&lt;h3 id="关键概念"&gt;关键概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;注意力机制：对于输出，某些输入词元比其他词元更重要。重要性由注意力权重决定。&lt;/li&gt;
&lt;li&gt;“自”是什么意思：&lt;/li&gt;
&lt;li&gt;上下文向量是什么？&lt;/li&gt;
&lt;li&gt;上下文向量怎么计算？&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="实践"&gt;实践&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;import torch
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;inputs = torch.tensor(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [[0.43, 0.15, 0.89], # Your (x^1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.55, 0.87, 0.66], # journey (x^2)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.57, 0.85, 0.64], # starts (x^3)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.22, 0.58, 0.33], # with (x^4)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.77, 0.25, 0.10], # one (x^5)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; [0.05, 0.80, 0.55]] # step (x^6)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(inputs.shape[0])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;query = inputs[1]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_scores = torch.empty(inputs.shape[0],inputs.shape[0])
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_scores = inputs @ inputs.T
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(attn_scores)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;attn_weights = torch.softmax(attn_scores, dim=-1)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(&amp;#34;Attention weights:&amp;#34;, attn_weights)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(&amp;#34;Sum:&amp;#34;, attn_weights.sum(dim=-1))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;all_context_vecs = attn_weights @ inputs
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(all_context_vecs)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="带可训练权重的自注意力机制缩放点积注意力-scaled-dot-product-attention"&gt;带可训练权重的自注意力机制（缩放点积注意力 scaled dot-product attention）&lt;/h2&gt;
&lt;h3 id="关键概念-1"&gt;关键概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;缩放点积注意力&lt;/p&gt;</description></item><item><title>2025-07-26 论文阅读 LongCite Enabling LLMs to Generate Fine-grained Citations in Long-context QA</title><link>https://huizhixu.github.io/chs/know_how/20250726-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBlongcite-enabling-llms-to-generate-fine-grained-citations-in-long-context-qa/</link><pubDate>Sat, 26 Jul 2025 14:11:41 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250726-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBlongcite-enabling-llms-to-generate-fine-grained-citations-in-long-context-qa/</guid><description>&lt;p&gt;大模型的幻觉一直没有被解决，在有上下文的情况下最直接的应对方式就是让它“自证出处”。在调研的过程中，我发现，目前主流做法要么照搬 DeepSeek-R1 的 prompt 模板让模型当场给出引用，要么事后用规则再捞一遍参考文献。但是这篇论文走了另一条路：拿一个 8B/9B 的小模型，针对“长上下文问答 + 引用生成”做微调。&lt;/p&gt;
&lt;p&gt;这个一年前的论文微调的小模型应该打不过现有的大模型，但是在构造数据集、构造评估的方法等方面都给了我启发。&lt;/p&gt;
&lt;p&gt;原文地址：https://arxiv.org/abs/2409.02897&lt;/p&gt;
&lt;h1 id="背景"&gt;背景&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;长文本大模型用来做信息抽取或者总结，但是因为缺乏引用，无法支撑观点。&lt;/li&gt;
&lt;li&gt;RAG因为缺少完整的上下文信息导致答案质量下降，post-hoc方法则因流程复杂延长用户等待时间。&lt;/li&gt;
&lt;li&gt;虽然有的web search能够提供引用，但是指向整个页面，粒度太粗。而用户需要知道知道具体的引用段落或者句子。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;提出了LongBench-Cite，一个带引用的长上下文问答的benchmark&lt;/li&gt;
&lt;li&gt;提出了CoF，一种用大模型自动构建高质量长上下文数据集的pipeline&lt;/li&gt;
&lt;li&gt;构造了数据集 LongCite-45k&lt;/li&gt;
&lt;li&gt;训练了模型 LongCite-8B 和 LongCite-9B&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="benchmark-longbench-cite"&gt;Benchmark LongBench-Cite&lt;/h2&gt;
&lt;h3 id="1-构造带引用的长上下文问答任务"&gt;1. 构造带引用的长上下文问答任务&lt;/h3&gt;
&lt;p&gt;给定语料$D$和查询$q$，大模型需要返回一个响应$A$，该响应由n个陈述$s_1$，&amp;hellip;，$s_n$组成，每个陈述$s_i$有一个引用列表$Ci = {c_{i,1}, c_{i,2}，&amp;hellip; }$，里面引用了D的片段。&lt;/p&gt;
&lt;p&gt;D表示Document，q表示query，A表示Answer，s表示statement，C表示citation。&lt;/p&gt;
&lt;p&gt;大模型需要把它的结果分割成不同的陈述，格式为&amp;lt;&lt;em&gt;statement&lt;/em&gt;&amp;gt;content&amp;lt;&lt;em&gt;/statement&lt;/em&gt;&amp;gt;。&lt;/p&gt;
&lt;p&gt;有两种粒度的引用，这里主要考虑句子级别的引用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;块级引用 Chunk-level citation&lt;/li&gt;
&lt;li&gt;句级引用 Setence-level citation&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="2-构建基准测试longbench-cite"&gt;2. 构建基准测试：LongBench-Cite&lt;/h3&gt;
&lt;p&gt;整合了现有的以下的两个Benchmark的数据。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LongBench&lt;/li&gt;
&lt;li&gt;LongBench-Chat&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="3-评估"&gt;3. 评估&lt;/h3&gt;
&lt;p&gt;LongBench-Cite基于两个维度进行评估：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;正确性（Correctness）：大模型的回答是否准确和全面&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;引用质量（Citation quality）：回答是否完全能由引用的片段得出，同时没有不相关的片段被引用，并且被引用的片段是细粒度的。
3.1 “正确性”的评估方法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;首先把回答里面引用相关的部分移除，让大模型(GPT-4o)基于query和正确答案来评分，采用之前别人的论文提出来的方法来进行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为了看增加引用是否会伤害模型的长上下文问答的性能，增加了correctness ratio的计算。
C 和 C_{LQA} 分别表示带引用和不带引用的正确率，不带引用的做法是直接把语料和query给大模型，生成回复。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.2 “引用质量”的评估方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;计算 Citation Recall&lt;/li&gt;
&lt;li&gt;计算 Citation Precision
对于每个引用，判断它是否是相关的引用（1/0表示相关/不相关），然后计算平均值。这个过程也是用GPT-4o来做的。&lt;/li&gt;
&lt;li&gt;计算 Citation F1
使用 $F1 = (2 · P · R)/(P + R)$ 来计算&lt;/li&gt;
&lt;li&gt;用 Citation Length来评估粗细粒度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cofcoarse-to-fine"&gt;CoF（Coarse to Fine）&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250726/18029c50.png" alt=""&gt;&lt;/p&gt;</description></item><item><title>2025-07-02 GraphRAG实践</title><link>https://huizhixu.github.io/chs/know_how/20250702-graphrag%E5%AE%9E%E8%B7%B5/</link><pubDate>Wed, 02 Jul 2025 13:54:51 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250702-graphrag%E5%AE%9E%E8%B7%B5/</guid><description>&lt;p&gt;GraphRAG刚出来的时候，使用的是OpenAI的对话模型和向量模型，由于在过程中会使用非常多的调用，所以成本较为昂贵。如果想用便宜的国产大模型或者在本地部署，免费使用，那就涉及到本地模型的使用。
使用其他模型有很多种方式，可以用ollama, slang, vllm，text-generations等方式部署。
GraphRAG改版非常多次，在1.0.0版本不支持使用本地模型，在最新的2.0.0以上的版本开始支持ollam部署的模型。
如果要用OpenAI之外的对话模型和向量模型，建议详细阅读：https://github.com/microsoft/graphrag/issues/657。&lt;/p&gt;
&lt;p&gt;我本次用的是ollama部署的qwen2:7b和本地部署的embedding模型。&lt;/p&gt;
&lt;h1 id="提前准备"&gt;提前准备&lt;/h1&gt;
&lt;h3 id="1-安装环境"&gt;1. 安装环境&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;conda create &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;n graphrag3&lt;span style="color:#bd93f9"&gt;.10&lt;/span&gt; python&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;3.10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;oonda activate graphrag3&lt;span style="color:#bd93f9"&gt;.10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-准备好ollama模型"&gt;2. 准备好ollama模型&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;ollama run qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="使用步骤"&gt;使用步骤&lt;/h1&gt;
&lt;h3 id="1-下载graphrag"&gt;1. 下载graphrag&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;git clone git@github.com:microsoft&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;graphrag&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;git
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cd graphrag
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;pip install &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;e&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="2-初始化"&gt;2. 初始化&lt;/h3&gt;
&lt;p&gt;准备数据输入文件夹&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;mkdir &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;p &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;graphrag_sophia&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;input&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# 注意一定要建立一个input子文件夹，在创建索引的时候会去识别这个名字。如果是其他名字，可以在settings.yaml更改&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;初始化&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;python &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;m graphrag init &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;root &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;graphrag_sophia
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看见在graphrag_sophia下生成settings.yaml和prompts文件夹。
这一步还需要把要把*.txt文件放入input文件夹中&lt;/p&gt;
&lt;h3 id="3-生成索引"&gt;3. 生成索引&lt;/h3&gt;
&lt;p&gt;3.1 准备数据
先准备数据，在graph_rag文件夹新建input，将.txt文件放进去。如果手头没有.txt文件，可以用官方提供的文件。
mkdir -p ./input （注意一定要建立一个input子文件夹，在创建索引的时候会去识别这个名字。如果是其他名字，可以在settings.yaml更改）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;curl https:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;www&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gutenberg&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;org&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;cache&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;epub&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;24022&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;pg24022&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;txt &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;o &lt;span style="color:#ff79c6"&gt;./&lt;/span&gt;data&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;test&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;book&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;txt
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.2 设置workspace variables&lt;/p&gt;
&lt;p&gt;我在查阅资料的过程中，发现很多人的settings.yaml是这样的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;llm:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model: qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;11434&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model_supports_json: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;max_tokens: &lt;span style="color:#bd93f9"&gt;32768&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在配置这一步卡了很久，反复报错。原因是新版必须包含三个字段：default_chat_model、type和api_key。官网没给示例，我试了很多写法都不对，估计是因为版本差异。现在我的解决方式是：在.env和settings.yaml里分别设置api_base和api_key。&lt;/p&gt;
&lt;p&gt;我这里的设置：在.env文件中GRAPHRAG_API_KEY=&amp;lt;API_KEY&amp;gt;
settings.yaml文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### This config file contains required core defaults that must be set, along with a handful of common optional settings.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### For a full list of available settings, see https://microsoft.github.io/graphrag/config/yaml/&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### LLM settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## There are a number of settings to tune the threading and token limits for LLM calls - check the docs.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;models:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_chat_model:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: openai_chat &lt;span style="color:#6272a4"&gt;# or azure_openai_chat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;11434&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; auth_type: api_key &lt;span style="color:#6272a4"&gt;# or azure_managed_identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_key: ollama &lt;span style="color:#6272a4"&gt;# set this in the generated .env file&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model: qwen2:&lt;span style="color:#bd93f9"&gt;7&lt;/span&gt;b
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoding_model: cl100k_base &lt;span style="color:#6272a4"&gt;# automatically set by tiktoken if left undefined&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_supports_json: true &lt;span style="color:#6272a4"&gt;# recommended if this is available for your model.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; concurrent_requests: &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# max number of simultaneous LLM requests allowed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; async_mode: threaded &lt;span style="color:#6272a4"&gt;# or asyncio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retry_strategy: native
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_retries: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokens_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; requests_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_embedding_model:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: openai_embedding &lt;span style="color:#6272a4"&gt;# or azure_openai_embedding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_base: http:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;127.0.0.1&lt;/span&gt;:&lt;span style="color:#bd93f9"&gt;8005&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;api&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;v1 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; auth_type: api_key &lt;span style="color:#6272a4"&gt;# or azure_managed_identity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_key: ollama
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model: bge
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; encoding_model: cl100k_base &lt;span style="color:#6272a4"&gt;# automatically set by tiktoken if left undefined&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_supports_json: true &lt;span style="color:#6272a4"&gt;# recommended if this is available for your model.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; concurrent_requests: &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# max number of simultaneous LLM requests allowed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; async_mode: threaded &lt;span style="color:#6272a4"&gt;# or asyncio&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; retry_strategy: native
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_retries: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokens_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; requests_per_minute: auto &lt;span style="color:#6272a4"&gt;# set to null to disable rate limiting&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Input settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;input&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# or blob&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; file_type: text &lt;span style="color:#6272a4"&gt;# [csv, text, json]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;input&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;chunks:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; size: &lt;span style="color:#bd93f9"&gt;200&lt;/span&gt; &lt;span style="color:#6272a4"&gt;#1200&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; overlap: &lt;span style="color:#bd93f9"&gt;50&lt;/span&gt; &lt;span style="color:#6272a4"&gt;# 100 &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; group_by_columns: [&lt;span style="color:#8be9fd;font-style:italic"&gt;id&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Output/storage settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## If blob storage is specified in the following four sections,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## connection_string and container_name must be provided&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;output:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;output&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cache:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;cache&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;reporting:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: file &lt;span style="color:#6272a4"&gt;# [file, blob, cosmosdb]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; base_dir: &lt;span style="color:#f1fa8c"&gt;&amp;#34;logs&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;vector_store:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; default_vector_store:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;type&lt;/span&gt;: lancedb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; db_uri: output\lancedb
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; container_name: default
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; overwrite: &lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Workflow settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;embed_text:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; vector_store_id: default_vector_store
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/extract_graph.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; entity_types: [organization,person,geo,event]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_gleanings: &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;summarize_descriptions:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/summarize_descriptions.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_length: &lt;span style="color:#bd93f9"&gt;500&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_graph_nlp:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text_analyzer:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; extractor_type: regex_english &lt;span style="color:#6272a4"&gt;# [regex_english, syntactic_parser, cfg]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;cluster_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_cluster_size: &lt;span style="color:#bd93f9"&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;extract_claims:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/extract_claims.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; description: &lt;span style="color:#f1fa8c"&gt;&amp;#34;Any claims or facts that could be relevant to information discovery.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_gleanings: &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;community_reports:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; graph_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/community_report_graph.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/community_report_text.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_length: &lt;span style="color:#bd93f9"&gt;2000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; max_input_length: &lt;span style="color:#bd93f9"&gt;8000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;embed_graph:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false &lt;span style="color:#6272a4"&gt;# if true, will generate node2vec embeddings for nodes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;umap:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; enabled: false &lt;span style="color:#6272a4"&gt;# if true, will generate UMAP embeddings for nodes (embed_graph must also be enabled)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;snapshots:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; graphml: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings: false
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;### Query settings ###&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## The prompt locations are required here, but each search method has a number of optional knobs that can be tuned.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;## See the config docs: https://microsoft.github.io/graphrag/config/yaml/#query&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;local_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/local_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;global_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; map_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_map_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; reduce_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_reduce_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; knowledge_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/global_search_knowledge_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;drift_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/drift_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; reduce_prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/drift_search_reduce_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;basic_search:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; chat_model_id: default_chat_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embedding_model_id: default_embedding_model
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; prompt: &lt;span style="color:#f1fa8c"&gt;&amp;#34;prompts/basic_search_system_prompt.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.2 生成索引
这个过程非常非常慢，且token的消耗巨大。（在chunk_length为100的情况下，final_documents每100个14分钟，extract_graph一个小时进度35%）&lt;/p&gt;</description></item><item><title>2025-06-26 论文阅读 Qwen3 Embedding</title><link>https://huizhixu.github.io/chs/know_how/20250626%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBqwen3-embedding/</link><pubDate>Thu, 26 Jun 2025 13:55:03 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250626%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBqwen3-embedding/</guid><description>&lt;p&gt;论文地址：https://arxiv.org/pdf/2506.05176&lt;/p&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;基于合成数据的multi-stage训练&lt;/li&gt;
&lt;li&gt;构建高质量合成数据&lt;/li&gt;
&lt;li&gt;引入模型合并（model merging）&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="模型"&gt;模型&lt;/h2&gt;
&lt;h3 id="embedding-models"&gt;Embedding Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;所有嵌入模型均基于 Qwen3 基座大模型构建；&lt;/li&gt;
&lt;li&gt;使用带因果注意力（causal attention）的解码式架构；&lt;/li&gt;
&lt;li&gt;在输入序列的末尾添加 [EOS]，使用其最终一层 hidden state 作为 embedding 表示；&lt;/li&gt;
&lt;li&gt;支持带指令输入（instruction），格式为： {Instruction} {Query}&amp;lt;|endoftext|&amp;gt;；&lt;/li&gt;
&lt;li&gt;官方实验显示：相比无 instruction，指令式输入能显著提升效果；&lt;/li&gt;
&lt;li&gt;支持 MRL。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="reranking-models"&gt;Reranking Models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;采用 point-wise reranking with LLMs within a single context：point-wise reranking是指 大型语言模型会对每个候选项单独评估其与查询的相关性，给出一个分数，然后根据这些分数进行排序。&lt;/li&gt;
&lt;li&gt;支持 instruction 输入，prompt 格式如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-plain" data-lang="plain"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;system
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Judge whether the Document meets the requirements based on the Query and the
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Instruct provided. Note that the answer can only be &amp;#34;yes&amp;#34; or
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;#34;no&amp;#34;.&amp;lt;|im_end|&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;, →, →
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;user
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Instruct&amp;gt;: {Instruction}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Query&amp;gt;: {Query}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;Document&amp;gt;: {Document}&amp;lt;|im_end|&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;|im_start|&amp;gt;assistant
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&amp;lt;think&amp;gt;\n\n&amp;lt;/think&amp;gt;\n\n
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="训练"&gt;训练&lt;/h2&gt;
&lt;h3 id="训练目标"&gt;训练目标&lt;/h3&gt;
&lt;p&gt;Embedding 模型采用 InfoNCE 对比损失&lt;/p&gt;</description></item><item><title>2025-06-16 Weaviate使用（四） RAG的两种处理方法</title><link>https://huizhixu.github.io/chs/know_how/20250616weaviate%E4%BD%BF%E7%94%A8_rag%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 16 Jun 2025 12:50:37 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250616weaviate%E4%BD%BF%E7%94%A8_rag%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;执行RAG操作过程中，对检索到的条目有两种处理方法：一种是single_prompt，另一种是grouped_tasks。&lt;/p&gt;
&lt;p&gt;grouped_task是对所有检索到的条目做一个整体的处理，例如&amp;quot;write a tweet about these facts&amp;quot;， &amp;ldquo;what do these movies have in common?&amp;quot;。&lt;/p&gt;
&lt;p&gt;single_prompt是对每一个检索到的object应用prompt。例如&amp;quot;translate this into French:{title}&amp;quot;。&lt;/p&gt;
&lt;h2 id="single-prompt"&gt;Single prompt&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;# Single prompt&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;response &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; movies&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;generate&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;near_vector(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; near_vector&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;query_vector,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; limit&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; single_prompt &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Translate this into French:&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{title}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; o &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; response&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;objects:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(o&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;properties[&lt;span style="color:#f1fa8c"&gt;&amp;#34;title&amp;#34;&lt;/span&gt;]) &lt;span style="color:#6272a4"&gt;# Print the title&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(o&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;generated) &lt;span style="color:#6272a4"&gt;# Print the generated text (the title, in French)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结果为&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;I, Robot
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The translation of &lt;span style="color:#f1fa8c"&gt;&amp;#34;I, Robot&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; French &lt;span style="color:#ff79c6"&gt;is&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Je, robot&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;Looper
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;The word &lt;span style="color:#f1fa8c"&gt;&amp;#34;Looper&amp;#34;&lt;/span&gt; translates to &lt;span style="color:#f1fa8c"&gt;&amp;#34;Loupé&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; French&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从结果可以看出，找出来两个数据”I, Robot”和”Looper”，并且分别翻译成法语。&lt;/p&gt;</description></item><item><title>2025-06-15 Weaviate使用（三） 两种导入数据的方法</title><link>https://huizhixu.github.io/chs/know_how/20250615weaviate%E4%BD%BF%E7%94%A8_%E4%B8%A4%E7%A7%8D%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/</link><pubDate>Sun, 15 Jun 2025 12:50:36 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250615weaviate%E4%BD%BF%E7%94%A8_%E4%B8%A4%E7%A7%8D%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;在导入的时候，可以先生成embedding，写入csv，然后在add_batch的时候添加。另外一种方法是在导入的时候直接embedding。&lt;/p&gt;
&lt;h2 id="第一种方法"&gt;第一种方法&lt;/h2&gt;
&lt;h3 id="先创建集合create-collection"&gt;先创建集合：Create collection&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate.classes.config &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; wc
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; weaviate.classes.config &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; Configure
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; weaviate&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;connect_to_local()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;# client.collections.delete(&amp;#34;MovieCustomVector&amp;#34;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;collections&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;create(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;MovieCustomVector&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; properties&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;title&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;TEXT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;overview&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;TEXT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;vote_average&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;NUMBER),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;genre_ids&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;INT_ARRAY),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;release_date&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DATE),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Property(name&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;tmdb_id&amp;#34;&lt;/span&gt;, data_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;wc&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataType&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;INT),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; vectorizer_config&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;Configure&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Vectorizer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;none(),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; generative_config&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;Configure&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;Generative&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;ollama(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; api_endpoint&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;http://host.docker.internal:11434&amp;#34;&lt;/span&gt;, model&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;llama3.2&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;close()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="对文本向量化和存储embed_text"&gt;对文本向量化和存储：embed_text&lt;/h3&gt;
&lt;p&gt;这一步组合标题和概述的内容作为要向量化的文本，向量化之后存为csv。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; pandas &lt;span style="color:#ff79c6"&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; os
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;from&lt;/span&gt; FlagEmbedding &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; BGEM3FlagModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;generate_embeddings&lt;/span&gt;(df: pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame, batch_size: &lt;span style="color:#8be9fd;font-style:italic"&gt;int&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;&amp;#34;&amp;#34;生成文本的向量表示
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; Args:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; df: 包含电影数据的DataFrame
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; batch_size: 批处理大小
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; Returns:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; DataFrame: 包含所有embeddings的DataFrame
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt; &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BGEM3FlagModel(&lt;span style="color:#f1fa8c"&gt;&amp;#34;BAAI/bge-m3&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_dfs &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 批量处理文本&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; i, row &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;enumerate&lt;/span&gt;(df&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;itertuples(index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 组合标题和概述&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; text &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;f&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;Title: &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{&lt;/span&gt;row&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;title&lt;span style="color:#f1fa8c"&gt;}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;;Overview: &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;{&lt;/span&gt;row&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;overview&lt;span style="color:#f1fa8c"&gt;}&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(text)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(i)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 达到批处理大小或处理完所有数据时进行向量化&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(src_texts) &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; batch_size &lt;span style="color:#ff79c6"&gt;or&lt;/span&gt; i &lt;span style="color:#ff79c6"&gt;+&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;1&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(df):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; model&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;encode(src_texts)[&lt;span style="color:#f1fa8c"&gt;&amp;#34;dense_vecs&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;DataFrame(embeddings, index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;indices)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; emb_dfs&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;append(emb_df)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; src_texts &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; indices &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;concat(emb_dfs)&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;sort_index()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;main&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;&amp;#34;&amp;#34;主函数，处理电影数据并生成向量&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 读取数据&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; data_path &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;path&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;join(os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;path&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;dirname(&lt;span style="color:#8be9fd;font-style:italic"&gt;__file__&lt;/span&gt;), &lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch/movies_data_1990_2024.json&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; pd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;read_json(data_path)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#6272a4"&gt;# 生成向量并保存&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings_df &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; generate_embeddings(df)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; os&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;makedirs(&lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch&amp;#34;&lt;/span&gt;, exist_ok&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings_df&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;to_csv(&lt;span style="color:#f1fa8c"&gt;&amp;#34;scratch/movies_data_1990_2024_embeddings.csv&amp;#34;&lt;/span&gt;, index&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;__name__&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;==&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; main()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="导入数据import-data"&gt;导入数据：Import data&lt;/h3&gt;
&lt;p&gt;在导入数据(batch.add_object)的时候需要把 vector和property分别写入。另外uuid是数据库为每一条数据创建的不重复的id。&lt;/p&gt;</description></item><item><title>2025-06-14 Weaviate使用（二） 使用自定义模型</title><link>https://huizhixu.github.io/chs/know_how/20250614weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 14 Jun 2025 12:50:33 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250614weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/</guid><description>&lt;p&gt;如果不想用Ollama启用的向量模型，想用自定义的模型有多种方法，下面介绍两种：一种是通过huggingface或者其他的框架导入，另一种是直接调用已有的向量调用的服务（例如用FastAPI启动）。&lt;/p&gt;
&lt;p&gt;把向量服务或者大模型封装成服务的好处是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;功能解耦：大模型服务或者向量服务独立出来，在替换的时候无需更改代码&lt;/li&gt;
&lt;li&gt;环境解耦：大模型服务通常需要更多的资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这时的docker compose file 非常简单，不再需要ENABLE_MODULES: &amp;rsquo;text2vec-ollama,generative-ollama&amp;rsquo; 这一行。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;---&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;services&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; command&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;host
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;port
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;8080&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;scheme
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; http
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; image&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; cr.weaviate.io&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;semitechnologies&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1.30&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ports&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;/var/lib/weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; restart&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; on&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;failure&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; environment&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; QUERY_DEFAULTS_LIMIT&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; PERSISTENCE_DATA_PATH&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;/var/lib/weaviate&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_API_BASED_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; CLUSTER_HOSTNAME&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;node1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="通过hugging-face导入"&gt;通过hugging face导入&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;def vectorize(texts&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; List[str])&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; from FlagEmbedding &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; BGEM3FlagModel
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BGEM3FlagModel(&lt;span style="color:#f1fa8c"&gt;&amp;#39;BAAI/bge-m3&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; model.encode(texts)[&lt;span style="color:#f1fa8c"&gt;&amp;#34;dense_vecs&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; embeddings
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="通过api调用"&gt;通过API调用&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;class&lt;/span&gt; CustomEmbedding(EmbedGen)&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; def generate_embeddings(self, texts&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; List[str]) &lt;span style="color:#ff79c6"&gt;-&amp;gt;&lt;/span&gt; np.array&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; requests
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; json
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; payload &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; json.dumps(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;input&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; texts,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; )
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; headers &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; {&lt;span style="color:#f1fa8c"&gt;&amp;#34;Content-Type&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;application/json&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; response &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; requests.request(&lt;span style="color:#f1fa8c"&gt;&amp;#34;POST&amp;#34;&lt;/span&gt;, url&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;EMBED_URL, headers&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;headers, data&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;payload)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; [i[&lt;span style="color:#f1fa8c"&gt;&amp;#34;embedding&amp;#34;&lt;/span&gt;] &lt;span style="color:#ff79c6"&gt;for&lt;/span&gt; i &lt;span style="color:#ff79c6"&gt;in&lt;/span&gt; response.json()[&lt;span style="color:#f1fa8c"&gt;&amp;#34;data&amp;#34;&lt;/span&gt;]]
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; embeddings &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; np.array(embeddings)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; embeddings
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description></item><item><title>2025-06-13 论文阅读BGE-M3</title><link>https://huizhixu.github.io/chs/know_how/20250613%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBbge-m3/</link><pubDate>Fri, 13 Jun 2025 12:50:30 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250613%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BBbge-m3/</guid><description>&lt;p&gt;论文地址：https://arxiv.org/abs/2402.03216&lt;/p&gt;
&lt;p&gt;M3的意思是 Multi-Linguality, Multi-Functionality和Multi-Granularity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持100种语言（multi-lingual, cross-lingual)&lt;/li&gt;
&lt;li&gt;支持短句和长文档，最高到8192tokesn&lt;/li&gt;
&lt;li&gt;支持不同的检索方法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20250613/d5b741c9.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;(图来源于论文)&lt;/p&gt;
&lt;h1 id="contribution"&gt;Contribution&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;实现了自知识蒸馏，将来自不同检索功能的相关性分数集成到教师信号，从而提高训练质量。&lt;/li&gt;
&lt;li&gt;优化了批处理策略，实现较大的批处理大小和高训练吞吐量，以提高Embedding的区分能力。&lt;/li&gt;
&lt;li&gt;用data curation来得到高质量的数据&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="细节"&gt;细节&lt;/h1&gt;
&lt;h2 id="不同的向量检索方法"&gt;不同的向量检索方法&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[CLS]用来做dense retrieval&lt;/li&gt;
&lt;li&gt;其他token的向量用来做sparse retrieval 和multi-vector retrieval&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dataset-sources"&gt;Dataset sources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;extract the unsupervised data from massive multi-lingual corpora&lt;/li&gt;
&lt;li&gt;Integrate the closely related supervised data&lt;/li&gt;
&lt;li&gt;Synthesize the scarce data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="self-knowledge-distillation"&gt;Self-Knowledge Distillation&lt;/h2&gt;
&lt;p&gt;InfoNCE loss 的目标是最大化正样本对的相似度，同时最小化负样本对的相似度。&lt;/p&gt;
&lt;p&gt;InfoNCE loss的计算&lt;/p&gt;
&lt;p&gt;$$Loss= -log \frac{ \exp(sim(x_i,x_i^+)/\tau) }{\sum_{j=1}^K \exp(sim(x_i, x_i^{-j})/\tau) }$$&lt;/p&gt;
&lt;p&gt;假设我们有一个数据集，其中每个样本 xi 有一个对应的正样本 $$x_i^+$$ 和多个负样本 $$x_i^{-1}, x_i^{-2}, &amp;hellip;, x_i^{-K} $$。&lt;/p&gt;
&lt;p&gt;对于每个样本 $$x_i$$，我们希望其与正样本 $$x_i^+ $$的相似度尽可能高。&lt;/p&gt;</description></item><item><title>2025-06-12 Weaviate使用（一） 使用ollama启用大模型和向量模型</title><link>https://huizhixu.github.io/chs/know_how/20250612weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8ollama%E5%90%AF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B/</link><pubDate>Thu, 12 Jun 2025 12:50:29 +0000</pubDate><guid>https://huizhixu.github.io/chs/know_how/20250612weaviate%E4%BD%BF%E7%94%A8_%E4%BD%BF%E7%94%A8ollama%E5%90%AF%E7%94%A8%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B/</guid><description>&lt;h2 id="先决条件"&gt;先决条件&lt;/h2&gt;
&lt;p&gt;在本地用docker-compose.yml部署Weaviate。因为使用Ollama来启动模型，所以在配置文件中要加上ENABLE_MODULES: &amp;rsquo;text2vec-ollama,generative-ollama'&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;---&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;services&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; command&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;host
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;0.0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;port
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;8080&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;scheme
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; http
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; image&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; cr.weaviate.io&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;semitechnologies&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;weaviate&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;1.30&lt;/span&gt;.&lt;span style="color:#bd93f9"&gt;6&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ports&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50051&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;/var/lib/weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; restart&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; on&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;failure&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; environment&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; QUERY_DEFAULTS_LIMIT&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#bd93f9"&gt;25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; PERSISTENCE_DATA_PATH&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;/var/lib/weaviate&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_API_BASED_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;true&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ENABLE_MODULES&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;text2vec-ollama,generative-ollama&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; CLUSTER_HOSTNAME&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;node1&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;volumes&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weaviate_data&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在本地安装启动Weaviate之后，运行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; weaviate
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;client &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; weaviate.connect_to_local()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;print(client.is_ready())
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;True表示这个数据库是可用的。&lt;/p&gt;
&lt;h2 id="准备数据"&gt;准备数据&lt;/h2&gt;
&lt;p&gt;下面是jeopardy_tiny.json的例子&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-javascript" data-lang="javascript"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;SCIENCE&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;This organ removes excess glucose from the blood &amp;amp; stores it as glycogen&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Liver&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;ANIMALS&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;It&amp;#39;s the only living mammal in the order Proboseidea&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Elephant&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; },
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Category&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;ANIMALS&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Question&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;The gavial looks very much like a crocodile except for this bodily feature&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;Answer&amp;#34;&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;:&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;the nose or snout&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; }
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="创建collection"&gt;创建collection&lt;/h2&gt;
&lt;p&gt;Ollama启动服务，api_endpoint统一为http://host.docker.internal:11434，模型根据模型名填写。&lt;/p&gt;</description></item><item><title>2024-05-25 用大模型理解爆火的KAN网络</title><link>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</link><pubDate>Sat, 25 May 2024 16:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240525kan_basic/</guid><description>&lt;p&gt;五一假期的时候，KAN突然成为了热门话题。虽然最初我并没有计划弄懂它，但在老板的要求下，我还是探索了一下。&lt;/p&gt;
&lt;h2 id="一kan是什么"&gt;一、KAN是什么？&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Kolmogorov-Arnold 定理是数学领域的一个里程碑，它揭示了多元函数能够通过一组更简单的函数来近似表示的原理。&lt;/strong&gt; 在神经网络的研究领域，来自 MIT 的杰出研究者 Ziming Liu 将这一定理巧妙地融入，提出了创新的 KANs（&lt;strong&gt;Kolmogorov-Arnold Networks&lt;/strong&gt;）概念。（GitHub地址：https://github.com/KindXiaoming/pykan）。&lt;/p&gt;</description></item><item><title>2024-05-13 大型语言模型在「想」什么呢？ — 浅谈大型语言模型的可解释性</title><link>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</link><pubDate>Mon, 13 May 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</guid><description>&lt;p&gt;Explainable 和 Interpretable的区别：&lt;/p&gt;
&lt;p&gt;Explainable： 事物本身是黑箱，我们尝试去解释它的行为或输出。&lt;/p&gt;
&lt;p&gt;Interpretable： 事物本身不是黑箱，其工作原理是清晰和可以理解的。&lt;/p&gt;</description></item><item><title>2024-04-22 用大语言模型打造AI Agent</title><link>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</link><pubDate>Mon, 22 Apr 2024 23:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</guid><description>&lt;p&gt;人类需要的不仅仅是大模型，而是能做复杂的多步骤的任务的大模型，Agent因此诞生了。&lt;/p&gt;
&lt;h1 id="知名的ai-agent"&gt;知名的AI Agent&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;1. AutoGPT: &lt;a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" rel="noopener"&gt;https://github.com/Significant-Gravitas/AutoGPT&lt;/a&gt;
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AutoGPT是一个由Significant Gravitas开发的开源项目,旨在创建一个自主的AI代理,能够持续地学习、成长并完成各种任务。&lt;/p&gt;</description></item><item><title>2024-04-14 让AI村民组成虚拟村庄会发生什么事</title><link>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</link><pubDate>Sun, 14 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</guid><description>&lt;p&gt;去年Agent很火的时候，就知道有斯坦福出的这个虚拟小镇的论文了，当时大家都很好奇，怎么能够让大语言模型来操纵agent做出非常复杂的行为呢？&lt;/p&gt;</description></item><item><title>2024-04-13 大型语言模型修炼史（第三阶段）</title><link>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</link><pubDate>Sat, 13 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</guid><description>&lt;h1 id="第三阶段参与实战打磨技巧"&gt;第三阶段：参与实战，打磨技巧&lt;/h1&gt;
&lt;p&gt;如何克服第二阶段的局限性呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键是用第一阶段的参数作为初始参数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（贝叶斯定理这不就来了嘛！）&lt;/p&gt;
&lt;p&gt;所以第三阶段是由第一阶段和第二阶段组合而成的：&lt;/p&gt;
&lt;p&gt;第一阶段：通过网络上任何语料学习而来的，叫做预训练Pretrain&lt;/p&gt;</description></item><item><title>2024-04-05 大型语言模型修炼史（第一、二阶段）</title><link>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</link><pubDate>Fri, 05 Apr 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</guid><description>&lt;h1 id="背景知识"&gt;背景知识&lt;/h1&gt;
&lt;p&gt;大模型的本质是文字接龙。输入一个未完成的句子，输出这个未完成的句子的下一个token。&lt;/p&gt;
&lt;p&gt;大模型可以看成是一个函数。$$ f(未完成的句子)= 下一个token $$这个函数是一个有数十亿个未知参数的函数。&lt;/p&gt;</description></item><item><title>2024-03-05 改进量的期望 Expected Improvement</title><link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link><pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid><description>&lt;p&gt;在看正文之前，先复习一下期望（Expectation）：&lt;/p&gt;
&lt;p&gt;在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。&lt;/p&gt;
&lt;p&gt;对于一个连续随机变量&lt;em&gt;X&lt;/em&gt;，其期望值可以通过以下公式计算：&lt;/p&gt;</description></item><item><title>2024-02-03 Bayesian Optimization</title><link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link><pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid><description>&lt;p&gt;贝叶斯优化有重要的两步步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造代理模型（surrogate model）&lt;/li&gt;
&lt;li&gt;由获取函数（acquisition function）来生成采样建议&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;贝叶斯优化中，因为不知道目标函数的closed-form，所以需要构造一个代理模型（surrogate model）来近似目标函数。记住，代理模型对目标函数的潜在分布进行建模。通常用gaussian process来作为代理模型，也可以用random forest来作为代理模型。（任何模型，只要它为函数提供后验估计，可以用来作为surrogate model）。&lt;/p&gt;</description></item><item><title>2024-02-22 grobid的使用</title><link>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240222grobid%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;p&gt;最近被文本分块虐得不轻，看到有人介绍grobid，赶紧用上了。&lt;/p&gt;
&lt;h3 id="1-grobid-介绍"&gt;1. Grobid 介绍&lt;/h3&gt;
&lt;p&gt;Grobid 的全称是Generation of Bibliographic Data。它用机器学习来解析、提取文档。&lt;/p&gt;</description></item><item><title>2023-12-17 Gaussian Process Regression with GPyTorch</title><link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link><pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid><description>&lt;p&gt;这个例子主要是利用GPytorch，来实现高斯过程回归。&lt;/p&gt;
&lt;h1 id="计算mean"&gt;计算Mean&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;zero mean function &lt;code&gt;gpytorch.means.ZeroMean()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;constant mean function &lt;code&gt;gpytorch.means.ConstantMean()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;linear mean function &lt;code&gt;gpytorch.means.LinearMean()&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="计算covariance"&gt;计算Covariance&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;RBFKernel &lt;code&gt;gpytorch.kernels.RBFKernel()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;adding a scaling coefficient: &lt;code&gt;kernels.ScaleKernel(gpytorch.kernels.RBFKernel())&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一般会在核函数的输出上添加缩放系数。&lt;/p&gt;
&lt;p&gt;在核函数的输出上添加缩放系数是为了调整核函数的影响力。&lt;/p&gt;</description></item><item><title>2023-12-10 Gaussian Process in Practice 高斯过程实践</title><link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link><pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid><description>&lt;p&gt;这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。&lt;/p&gt;
&lt;h2 id="1-先验分布"&gt;1. 先验分布&lt;/h2&gt;
&lt;h4 id="11-多变量高斯分布"&gt;1.1 多变量高斯分布&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;创建一个包含n个候选输入位置的列表${x_i，i=1,&amp;hellip;,n}$&lt;/li&gt;
&lt;li&gt;初始化均值向量μ和协方差矩阵K（含n x n个元素）
&lt;ul&gt;
&lt;li&gt;假设x_1和x_2是多维的矩阵。x_1是一个 m* d的矩阵，x_2是一个n&lt;em&gt;d的矩阵，那么K是一个m&lt;/em&gt;n的矩阵，$K[i,j] = k(x_1[i,:], x_2[j,:])$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;执行Cholesky分解K=LL T来获得L&lt;/li&gt;
&lt;li&gt;通过LN（0,I）获得N（0,K）上的一个样本并存储在f_prior中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;multivariante_samples01 和multivariante_samples02 这两个function的作用是一样的，只不过有两种写法。&lt;/p&gt;</description></item><item><title>2023-12-07 Kernel Function 核函数</title><link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link><pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid><description>&lt;p&gt;这篇文章主要解决三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;正态分布的表示&lt;/li&gt;
&lt;li&gt;核函数是什么，有什么类型&lt;/li&gt;
&lt;li&gt;已知先验知识，如何计算后验分布&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="1-正态分布的表示"&gt;1. 正态分布的表示&lt;/h2&gt;
&lt;p&gt;正态分布一般表示为$f \sim N(0,K)$，书上写作 $p(f|x) = N(f|0,K)$。&lt;/p&gt;</description></item><item><title>2023-11-25 书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title><link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link><pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid><description>&lt;h2 id="1-理解covariance-matrix"&gt;1. 理解covariance matrix&lt;/h2&gt;
&lt;p&gt;Gaussian Process is a stochastic process used to characterize the distribution over function.&lt;/p&gt;
&lt;p&gt;GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。&lt;/p&gt;
&lt;p&gt;假设我们有两个变量，X1和X2，它俩符合multivariate Gaussian distribution。&lt;/p&gt;</description></item><item><title>2023-11-20 论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title><link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link><pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid><description>&lt;p&gt;Abstract&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;types
&lt;ul&gt;
&lt;li&gt;第一种分类
&lt;ul&gt;
&lt;li&gt;data uncertainty (measurement noise)&lt;/li&gt;
&lt;li&gt;model uncertainty ( limited data)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;第二种分类
&lt;ul&gt;
&lt;li&gt;epistemic uncertainty
&lt;ul&gt;
&lt;li&gt;认知上的不确定性，通常是由于没有足够的知识（数据）而产生&lt;/li&gt;
&lt;li&gt;can be reducible&lt;/li&gt;
&lt;li&gt;分为两类
&lt;ul&gt;
&lt;li&gt;model-form uncertainty
&lt;ul&gt;
&lt;li&gt;由于模型的选择导致，例如architectures, activation functions or kernel functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;parameter uncertainty
&lt;ul&gt;
&lt;li&gt;在训练过程产生，由于数据不够导致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;aleatory uncertainty
&lt;ul&gt;
&lt;li&gt;stems from physical systems, 具有随机性, cannot be reducible&lt;/li&gt;
&lt;li&gt;e.g. noises&lt;/li&gt;
&lt;li&gt;这种类型的不确定性在ML模型里面被看成是似然函数的一部分(a part of the likelihood function)&lt;/li&gt;
&lt;li&gt;也被叫做data uncertainty&lt;/li&gt;
&lt;li&gt;捕捉这种不确定性的方式有：同方差 homoscedastic和异方差 heteroscedastic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例子：
&lt;ul&gt;
&lt;li&gt;test data和train data不同分布：epistemic uncertainty (model performs poorer in extrapolation than in interpolation)&lt;/li&gt;
&lt;li&gt;测量数据由仪器导致的误差是aleatory Unc， 大试如果由于精度原因导致，则属于epistemic unc，因为提高精度可以减少这个误差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;causes&lt;/li&gt;
&lt;li&gt;methods:
&lt;ul&gt;
&lt;li&gt;Gaussian process regression
&lt;ul&gt;
&lt;li&gt;a ML method with UQ capability&lt;/li&gt;
&lt;li&gt;一般不用来quantify uncertainty of a final surrogate&lt;/li&gt;
&lt;li&gt;一般用来在高度不确定的采样空间里采样，来减少训练样本的数量
&lt;ul&gt;
&lt;li&gt;to build an accurate surrogate within some lower and upper bounds of input variables&lt;/li&gt;
&lt;li&gt;to find a globally optimally design for black-box objective function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一般不评估GPR的UQ质量
&lt;ul&gt;
&lt;li&gt;因为预测一般在pre-defined design bounds&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bayesian neural network
&lt;ul&gt;
&lt;li&gt;Monte Carlo dropout as an alternative to traditional Bayesian neural network&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;neural network ensemble
&lt;ul&gt;
&lt;li&gt;neural network ensemble consisting of multiple neural networks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;deterministic UQ methods&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;metrics
&lt;ul&gt;
&lt;li&gt;classification
&lt;ul&gt;
&lt;li&gt;probability can be viewed as uncertainty&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;regression
&lt;ul&gt;
&lt;li&gt;confidence interval :
&lt;ul&gt;
&lt;li&gt;没看懂： prediction may be 120 ± 15, in weeks, which represents a two-sided 95% confidence interval (i.e.,∼1.96 standard deviations subtracted from or added to the mean estimate assuming the model-predicted RUL follows a Gaussian distribution).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>2023-07-20Redash V10安装（在Ubuntu系统上用docker部署安装）</title><link>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</link><pubDate>Thu, 20 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230720redash%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95/</guid><description>&lt;p&gt;市面上的Redash教程太混乱了，官方发布了不同的安装方式，但是写得不是很明白。基本上都会有一个重复安装和卸载的过程，是正常的。&lt;/p&gt;
&lt;p&gt;这次安装的经验就是：&lt;/p&gt;</description></item><item><title>2023-07-19Ubuntu上安装Docker</title><link>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</link><pubDate>Wed, 19 Jul 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230719ubuntu%E4%B8%8A%E5%AE%89%E8%A3%85docker/</guid><description>&lt;h1 id="一设置docker-repository"&gt;一、设置Docker Repository&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;升级&lt;code&gt;apt-get&lt;/code&gt;到最新&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get update
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get install ca&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;certificates curl gnupg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="2"&gt;
&lt;li&gt;添加Docker的官方GPG key&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo install &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;m &lt;span style="color:#bd93f9"&gt;0755&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;d &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;curl &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;fsSL https:&lt;span style="color:#ff79c6"&gt;//&lt;/span&gt;download&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;com&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;linux&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;ubuntu&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;gpg &lt;span style="color:#ff79c6"&gt;|&lt;/span&gt; sudo gpg &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;dearmor &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;o &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gpg
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo chmod a&lt;span style="color:#ff79c6"&gt;+&lt;/span&gt;r &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;keyrings&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;gpg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="3"&gt;
&lt;li&gt;设置仓库&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;echo \
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;deb [arch=&amp;#34;&lt;/span&gt;$(dpkg &lt;span style="color:#ff79c6"&gt;--&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;architecture)&lt;span style="color:#f1fa8c"&gt;&amp;#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu &lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f1fa8c"&gt;&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt; &amp;#34;&lt;/span&gt;$(&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;os&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;release &lt;span style="color:#ff79c6"&gt;&amp;amp;&amp;amp;&lt;/span&gt; echo &lt;span style="color:#f1fa8c"&gt;&amp;#34;$VERSION_CODENAME&amp;#34;&lt;/span&gt;)&lt;span style="color:#f1fa8c"&gt;&amp;#34; stable&amp;#34;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;|&lt;/span&gt; \
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; sudo tee &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;etc&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;apt&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;sources&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;list&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;d&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;docker&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;list &lt;span style="color:#ff79c6"&gt;&amp;gt;&lt;/span&gt; &lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;dev&lt;span style="color:#ff79c6"&gt;/&lt;/span&gt;null
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="二安装docker-engine"&gt;二、安装Docker Engine&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;升级apt-get到最新&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="2"&gt;
&lt;li&gt;安装最新版本的Docker Engine， containerd和Docker Compose&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo apt&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;get install docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;ce docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;ce&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;cli containerd&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;io docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;buildx&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;plugin docker&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;compose&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;plugin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start="3"&gt;
&lt;li&gt;确保安装成功&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo docker run hello&lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;world
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="三配置docker环境"&gt;三、配置Docker环境&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#配置log文件大小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo sh &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;c &lt;span style="color:#f1fa8c"&gt;&amp;#39;mkdir /etc/docker &amp;amp;&amp;amp; cat &amp;gt; /etc/docker/daemon.json &amp;lt;&amp;lt; EOF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;log-driver&amp;#34;&lt;/span&gt;:&lt;span style="color:#f1fa8c"&gt;&amp;#34;json-file&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#34;log-opts&amp;#34;&lt;/span&gt;:{ &lt;span style="color:#f1fa8c"&gt;&amp;#34;max-size&amp;#34;&lt;/span&gt; :&lt;span style="color:#f1fa8c"&gt;&amp;#34;50m&amp;#34;&lt;/span&gt;,&lt;span style="color:#f1fa8c"&gt;&amp;#34;max-file&amp;#34;&lt;/span&gt;:&lt;span style="color:#f1fa8c"&gt;&amp;#34;3&amp;#34;&lt;/span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;EOF&lt;span style="color:#f1fa8c"&gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#将当前用户加入docker组&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo usermod &lt;span style="color:#ff79c6"&gt;-&lt;/span&gt;aG docker $USER
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#6272a4"&gt;#启动docker服务并配置自启&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sudo systemctl start docker &lt;span style="color:#ff79c6"&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo systemctl enable docker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id="四参考"&gt;四、参考&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener"&gt;Docker官网安装&lt;/a&gt;
&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2023-04-27GPU运行LLaMa模型——用HF的方式推理</title><link>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</link><pubDate>Thu, 27 Apr 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230427gpu%E8%BF%90%E8%A1%8Cllama%E6%A8%A1%E5%9E%8Bhf%E6%96%B9%E5%BC%8F/</guid><description>&lt;p&gt;在GPU上运行中文LLaMa模型，主要是按照 &lt;a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener"&gt;https://github.com/ymcui/Chinese-LLaMA-Alpaca&lt;/a&gt;
 这个仓库的方法。
中文LLaMa模型和中文Alpaca的区别是：中文LLaMa在英文llama的基础上扩充了中文词表并且使用了中文数据进行二次训练。中文LLaMa只能进行单轮问答。中文Alpaca经过instruct-tuning 生成，可以进行多轮问答。本次实验主要是针对中文LLaMa模型。&lt;/p&gt;</description></item><item><title>2023-03-05用随机梯度下降来优化人生【转载】</title><link>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</link><pubDate>Sun, 05 Mar 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230305%E7%94%A8%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%9D%A5%E4%BC%98%E5%8C%96%E4%BA%BA%E7%94%9F/</guid><description>&lt;h2 id="要有目标"&gt;要有目标。&lt;/h2&gt;
&lt;p&gt;你需要有目标。短的也好，长的也好。认真定下的也好，别人那里捡的也好。就跟随机梯度下降需要有个目标函数一样。&lt;/p&gt;
&lt;h2 id="目标要大"&gt;目标要大。&lt;/h2&gt;
&lt;p&gt;不管是人生目标还是目标函数，你最好不要知道最后可以走到哪里。如果你知道，那么你的目标就太简单了，可能是个凸函数。你可以在一开始的时候给自己一些小目标，例如期末考个80分，训练一个线性模型。但接下来得有更大的目标，财富自由也好，100亿参数的变形金刚也好，得足够一颗赛艇。&lt;/p&gt;</description></item><item><title>2023-03-01我都用chatGPT干了啥</title><link>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</link><pubDate>Wed, 01 Mar 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230301%E6%88%91%E9%83%BD%E7%94%A8chatgpt%E5%B9%B2%E4%BA%86%E5%95%A5/</guid><description>&lt;ol&gt;
&lt;li&gt;写诗&lt;/li&gt;
&lt;li&gt;帮我写程序&lt;/li&gt;
&lt;li&gt;帮我debug&lt;/li&gt;
&lt;li&gt;帮我构造数据&lt;/li&gt;
&lt;li&gt;帮我优化Resume&lt;/li&gt;
&lt;li&gt;梳理NLP知识时，解释不清晰的名词，并给出例子&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2023-02-20 chatGPT有可能是个骗局吗</title><link>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</link><pubDate>Mon, 20 Feb 2023 20:07:58 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230220chatgpt%E6%9C%89%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%AA%E9%AA%97%E5%B1%80%E5%90%97/</guid><description>&lt;p&gt;昨天读了一篇文章：&lt;a href="https://www.newyorker.com/tech/annals-of-technology/chatGPT-is-a-blurry-jpeg-of-the-web" target="_blank" rel="noopener"&gt;ChatGPT is a blurry JPEG of the web&lt;/a&gt;
。中文翻译在这：&lt;a href="http://www.chinawriter.com.cn/n1/2023/0213/c404090-32622497.html" target="_blank" rel="noopener"&gt;ChatGPT是网上所有文本的模糊图像&lt;/a&gt;
 ，无比同意这篇文章说的，&amp;ldquo;有一种模糊是可以接受的，那就是用不同的词重新陈述信息；对于完全捏造的模糊，当我们寻找事实时，我们认为这是不可接受的&amp;rdquo;。这就是我使用chatGPT的感受。&lt;/p&gt;</description></item><item><title>2023-02-16 如何理解Seq2seq</title><link>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</link><pubDate>Thu, 16 Feb 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230216%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3seq2seq/</guid><description>&lt;p&gt;先搞清楚几个基本概念：&lt;/p&gt;
&lt;p&gt;Seq2seq是一个概念，它的表现形式就是有encoder和decoder的一个结构。换言之，有encoder和decoder就可以说这是一个Seq2seq模型。编码器或者解码器具体可以用CNN、RNN、LSTM或者attention来构建。&lt;/p&gt;</description></item><item><title>2023-02-13 chatGPT 在攻陷所有人</title><link>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</link><pubDate>Mon, 13 Feb 2023 20:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230213chatgpt%E5%9C%A8%E6%94%BB%E9%99%B7%E6%89%80%E6%9C%89%E4%BA%BA/</guid><description>&lt;p&gt;承认吧，现在全世界最火就是chatGPT。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;去参加了王建硕老师那边组织的关于chatGPT的讨论。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;会上的讨论：对新技术进行哲学思考无疑是最让我震撼的。正因为他们进行深度思考，才能真正看到事物的本质，才能正确判断事物的走向。&lt;/li&gt;
&lt;li&gt;从心理学和教育学来看，也开拓了我的眼界。&lt;/li&gt;
&lt;li&gt;从高效使用和商业化来看，它无疑会改变很多人的生活。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;chatGPT的使用感受很不错。&lt;/p&gt;</description></item><item><title>2023-02-09 如何理解自注意力机制</title><link>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 09 Feb 2023 08:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid><description>&lt;h2 id="理解输入与输出"&gt;理解输入与输出&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;输入有可能是一个 vector，有可能是多个 vector&lt;/li&gt;
&lt;li&gt;输出：
&lt;ul&gt;
&lt;li&gt;一个序列对应一个 label。the whole sequence has a label
&lt;ul&gt;
&lt;li&gt;例子：在情感分析里面，This is good 对应的输入是多个 vector，输出为 positive，是一个vector。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一个 vector 对应一个 label。一个序列对应多个 label。
&lt;ul&gt;
&lt;li&gt;例子：在词性标注里面，This is good 对应的输入是多个 vector，输出为 代词，动词，形容词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;模型决定 label 的个数。seq2seq 任务
&lt;ul&gt;
&lt;li&gt;例子：在机器翻译里面，This is good 对应的输入是3个 vector，中文翻译是”不错“，输出为2个 vector。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="一个vector对应一个label的情况即输入和输出一样多也叫做sequence-labeling"&gt;一个vector对应一个label的情况，即输入和输出一样多，也叫做sequence labeling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;例子： I saw a saw&lt;/li&gt;
&lt;li&gt;如何解决 sequence labeling 的问题：用 fully connected network 对每一个 input vector 进行作用&lt;/li&gt;
&lt;li&gt;弊端：
&lt;ul&gt;
&lt;li&gt;用 fully connected network 来输出，假设对 I saw a saw 做词性标注。对于 FC 层来说，两个 saw没有什么不同，但是他们实际上一个是动词，一个是名词。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;解决思路：考虑更多的上下文。每一个 fc 层，都对所有的输入作用。或者给他一个 window，作用于相邻的几个 input vector。但是作用还是有限，计算也很复杂。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们想考虑整个 sequence，但是不想把 sequence 所有的数据都包括在里面，就有了 self-attention。&lt;/p&gt;</description></item><item><title>2023-01-31 如何用HuggingFace对不均衡类别进行分类</title><link>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</link><pubDate>Tue, 31 Jan 2023 19:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20230131%E5%A6%82%E4%BD%95%E7%94%A8huggingface%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</guid><description>&lt;h2 id="数据均衡"&gt;数据均衡&lt;/h2&gt;
&lt;p&gt;做文本分类时，如果类别数量差别不大，可以用hugging face的Trainer类，训练代码如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;model &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BertForSequenceClassification&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;from_pretrained(&lt;span style="color:#f1fa8c"&gt;&amp;#34;bert-base-chinese&amp;#34;&lt;/span&gt;, num_labels&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;len&lt;/span&gt;(labels),
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; problem_type&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#f1fa8c"&gt;&amp;#34;multi_label_classification&amp;#34;&lt;/span&gt;, id2label&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;id2label,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; label2id&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;label2id)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tokenizer &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; BertTokenizerFast&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;from_pretrained(&lt;span style="color:#f1fa8c"&gt;&amp;#34;bert-base-chinese&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;def&lt;/span&gt; &lt;span style="color:#50fa7b"&gt;compute_metrics&lt;/span&gt;(p):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; preds &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions[&lt;span style="color:#bd93f9"&gt;0&lt;/span&gt;] &lt;span style="color:#ff79c6"&gt;if&lt;/span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;isinstance&lt;/span&gt;(p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#8be9fd;font-style:italic"&gt;tuple&lt;/span&gt;) &lt;span style="color:#ff79c6"&gt;else&lt;/span&gt; p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;predictions
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; result &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; multi_label_metrics(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; predictions&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;preds,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; labels&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;p&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;label_ids)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#ff79c6"&gt;return&lt;/span&gt; result
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;training_args &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; TrainingArguments(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; output_dir&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;model_directory, 
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; learning_rate&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;5e-5&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; per_device_train_batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; per_device_eval_batch_size&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;2&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; num_train_epochs&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;3&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; dataloader_drop_last&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#ff79c6"&gt;True&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; weight_decay&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;0.01&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; save_steps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logging_steps&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;&lt;span style="color:#bd93f9"&gt;50&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; Trainer(
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; model&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;model,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; args&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;training_args,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; train_dataset&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#34;train&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; eval_dataset&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;data[&lt;span style="color:#f1fa8c"&gt;&amp;#34;train&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; tokenizer&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;tokenizer,
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; compute_metrics&lt;span style="color:#ff79c6"&gt;=&lt;/span&gt;compute_metrics
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;train()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;trainer&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;evaluate()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;model_directory 是模型存储路径，data是数据。&lt;/p&gt;</description></item><item><title>2022-12-10 HuggingFace的Dataset的使用</title><link>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 10 Dec 2022 18:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20221210huggingface%E7%9A%84dataset%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description>&lt;h2 id="hub上的数据集"&gt;hub上的数据集&lt;a name="datasets from the hub"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;（这里不是互联网上任意的数据集，专指Huggingface的hub上面的，就是可以用关键字直接下载的）&lt;/p&gt;
&lt;p&gt;数据集可以在&lt;a href="https://huggingface.co/datasets" target="_blank" rel="noopener"&gt;https://huggingface.co/datasets&lt;/a&gt;
 找到，另外也可以用**&lt;code&gt;datasets.list_datasets()&lt;/code&gt;
来看有什么数据集，然后通过关键字下载。&lt;/p&gt;</description></item><item><title>2022-10-24 在程序里起名有很多要注意的</title><link>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</link><pubDate>Mon, 24 Oct 2022 20:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20221024%E5%A6%82%E4%BD%95%E5%9C%A8%E7%A8%8B%E5%BA%8F%E4%B8%AD%E8%B5%B7%E5%90%8D/</guid><description>&lt;p&gt;最近检查以前写的代码，发现我给不同的功能函数或者变量起的名不是很精确。 比如数据处理这个阶段，就很容易取 &lt;code&gt;data_process&lt;/code&gt;， &lt;code&gt;get_data&lt;/code&gt;，&lt;code&gt;process_data&lt;/code&gt;，&lt;code&gt;data_preprocess&lt;/code&gt;，&lt;code&gt;deal_with_data&lt;/code&gt; 这些名字。再比如很多类的主入口，我经常会写 &lt;code&gt;run()&lt;/code&gt;、&lt;code&gt;xx_driver()&lt;/code&gt; 等等。&lt;/p&gt;</description></item><item><title>2022-08-02 用 HanLP 分词时如何自定义词典</title><link>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</link><pubDate>Tue, 02 Aug 2022 17:51:00 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20220802%E7%94%A8hanlp%E5%88%86%E8%AF%8D%E6%97%B6%E5%A6%82%E4%BD%95%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AF%8D%E5%85%B8/</guid><description>&lt;p&gt;在分词的过程中，碰到一个这样的句子：&lt;/p&gt;
&lt;p&gt;&amp;lsquo;&lt;code&gt;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&lt;/code&gt;&amp;rsquo;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#ff79c6"&gt;import&lt;/span&gt; hanlp
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;tok &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; hanlp&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;load(hanlp&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;pretrained&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;tok&lt;span style="color:#ff79c6"&gt;.&lt;/span&gt;COARSE_ELECTRA_SMALL_ZH)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sentence &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; &lt;span style="color:#f1fa8c"&gt;&amp;#39;公司产品品质持续提升，单晶硅片用料比例大幅高于行业平均，单晶硅料价格上涨。&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;sen_list &lt;span style="color:#ff79c6"&gt;=&lt;/span&gt; tok(sentence)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#8be9fd;font-style:italic"&gt;print&lt;/span&gt;(sen_list)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;[&lt;span style="color:#f1fa8c"&gt;&amp;#39;公司&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;产品&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;品质&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;持续&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;提升&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;，&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;单晶&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;硅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;片&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;用&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;料&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;比例&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;大幅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;高于&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;行业&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;平均&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;，&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;单晶&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;硅&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;料&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;价格&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;上涨&amp;#39;&lt;/span&gt;, &lt;span style="color:#f1fa8c"&gt;&amp;#39;。&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看出来，这里“单晶硅片”，“单晶硅料”， 被分为了“单晶”“硅”“料”和“单晶”“硅”“片”。&lt;/p&gt;</description></item></channel></rss>