<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Llm on 徐慧志的个人博客</title><link>https://huizhixu.github.io/chs/tags/llm/</link><description>Recent content in Llm on 徐慧志的个人博客</description><generator>Hugo</generator><language>chs</language><lastBuildDate>Mon, 13 May 2024 19:01:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>大型语言模型在「想」什么呢？ — 浅谈大型语言模型的可解释性</title><link>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</link><pubDate>Mon, 13 May 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240513explainable_llm/</guid><description>&lt;p>Explainable 和 Interpretable的区别：&lt;/p>
&lt;p>Explainable： 事物本身是黑箱，我们尝试去解释它的行为或输出。&lt;/p>
&lt;p>Interpretable： 事物本身不是黑箱，其工作原理是清晰和可以理解的。&lt;/p></description></item><item><title>用大语言模型打造AI Agent</title><link>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</link><pubDate>Mon, 22 Apr 2024 23:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240421ai_agent/</guid><description>&lt;p>人类需要的不仅仅是大模型，而是能做复杂的多步骤的任务的大模型，Agent因此诞生了。&lt;/p>
&lt;h1 id="知名的ai-agent">知名的AI Agent&lt;/h1>
&lt;p>&lt;strong>1. AutoGPT: &lt;a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank" rel="noopener">https://github.com/Significant-Gravitas/AutoGPT&lt;/a>
&lt;/strong>&lt;/p>
&lt;p>AutoGPT是一个由Significant Gravitas开发的开源项目,旨在创建一个自主的AI代理,能够持续地学习、成长并完成各种任务。&lt;/p></description></item><item><title>让AI村民组成虚拟村庄会发生什么事</title><link>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</link><pubDate>Sun, 14 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240414ai_virtual_town/</guid><description>&lt;p>去年Agent很火的时候，就知道有斯坦福出的这个虚拟小镇的论文了，当时大家都很好奇，怎么能够让大语言模型来操纵agent做出非常复杂的行为呢？&lt;/p></description></item><item><title>大型语言模型修炼史(第三阶段)</title><link>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</link><pubDate>Sat, 13 Apr 2024 19:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240413the-history-of-cultivating-llm_second_part/</guid><description>&lt;h1 id="第三阶段参与实战打磨技巧">第三阶段：参与实战，打磨技巧&lt;/h1>
&lt;p>如何克服第二阶段的局限性呢？&lt;/p>
&lt;p>&lt;strong>关键是用第一阶段的参数作为初始参数。&lt;/strong>&lt;/p>
&lt;p>（贝叶斯定理这不就来了嘛！）&lt;/p>
&lt;p>所以第三阶段是由第一阶段和第二阶段组合而成的：&lt;/p>
&lt;p>第一阶段：通过网络上任何语料学习而来的，叫做预训练Pretrain&lt;/p></description></item><item><title>大型语言模型修炼史（第一、二阶段）</title><link>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</link><pubDate>Fri, 05 Apr 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240405the-history-of-cultivating-llm/</guid><description>&lt;h1 id="背景知识">背景知识&lt;/h1>
&lt;p>大模型的本质是文字接龙。输入一个未完成的句子，输出这个未完成的句子的下一个token。&lt;/p>
&lt;p>大模型可以看成是一个函数。$$ f(未完成的句子)= 下一个token $$这个函数是一个有数十亿个未知参数的函数。&lt;/p></description></item></channel></rss>