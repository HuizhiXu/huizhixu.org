<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>emoji on 徐慧志的个人博客</title>
    <link>https://huizhixu.github.io/chs/tags/emoji/</link>
    <description>Recent content in emoji on 徐慧志的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>chs</language>
    <lastBuildDate>Fri, 02 Jun 2023 18:31:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/tags/emoji/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2023-03-02 季读——2023年（一）</title>
      <link>https://huizhixu.github.io/chs/treasure/20230302%E5%AD%A3%E8%AF%BB/</link>
      <pubDate>Fri, 02 Jun 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/treasure/20230302%E5%AD%A3%E8%AF%BB/</guid>
      <description>本来过年的时候想着今年要读一些书，每个月都至少读一本，结果今天发现已经三月份了，我还在读第一本书。
虽然没有读书，但是看了很多别人写的材料，博客，听了很多访谈。当然，主要因为chatGPT的爆火，公众号每天都充斥着关于大模型的知识。 有一些大咖表面上在聊chatGPT，其实是趁机卖自己的课和书；还有一些人觉得这是个绝佳的创业的机会；还有一些号，明明和他八竿子打不着关系，还要硬往上面蹭。
还记得去年冬天，行业加上疫情的原因，一片萧瑟，各大媒体都在唱衰，说是 AI 寒冬，结果过了个年就变成了AI盛世。 也不知道这个热火朝天的劲头能持续多久。
chatGPT会是一个变革性的产品吗？就像信息时代让我们的生活发生翻天覆地的变化那样，人工智能时代也会让我们有完全不同的生活体验吗？ 还很难说。人工智能只是少数人的游戏，因为目前来说，他太昂贵了。 先进的技术带来高效，但是与固有的生产方式相比，它并不一定能省钱。
另外，通过chatGPT，加深了我对认知的重视程度。 一开始我总是在想 openAI 和用户数据之间的关系，想着他们会不会用户输入的数据进行清洗，在此基础上做后续模型升级。 我以为只有花钱用上chatGPT的那些人，他们的数据才是有价值的数据。这种认知就错了。数据永远都是有用的，但是对于每一个组织的作用是不同的。 而openAI不需要去深究这些数据，他们只需要提供接口服务就可以收割全世界。当然他们肯定想做更多。所以认知上的差异，会导致决策差异。
不过，我还有另外一些疑问。机器和人对齐，增强了机器的性能。这其实是仿生学，哪种动物在哪方面做得好，我们就利用这方面，学习这方面。 但是，对于人来说， 我们人类除了学习用文字写出来的知识，我们也学会了一种&amp;quot;上下文&amp;quot;。一个小学生，在学校不仅仅学了加减乘除，也学会了如何和同学打交道，每一件事情的发生都在他身上有影响。 那么机器如何拥有这种能力呢？
推荐我读的一些博客文章：
Why everybody feels like theyr&amp;rsquo;e faking it? https://www.newyorker.com/magazine/2023/02/13/the-dubious-rise-of-impostor-syndrome Fix the machine, not the person by aaron Swartz
http://www.aaronsw.com/weblog/productivity Life in Suburbia: Land of Cliche http://www.aaronsw.com/weblog/suburbia how to work hard http://paulgraham.com/hwh.html 做大事的人除了有天分，还有练习以及时间投入。
《微积分的力量》
里面引用了两段话
I do not remember having felt, as a boy, any passion for mathematics, and such notions as I may have had of the career of a mathematician were far from noble.</description>
    </item>
    
    <item>
      <title>2023-06-02 季读——2023年（二）</title>
      <link>https://huizhixu.github.io/chs/treasure/20230602%E5%AD%A3%E8%AF%BB/</link>
      <pubDate>Fri, 02 Jun 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/treasure/20230602%E5%AD%A3%E8%AF%BB/</guid>
      <description>今天早上醒来，看到朋友圈大家都在（给娃）庆祝儿童节，发现居然已经到了6月了。想起自己的季读还没写多少。😄
由于行业技术的快速发展，这个季度基本都在一个提高认知、拓宽眼界的技术氛围里。因此，我在这段时间里阅读的大部分文章都与技术有关。
《Prompt Tuning的万字综述》 （https://wjn1996.blog.csdn.net/article/details/120607050） 读了四个多小时，没有全部读完。之前对Prompt Tuning的理解仅仅停留在第三章：如何构建模板，但是到第三章只是入门，后面还有更多的细节。最精髓的就是一句话：prompt的本质是参数有效性学习。
《LLM as Controller 无限拓展LLM的能力边界》（https://zhuanlan.zhihu.com/p/626736120） 作者的抽象能力很强，它描述了LangChain那一套如何运作的，让我很受启发。
它把大模型回答问题的这个过程抽象成一个系统，这个系统只包括LLM和Agent，其中LLM理解输入并且将输入转化成不同的指令，Agent接收指令并行动。假设LLM理解能力很强，100%理解输入的意思，Agent 力量很强，100%能够执行命令。那么，理论上这个LLM+Agent的组合能够做任何事情。
那这样的话，可以进一步缩小空间，问题变成下面两个问题：第一，LLM对输入进行理解之后，转变成怎样的指令，才能被更好地被Agent执行？第二，Agent要去哪里执行指令，才能找到更好的回答？
下面是一些例子，越往下，功能越多，也越难做。这一层一层叠加，真是牛啊~
Visual ChatGPT：单一任务——agent去一些基于视觉的模型里面找答案。
HuggingGPT：多重任务——agent根据不同的输入去不同的模型（基于hf hub）里面找答案。
Toolformer：多重任务——agent的范围更大，是网络上的不同的API（例如谷歌搜索、谷歌翻译）等。
AutoGPT：多重任务——llm和agent能自我迭代。agent会不断反馈，llm根据反馈的答案调整生成更好的指令，形成正向反馈。
《它帮大语言模型消除“幻觉”，一个月内三家向量数据库创业公司获新融资》（https://mp.weixin.qq.com/s/Fhz2O03JkdqZWug2cF7v_A） 为啥大家的目光最近会聚集在向量数据库上面呢？主要是由于大模型的缺陷。
向量数据库是怎么用的呢？以下是一个理解。
假设我们现在有一堆文档，内容是某个保险领域的所有条款。用户提出一些问题，例如，用户问：老人在什么情况下可以投某种保险？我们想要GPT4在这堆文档中找出答案，回答用户。
首先，要知道的是，GPT4输入的token长度是有限制的。大模型只能输入几千个token，但这堆保险文档有几百万个token，大模型它没法一次读啊。
很容易想到，大模型没法一次读，那就拆解让它读多次就好啦~
但是，拆解也是不OK的。主要原因是一，这几百万个token截断之后再拼起来的效果不好。二，太贵了，太慢了。调用GPT4几万次只为回答一个问题，没有人会这么做。
那么就用到向量数据库了。向量数据库会存向量，也是就一堆拥有很多中括号和小数的数值。它一般用来做相似度查找。
我们可以把上面的文档都存在向量数据库里，把用户的问题也转化为向量，然后去搜相似的文本。文本找出来了之后，再传给大模型，让它去分析，给出答案。
这样大模型的输入是不是一下子从百万级变成了万千级，而且向量数据库搜索的效率也很快，所以理论上整个流程就打通了。
这个本地知识库，其实在每个领域都能应用，特别是文本资料很多的法律、保险、金融领域。
但是，向量数据库是一个中间产物。如果我们基于某一个专业领域的大量数据训练了一个大模型，它本身读了很多这个领域的知识，所有的知识点它都了然于心，那么就不需要向量数据库了。或者，如果大模型的输入支持百万、千万数量级的token，也不需要向量数据库了。未来有一天或许能实现呢？
《最早出发的中国大模型创业者：“贫穷限制了我们的想象力”》 这篇文章我读了好多遍，虽然我经历没有周博士那么多，看得没有那么远，但在一些方面也感同身受。还蛮佩服他19年出来创业的，因为后面就是AI寒冬了。那时AI领域像是一潭死气沉沉的冬水，大家发现算法也不是万能的呀，还不如规则和廉价人工好使（狗头）。然后今年，情况明显不一样了，突然变成了so-called ”AI盛世“。但是大模型真的能快速落地吗？
特别是在周博士在的金融领域，有两个限制：一是对结果要求非常准确；二是国内的企业（专指国企央企）有信创的需求。这种情况下，如何去研发大模型，要研发怎样的大模型呢？
他这里面说“贫穷限制了想象力”，在1980年做开发的时候需要考虑节省算力。刚好《黑客与画家》里面也写了“他们在编程的时候需要删去一部分代码，为了节省内存”，但是大模型需要的就是海量数据+超乎想象的算力。
看完文章，我深深地感受到：时代的局限带给单个个体的影响，近乎一种残忍，哪怕是超级有能力的人，也无法跳出禁锢，上一代人没有能力在千亿参数层级去想象，这就已经决定了结果。
《疯狂的幻方：一家隐形AI巨头的大模型之路》（https://mp.weixin.qq.com/s/T-ccVKG_LS4OvUXQIfsoeg） 一家宣称不做垂类和应用，只做研究的公司。钱和算力都有，就是不知道有没有技术，哈哈持怀疑态度。（真羡慕他们的算力啊~ ）
最近的技术变化得实在太快了。在非常tough地学习了一天的新知识之后，精疲力尽地，第二天早上起来，发现又出来新的东西了。而且很有可能，昨天学的过时了。。。
所以，也看了不会过时的文章和书：
《从权力和垄断的演化机制，看投资(一）》 这篇文章的最重要的话就是：
权力斗争的关键就是 i) 在关键环节上，尽可能让自己不可替代。ii) 同时在与自己合作的关键环节上，确保有替代者可互相制约。
这篇文章是纠结要不要跳槽的那时候读的，让我看清了自己在前公司的地位：我的可替代性太强了。这也提醒我了，要去慢慢地构建自己的生态圈。
《软件工程》——李爱萍
《黑客与画家》
这两本书的内容下次写吧。</description>
    </item>
    
    <item>
      <title>2021-10-30 回国内卷</title>
      <link>https://huizhixu.github.io/chs/life/20211031%E5%9B%9E%E5%9B%BD%E5%86%85%E5%8D%B7/</link>
      <pubDate>Sat, 30 Oct 2021 20:07:58 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/life/20211031%E5%9B%9E%E5%9B%BD%E5%86%85%E5%8D%B7/</guid>
      <description>回国后，我如愿以偿的成为了一名又苦又累的Python后端开发工程师。一眨眼，入职已经两个多月了。我只能说，路是自己选的，苦也是自己选的，人生无非是苦中作乐。
记得当初我要找后端开发的工作时，一个朋友劝我，“不要去做后端，等你做久了就会发现，很无聊的，后端就是体力活。”
我头一偏，“我不，我觉得后端还挺好玩的。”
这个又苦又累的过程，从4月初准备面试时就开始了。
在我分析了几份job description的过程中发现，苍天，要准备的东西太多了吧。编程语言Python的特性与使用要熟悉吧？否则你怎么好意思说你是写Python的。数据库不能只会增删改查吧？高级应用建个索引，弄个查询优化要会吧？常见的数据结构和算法要知道吧，Leetcode刷题至少要刷个100道吧，不然连笔试都过不了。git， linux操作要知道一些吧？没用过可不行啊！做Python后端，Django/Flask要用过吧，至少自己得做个小网站出来。设计模式要稍微知道一点吧？Docker/openstack/k8s这些都最好有涉猎吧。
照着jd我分析了下我的技能：每个以前都用过一点，但每个都不深入。
于是我开始了准备的过程：每天刷题，同时看《流畅的Python》，同时在b站上看数据库，同时在看django实践。
准备了两个月之后（在此谢谢前司轻松的在家办公氛围，让我有很多时间准备面试），一个朋友劝我不要一味的准备，不管有没有准备好都要先去面试，在面试中成长就是最快的。于是我的简历被内推了，我也有了第一次面试。
第一次国内面试第一感觉就是流程好快，简历刚发，就来面试通知了。第二感觉就是，真的长见识。就算我不是他们要找的人，公司不是我要找的公司，我也能从面试中知道这个公司在做什么，需要什么样的人，而我合不合适。多面同一行业的岗位几次，也基本知道这个行业大家在做什么，现在缺什么人。这种反馈让我不断地调整自己的定位和期望。
很快，我又投了很多职位，接下来的两周，基本上每天都有一两个面试。每一次面试我都会记录问的问题，然后好好总结，这样，我也有了一份属于我自己的面试宝典。
时间很快，6月底快到了，我马上就要回国了。这个月让我印象最深的是一个周五的上午，是我在Cariad工作的最后一天。我记得这一天，因为心情起伏非常大，上午我有个面试，刚挂电话，楚哥特别着急的和我说我们回国的航班取消了，我有点慌了，马上打开手机查最近的能回国的票，一查最近都没有，然后电脑那发出会议提醒，还有5分钟就是我的线上离职欢送会了。我赶紧进入页面，气氛一片祥和，同事们都带着微笑，我心里在焦虑我的机票还没搞定，房子月底到期还要另外找住的地方，却还要假装镇定的说感谢巴拉巴拉。
后来我们另外买了票，也找到了住处，这一天的感觉却是很久都忘不掉。我们同组的同事很nice，给我准备了拜仁的球迷商店的券作为离职礼物，非常感谢他们，也很感恩人生中有这段共事的日子。
扯远了，离职之后，我有更多的时间来准备面试和面试了。我也开始更有针对性地投简历。首先我把城市设为上海和南京，其次，我不再接受外包的面试（在初期，外包会有很多面试的机会），最后，我把眼光看向很多我觉得有潜力的感兴趣的小公司，尽一切力量去挖掘这这些公司的现状。
最后连隔离的时候都一直都在面试，每天给自己打鸡血，白天面试晚上总结，幸运的是最后也拿到了几个offer，大部分都是和AI有关的公司，最终来了现在这个公司。
但是咋说，大家都知道现在是AI的寒冬吧。事实上，因为前几年投资者被AI忽悠的太厉害了，投了很多钱给机器学习/深度学习，最后却发现落地很难，于是现在涉及到AI的投资就变得很谨慎。最典型的例子就是商汤科技几年亏损两百多个亿，却还没有盈利的能力，让人唏嘘啊。
所以车企的小伙伴想转行到互联网，我都劝不要转，除非是真的热爱。在德国的话汽车行业的福利已经足够好了，在国内的话新能源汽车自动驾驶才是风口，搞手机的搞通讯的搞互联网的都去搞汽车了。要转行，三思啊！
而且我在上海已经过上了传说中的995（有可能周六也要上半天班）的内卷生活，想要wlb的人肯定觉得很煎熬。回国以后我偶尔会感叹“我离世界很远”，但是又觉得“踏实过好当下每一天也很好”。
我也说不准换国家换行业换岗位这个决定对我是利大于弊还是弊大于利，只是觉得，我喜欢什么，就应该去亲近什么。喜欢阅读，就多去读书，喜欢聊天，就多交朋友。不管这件事情最后给我带来什么，它至少给我带来了乐趣。在这些乐趣中，我才算真正倾听了内心的声音。如黑塞在《德米安》书中说的，“对每个人而言，真正的职责只有一个：找到自我。然后在心中坚守其一生，全心全意，永不停息。所有其它的路都是不完整的，是人的逃避方式，是对大众理想的懦弱回归，是随波逐流，是对内心的恐惧。”
共勉。</description>
    </item>
    
  </channel>
</rss>
