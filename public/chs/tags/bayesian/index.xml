<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bayesian on 徐慧志的个人博客</title><link>https://huizhixu.github.io/chs/tags/bayesian/</link><description>Recent content in Bayesian on 徐慧志的个人博客</description><generator>Hugo</generator><language>chs</language><lastBuildDate>Tue, 05 Mar 2024 20:01:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/tags/bayesian/index.xml" rel="self" type="application/rss+xml"/><item><title>改进量的期望 Expected Improvement</title><link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link><pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid><description>&lt;p>在看正文之前，先复习一下期望（Expectation）：&lt;/p>
&lt;p>在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。&lt;/p>
&lt;p>对于一个连续随机变量&lt;em>X&lt;/em>，其期望值可以通过以下公式计算：&lt;/p></description></item><item><title>Bayesian Optimization</title><link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link><pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid><description>&lt;p>贝叶斯优化有重要的两步步：&lt;/p>
&lt;ol>
&lt;li>构造代理模型（surrogate model）&lt;/li>
&lt;li>由获取函数（acquisition function）来生成采样建议&lt;/li>
&lt;/ol>
&lt;p>贝叶斯优化中，因为不知道目标函数的closed-form，所以需要构造一个代理模型（surrogate model）来近似目标函数。记住，代理模型对目标函数的潜在分布进行建模。通常用gaussian process来作为代理模型，也可以用random forest来作为代理模型。（任何模型，只要它为函数提供后验估计，可以用来作为surrogate model）。&lt;/p></description></item><item><title>Gaussian Process Regression with GPyTorch</title><link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link><pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid><description>&lt;p>这个例子主要是利用GPytorch，来实现高斯过程回归。&lt;/p>
&lt;h1 id="计算mean">计算Mean&lt;/h1>
&lt;ol>
&lt;li>zero mean function &lt;code>gpytorch.means.ZeroMean()&lt;/code>&lt;/li>
&lt;li>constant mean function &lt;code>gpytorch.means.ConstantMean()&lt;/code>&lt;/li>
&lt;li>linear mean function &lt;code>gpytorch.means.LinearMean()&lt;/code>&lt;/li>
&lt;/ol>
&lt;h1 id="计算covariance">计算Covariance&lt;/h1>
&lt;ol>
&lt;li>RBFKernel &lt;code>gpytorch.kernels.RBFKernel()&lt;/code>&lt;/li>
&lt;li>adding a scaling coefficient: &lt;code>kernels.ScaleKernel(gpytorch.kernels.RBFKernel())&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>一般会在核函数的输出上添加缩放系数。&lt;/p>
&lt;p>在核函数的输出上添加缩放系数是为了调整核函数的影响力。&lt;/p></description></item><item><title>Gaussian Process in Practice 高斯过程实践</title><link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link><pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid><description>&lt;p>这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。&lt;/p>
&lt;h2 id="1-先验分布">1. 先验分布&lt;/h2>
&lt;h4 id="11-多变量高斯分布">1.1 多变量高斯分布&lt;/h4>
&lt;ul>
&lt;li>创建一个包含n个候选输入位置的列表${x_i，i=1,&amp;hellip;,n}$&lt;/li>
&lt;li>初始化均值向量μ和协方差矩阵K（含n x n个元素）
&lt;ul>
&lt;li>假设x_1和x_2是多维的矩阵。x_1是一个 m* d的矩阵，x_2是一个n&lt;em>d的矩阵，那么K是一个m&lt;/em>n的矩阵，$K[i,j] = k(x_1[i,:], x_2[j,:])$&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>执行Cholesky分解K=LL T来获得L&lt;/li>
&lt;li>通过LN（0,I）获得N（0,K）上的一个样本并存储在f_prior中&lt;/li>
&lt;/ul>
&lt;p>multivariante_samples01 和multivariante_samples02 这两个function的作用是一样的，只不过有两种写法。&lt;/p></description></item><item><title>Kernel Function 核函数</title><link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link><pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid><description>&lt;p>这篇文章主要解决三个问题：&lt;/p>
&lt;ol>
&lt;li>正态分布的表示&lt;/li>
&lt;li>核函数是什么，有什么类型&lt;/li>
&lt;li>已知先验知识，如何计算后验分布&lt;/li>
&lt;/ol>
&lt;h2 id="1-正态分布的表示">1. 正态分布的表示&lt;/h2>
&lt;p>正态分布一般表示为$f \sim N(0,K)$，书上写作 $p(f|x) = N(f|0,K)$。&lt;/p></description></item><item><title>书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title><link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link><pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid><description>&lt;h2 id="1-理解covariance-matrix">1. 理解covariance matrix&lt;/h2>
&lt;p>Gaussian Process is a stochastic process used to characterize the distribution over function.&lt;/p>
&lt;p>GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。&lt;/p>
&lt;p>假设我们有两个变量，X1和X2，它俩符合multivariate Gaussian distribution。&lt;/p></description></item><item><title>论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title><link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link><pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate><guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid><description>&lt;p>Abstract&lt;/p>
&lt;ul>
&lt;li>types
&lt;ul>
&lt;li>第一种分类
&lt;ul>
&lt;li>data uncertainty (measurement noise)&lt;/li>
&lt;li>model uncertainty ( limited data)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>第二种分类
&lt;ul>
&lt;li>epistemic uncertainty
&lt;ul>
&lt;li>认知上的不确定性，通常是由于没有足够的知识（数据）而产生&lt;/li>
&lt;li>can be reducible&lt;/li>
&lt;li>分为两类
&lt;ul>
&lt;li>model-form uncertainty
&lt;ul>
&lt;li>由于模型的选择导致，例如architectures, activation functions or kernel functions&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>parameter uncertainty
&lt;ul>
&lt;li>在训练过程产生，由于数据不够导致&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>aleatory uncertainty
&lt;ul>
&lt;li>stems from physical systems, 具有随机性, cannot be reducible&lt;/li>
&lt;li>e.g. noises&lt;/li>
&lt;li>这种类型的不确定性在ML模型里面被看成是似然函数的一部分(a part of the likelihood function)&lt;/li>
&lt;li>也被叫做data uncertainty&lt;/li>
&lt;li>捕捉这种不确定性的方式有：同方差 homoscedastic和异方差 heteroscedastic&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>例子：
&lt;ul>
&lt;li>test data和train data不同分布：epistemic uncertainty (model performs poorer in extrapolation than in interpolation)&lt;/li>
&lt;li>测量数据由仪器导致的误差是aleatory Unc， 大试如果由于精度原因导致，则属于epistemic unc，因为提高精度可以减少这个误差&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>causes&lt;/li>
&lt;li>methods:
&lt;ul>
&lt;li>Gaussian process regression
&lt;ul>
&lt;li>a ML method with UQ capability&lt;/li>
&lt;li>一般不用来quantify uncertainty of a final surrogate&lt;/li>
&lt;li>一般用来在高度不确定的采样空间里采样，来减少训练样本的数量
&lt;ul>
&lt;li>to build an accurate surrogate within some lower and upper bounds of input variables&lt;/li>
&lt;li>to find a globally optimally design for black-box objective function&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>一般不评估GPR的UQ质量
&lt;ul>
&lt;li>因为预测一般在pre-defined design bounds&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Bayesian neural network
&lt;ul>
&lt;li>Monte Carlo dropout as an alternative to traditional Bayesian neural network&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>neural network ensemble
&lt;ul>
&lt;li>neural network ensemble consisting of multiple neural networks&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>deterministic UQ methods&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>metrics
&lt;ul>
&lt;li>classification
&lt;ul>
&lt;li>probability can be viewed as uncertainty&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>regression
&lt;ul>
&lt;li>confidence interval :
&lt;ul>
&lt;li>没看懂： prediction may be 120 ± 15, in weeks, which represents a two-sided 95% confidence interval (i.e.,∼1.96 standard deviations subtracted from or added to the mean estimate assuming the model-predicted RUL follows a Gaussian distribution).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item></channel></rss>