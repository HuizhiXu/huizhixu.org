<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bayesian on 徐慧志的个人博客</title>
    <link>https://huizhixu.github.io/chs/tags/bayesian/</link>
    <description>Recent content in bayesian on 徐慧志的个人博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>chs</language>
    <lastBuildDate>Tue, 05 Mar 2024 20:01:50 +0800</lastBuildDate><atom:link href="https://huizhixu.github.io/chs/tags/bayesian/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>改进量的期望 Expected Improvement</title>
      <link>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</link>
      <pubDate>Tue, 05 Mar 2024 20:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240305expected-improvement/</guid>
      <description>在看正文之前，先复习一下期望（Expectation）： 在统计学和概率论中，期望是一个衡量随机变量取值的中心趋势的指标。 对于一个连续随机变量</description>
    </item>
    
    <item>
      <title>Bayesian Optimization</title>
      <link>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</link>
      <pubDate>Sat, 03 Feb 2024 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20240203%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/</guid>
      <description>贝叶斯优化有重要的两步步： 构造代理模型（surrogate model） 由获取函数（acquisition function）来生成采样建议 贝叶</description>
    </item>
    
    <item>
      <title>Gaussian Process Regression with GPyTorch</title>
      <link>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</link>
      <pubDate>Sun, 17 Dec 2023 17:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231217gaussian_process_regression_gpytorch/</guid>
      <description>这个例子主要是利用GPytorch，来实现高斯过程回归。 计算Mean zero mean function gpytorch.means.ZeroMean() constant mean function gpytorch.means.ConstantMean() linear mean function gpytorch.means.LinearMean() 计算Covariance RBFKernel gpytorch.kernels.RBFKernel() adding a scaling coefficient: kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) 一般会在核</description>
    </item>
    
    <item>
      <title>Gaussian Process in Practice 高斯过程实践</title>
      <link>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</link>
      <pubDate>Sun, 10 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231210gaussian_process_in_practice/</guid>
      <description>这个例子主要是利用高斯过程的先验分布，将样本绘制成曲线。然后更新参数，利用后验分布获得新的曲线。 1. 先验分布 1.1 多变量高斯分布 创建一个包含n个候</description>
    </item>
    
    <item>
      <title>Kernel Function 核函数</title>
      <link>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</link>
      <pubDate>Thu, 07 Dec 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231207kernel_function/</guid>
      <description>这篇文章主要解决三个问题： 正态分布的表示 核函数是什么，有什么类型 已知先验知识，如何计算后验分布 1. 正态分布的表示 正态分布一般表示为$f \sim N(0</description>
    </item>
    
    <item>
      <title>书籍 Bayesian Optimization Theory and Practice using Python 之Gaussian Process</title>
      <link>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</link>
      <pubDate>Sat, 25 Nov 2023 18:01:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231125gaussian_process/</guid>
      <description>1. 理解covariance matrix Gaussian Process is a stochastic process used to characterize the distribution over function. GP将一组有限的参数theta从一个连空间拓展到一个连续无限空间的一个无限函数f。 假设</description>
    </item>
    
    <item>
      <title>论文 Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics</title>
      <link>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</link>
      <pubDate>Mon, 20 Nov 2023 18:31:50 +0800</pubDate>
      
      <guid>https://huizhixu.github.io/chs/know_how/20231120uncertainty/</guid>
      <description>Abstract types 第一种分类 data uncertainty (measurement noise) model uncertainty ( limited data) 第二种分类 epistemic uncertainty 认知上的不确定性，通常是由于没有足够的知识（数据）而产生 can be reducible 分为两类 model-form uncertainty 由于模型的选择导致，</description>
    </item>
    
  </channel>
</rss>
