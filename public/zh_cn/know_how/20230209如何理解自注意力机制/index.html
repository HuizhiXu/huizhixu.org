<!DOCTYPE html>
<html lang="zh_cn" itemscope itemtype="http://schema.org/WebPage"><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="/favicon.svg">

  <title>
  2023-02-09 如何理解自注意力机制 - 徐慧志的个人博客
  </title>
  <meta name="description" content="Attention is all you need" />
  <meta name="author" content="Huizhi" />
  <meta name="generator" content="Hugo 0.115.4"><link
    rel="stylesheet"
    href="https://huizhixu.github.io/css/styles.min.57124cb7ab8760d9d9bd2f6915dfa0c0b534e2142ec246f479dc97d0fe212c75.css"
    integrity="sha256-VxJMt6uHYNnZvS9pFd+gwLU04hQuwkb0edyX0P4hLHU="
  />
  
  

  <meta property="og:title" content="2023-02-09 如何理解自注意力机制" />
<meta property="og:description" content="Attention is all you need" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://huizhixu.github.io/zh_cn/know_how/20230209%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" /><meta property="article:section" content="know_how" />
<meta property="article:published_time" content="2023-02-09T08:31:50+08:00" />
<meta property="article:modified_time" content="2023-03-30T00:00:00+00:00" />

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="2023-02-09 如何理解自注意力机制"/>
<meta name="twitter:description" content="Attention is all you need"/>

  <meta itemprop="name" content="2023-02-09 如何理解自注意力机制">
<meta itemprop="description" content="Attention is all you need"><meta itemprop="datePublished" content="2023-02-09T08:31:50+08:00" />
<meta itemprop="dateModified" content="2023-03-30T00:00:00+00:00" />
<meta itemprop="wordCount" content="398">
<meta itemprop="keywords" content="emoji," />

  
  <meta name="lang" content="zh_cn" />
  
</head>
<body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative">
  <a href="https://huizhixu.github.io/zh_cn/" class="capitalize font-extrabold text-2xl">
    
    <img src="/blist-logo.png" alt="徐慧志的个人博客" class="h-8 max-w-full" />
    
  </a>
  <button class="mobile-menu-button md:hidden">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <line x1="4" y1="8" x2="20" y2="8" />
      <line x1="4" y1="16" x2="20" y2="16" />
    </svg>
  </button>
  <ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800">

    
    <li><a href="/zh_cn/life/">生活见闻</a></li>
    
    <li><a href="/zh_cn/know_how/">IT技术</a></li>
    
    <li><a href="/zh_cn/treasure/">宝藏集结</a></li>
    
    <li><a href="/zh_cn/tags/">分类</a></li>
    

    
    
    <li class="relative cursor-pointer">
      <span class="language-switcher flex items-center gap-2">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"
          stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="12" cy="12" r="9" />
          <line x1="3.6" y1="9" x2="20.4" y2="9" />
          <line x1="3.6" y1="15" x2="20.4" y2="15" />
          <path d="M11.5 3a17 17 0 0 0 0 18" />
          <path d="M12.5 3a17 17 0 0 1 0 18" />
        </svg>
        <a>Language</a>
        <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14"
          viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round"
          stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <path d="M18 15l-6 -6l-6 6h12" transform="rotate(180 12 12)" />
        </svg>
      </span>
      <div
        class="language-dropdown absolute top-full mt-2 left-0 flex-col gap-2 bg-gray-100 dark:bg-gray-900 dark:text-white z-10 hidden">
        
        
        
        
        <a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href="/en/" lang="en">English</a>
        
        
        
        <a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href="/de/" lang="de">Deutsch</a>
        
        
      </div>
    </li>
    
    

    
    <li class="grid place-items-center">
      <span class="open-search inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="10" cy="10" r="7" />
          <line x1="21" y1="21" x2="15" y2="15" />
        </svg>
      </span>
    </li>
    

    
    <li class="grid place-items-center">
      <span class="toggle-dark-mode inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="12" cy="12" r="3" />
          <line x1="12" y1="5" x2="12" y2="5.01" />
          <line x1="17" y1="7" x2="17" y2="7.01" />
          <line x1="19" y1="12" x2="19" y2="12.01" />
          <line x1="17" y1="17" x2="17" y2="17.01" />
          <line x1="12" y1="19" x2="12" y2="19.01" />
          <line x1="7" y1="17" x2="7" y2="17.01" />
          <line x1="5" y1="12" x2="5" y2="12.01" />
          <line x1="7" y1="7" x2="7" y2="7.01" />
        </svg>
      </span>
    </li>
    
  </ul>
</header>
<main class="flex-1">
  
  

  
  <div class="relative max-w-5xl mx-auto px-4">
    <img src="https://picsum.photos/id/19/400/250" class="rounded-lg shadow-sm w-full object-contain" />
    
    <div class="absolute top-4 right-8 rounded shadow bg-white text-gray-900 dark:bg-gray-900 dark:text-white px-2 py-0.5">
      
  
    February 9, 2023
  


    </div>
    
  </div>
  

  <article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4">

    <h1 class="text-2xl font-bold mb-2">2023-02-09 如何理解自注意力机制</h1>
    
    <h5 class="text-sm flex items-center flex-wrap">
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <rect x="4" y="5" width="16" height="16" rx="2" />
        <line x1="16" y1="3" x2="16" y2="7" />
        <line x1="8" y1="3" x2="8" y2="7" />
        <line x1="4" y1="11" x2="20" y2="11" />
        <rect x="8" y="15" width="2" height="2" />
      </svg>
      Posted on 
  
    February 9, 2023
  


      
        &nbsp(Last modified on 
  
    March 30, 2023
  

)</h5><h5 class="text-sm flex items-center flex-wrap">
      
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <circle cx="12" cy="12" r="9" />
        <polyline points="12 7 12 12 15 15" />
      </svg>
      2&nbsp;minutes
      &nbsp;&bull;
      <svg xmlns="http://www.w3.org/2000/svg" class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <line x1="3" y1="6" x2="3" y2="19" />
        <line x1="12" y1="6" x2="12" y2="19" />
        <line x1="21" y1="6" x2="21" y2="19" />
      </svg>
      398&nbsp;words
      
        
      
    </h5>
    

    <details id="TableOfContents" class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc">
    <summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white">
      <span>Table of contents</span>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <polyline points="6 9 12 15 18 9"></polyline>
     </svg>
    </summary>

    <ul class="mt-2 pb-4">
        

        
        <li>
        <a href="#%e7%90%86%e8%a7%a3%e8%be%93%e5%85%a5%e4%b8%8e%e8%be%93%e5%87%ba">理解输入与输出</a>
        

        
        </li><li>
        <a href="#%e4%b8%80%e4%b8%aavector%e5%af%b9%e5%ba%94%e4%b8%80%e4%b8%aalabel%e7%9a%84%e6%83%85%e5%86%b5%e5%8d%b3%e8%be%93%e5%85%a5%e5%92%8c%e8%be%93%e5%87%ba%e4%b8%80%e6%a0%b7%e5%a4%9a%e4%b9%9f%e5%8f%ab%e5%81%9asequence-labeling">一个vector对应一个label的情况，即输入和输出一样多，也叫做sequence labeling</a>
        

        
        </li><li>
        <a href="#self-attention">Self-attention</a>
        

        
        <ul>
            <li>
        <a href="#%e8%bf%90%e4%bd%9c%e5%8e%9f%e7%90%86">运作原理：</a>
        

        
        </li></ul>
      </li><li>
        <a href="#qkv%e4%bb%8e%e7%9f%a9%e9%98%b5%e7%9a%84%e8%a7%92%e5%ba%a6%e7%9c%8bself-attention">$QKV$（从矩阵的角度看self-attention）</a>
        

        
        </li><li>
        <a href="#%e6%80%8e%e4%b9%88%e5%be%97%e5%88%b0wqwk%e5%92%8cwv">怎么得到$W^q$、$W^k$和$W^v$</a>
        

        
        </li><li>
        <a href="#%e8%87%aa%e6%b3%a8%e6%84%8f%e6%a8%a1%e5%9d%97%e8%ae%a1%e7%ae%97%e4%b8%a4%e4%b8%aa%e5%90%91%e9%87%8f%e7%9a%84%e5%85%b3%e8%81%94%e6%80%a7">自注意模块计算两个向量的关联性</a>
        

        
        <ul>
            <li>
        <a href="#%e5%86%85%e7%a7%af%e6%96%b9%e6%b3%95"><strong>内积方法</strong></a>
        

        
        </li><li>
        <a href="#%e7%9b%b8%e5%8a%a0%e6%96%b9%e6%b3%95"><strong>相加方法</strong></a>
        

        
        </li></ul>
      </li><li>
        <a href="#%e5%8f%82%e8%80%83">参考：</a>
        </li></ul>
  </details>

    <h2 id="理解输入与输出">理解输入与输出</h2>
<ul>
<li>输入有可能是一个 vector，有可能是多个 vector</li>
<li>输出：
<ul>
<li>一个序列对应一个 label。the whole sequence has a label
<ul>
<li>例子：在情感分析里面，This is good 对应的输入是多个 vector，输出为 positive，是一个vector。</li>
</ul>
</li>
<li>一个 vector 对应一个 label。一个序列对应多个 label。
<ul>
<li>例子：在词性标注里面，This is good 对应的输入是多个 vector，输出为 代词，动词，形容词。</li>
</ul>
</li>
<li>模型决定 label 的个数。seq2seq 任务
<ul>
<li>例子：在机器翻译里面，This is good 对应的输入是3个 vector，中文翻译是”不错“，输出为2个 vector。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="一个vector对应一个label的情况即输入和输出一样多也叫做sequence-labeling">一个vector对应一个label的情况，即输入和输出一样多，也叫做sequence labeling</h2>
<ul>
<li>例子： I saw a saw</li>
<li>如何解决 sequence labeling 的问题：用 fully connected network 对每一个 input vector 进行作用</li>
<li>弊端：
<ul>
<li>用 fully connected network 来输出，假设对 I saw a saw 做词性标注。对于 FC 层来说，两个 saw没有什么不同，但是他们实际上一个是动词，一个是名词。</li>
</ul>
</li>
<li>解决思路：考虑更多的上下文。每一个 fc 层，都对所有的输入作用。或者给他一个 window，作用于相邻的几个 input vector。但是作用还是有限，计算也很复杂。</li>
</ul>
<p>我们想考虑整个 sequence，但是不想把 sequence 所有的数据都包括在里面，就有了 self-attention。</p>
<h2 id="self-attention">Self-attention</h2>
<p>如果要考虑上下文的信息，输入可以扔进 self-attention 之后，生成 vector with context，然后丢进FC层，然后再过一次 self-attention，然后再丢进 FC 层。</p>
<p>可以这样理解，self-attention 获得上下文信息，FC 层专注于局部信息，交替使用。</p>
<h3 id="运作原理">运作原理：</h3>
<ul>
<li>输入：是一串 vector，可以是整个 network 的输入，也可以是 FC 层的输出，这里用 $a$ 表示。</li>
<li>输出：一串 vector，这里用  $b$ 表示。每一个 $b$  都对所有 $a$ 作用。（这个图乍一看很像上面的 FC，但其实不一样）</li>
</ul>
<p><img src="/img/20230209/0.png" alt="0"></p>
<p>问题就变成了，输入是 $a$ 时，如何计算 $b$？用 $b^1$来说明，具体分三步。</p>
<ul>
<li>如何产生 $b^1$ 这个向量：
<ul>
<li>
<p>第一步：找出 sequence 里面跟 $a^1$ 相关的其他向量。（FC 层会把 sequence 所有的向量都包括进来，这里只包括相关的向量，这就是不同点。）这个机制叫做自注意机制。</p>
<ul>
<li>每一个向量跟 $a^1$ 相关联的程度，我们用数值 $\alpha$ 来表示。</li>
<li>Self-attention 的 module 怎么决定两个向量的关联性呢？
<ul>
<li>内积：dot product （方法原理在文章最后面）</li>
<li>相加：additive（方法原理在文章最后面）</li>
</ul>
</li>
<li>这里的做法是：分别计算 $a^1$ 与 $a^2$， $a^3$，$a^4$ 的关联性</li>
<li>把 $a^1$ 乘以 $W^q$，得到 $q^1$ ，$q^1$ 就是 query——搜寻。</li>
<li>把 $a^2$ 乘以 $W^k$，得到 $k^2$，$k^2$ 就是 key——键。把 $a^3$ 乘以 $W^k$，得到 $k^3$，把 $a^4$ 乘以 $W^k$，得到 $k^4$。</li>
<li>那么 $\alpha_{1,2} =q^1\cdot k^2$，关联性就算出来了。$\alpha_{1,2}$ 也叫 attention score。</li>
<li>同理可以算出 $\alpha_{1,3}，$$\alpha_{1,4}$。</li>
<li>一般我们也会算 $q^1$ 和 $k^1$ 的关联性，也就是 $\alpha_{1,1}$。</li>
</ul>
<p><img src="/img/20230209/1.png" alt="1"></p>
</li>
<li>
<p>第二步：对 $\alpha_{1,1}$，$\alpha_{1,2}$，$\alpha_{1,3}$，$\alpha_{1,4}$进行Softmax 操作，得到$\alpha^\prime$。</p>
<ul>
<li>为什么要用 Softmax：Softmax 最常见，这里也可以用其他函数，可以用 relu 等。</li>
</ul>
</li>
<li>
<p>第三步：根据$\alpha^\prime$，在 sequence 里面抽取重要的信息。</p>
<ul>
<li>做法：将 $a^1$，$a^2$，$a^3$，$a^4$ 分别乘以 $W^v$，得到 $v^1，$$v^2，$$v^3$，$v^4$。  （其实这里$v^1，v^2，v^3，v^4$就是$a^1，a^2，a^3，a^4$自己本身的等价表示）</li>
<li>将 $v^1$ 到 $v^4$ 都乘以分别的 $\alpha^\prime$， 然后再相加。</li>
</ul>
<p>$$
b^1  = \sum_i \alpha\prime_{1,i} v^i
$$</p>
<ul>
<li>
<p>如果 $a^1$ 和 $a^2$ 的关联性很强，$\alpha^\prime_{1,2}$ 的值很大，那么经过 weighted sum 得到的 $b^1$ 的值就可能会接近 $v^2$。</p>
<p>也就是说，谁的 attention score 越大，谁的 v 就会 dominate 抽出来的结果。</p>
</li>
</ul>
<p><img src="/img/20230209/2.png" alt="2"></p>
</li>
</ul>
</li>
</ul>
<h2 id="qkv从矩阵的角度看self-attention">$QKV$（从矩阵的角度看self-attention）</h2>
<ol>
<li>把 $a^1$ 到 $a^4$ 看成是矩阵 $I$ 的列，$q^1$ 到 $q^4$ 是矩阵 $Q$ 的列，那么可以转化成矩阵间的运算。</li>
</ol>
<p>矩阵$I$乘以$Wq$，得到矩阵$Q$，$Q$的4列就是$q^1$到$q^4$。</p>
<p>同样，输入矩阵I乘以$W^k$，得到矩阵$K$，$K$的4列就是$k^1$到$k^4$。</p>
<p>输入$I$乘上三个不同的矩阵，就得到了$QKV$。</p>
<p><img src="/img/20230209/3.png" alt="3"></p>
<ol>
<li>
<p>每一个 $q$ 会和每一个 $k$ 计算内积，得到 attention score。</p>
<ol>
<li>
<p>矩阵和向量相乘：</p>
<ol>
<li>矩阵 $K$ 和 $q^1$ 内积，得到 $a^1$ 和其他输入的相关性。</li>
<li>矩阵 $K$ 和 $q^2$ 内积，得到 $a^2$ 和其他输入的相关性。</li>
<li>合起来，就是</li>
</ol>
<p>$$
\begin{array}{cc}<br>
\alpha_{1,1} &amp; \alpha_{2,1} &amp; \alpha_{3,1} &amp; \alpha_{4,1} \
\alpha_{1,2} &amp; \alpha_{2,2} &amp; \alpha_{3,2} &amp; \alpha_{4,2} \
\alpha_{1,3} &amp; \alpha_{2,3} &amp; \alpha_{3,3} &amp; \alpha_{4,3}\
\alpha_{1,4} &amp; \alpha_{2,4} &amp; \alpha_{3,4} &amp; \alpha_{4,4}
\end{array} =</p>
<p>\begin{array}{cc}
k^1 \
k^2 \
k^3 \
k^4 \<br>
\end{array}</p>
<p>\begin{array}{cc}
q^1 &amp;
q^2 &amp;
q^3 &amp;
q^4 &amp;
\end{array}
$$</p>
<p>简写为</p>
<p>$$
A = K^T \cdot Q
$$</p>
<p><img src="/img/20230209/4.png" alt="4"></p>
</li>
</ol>
</li>
<li>
<p>对 $A$ 做Softmax，得到 $A^\prime$</p>
</li>
<li>
<p>$V$乘以$A^\prime$得到B</p>
<ul>
<li>$v^1$乘上 $\alpha^\prime_{1,1}$， 加上$v^2$乘上 $\alpha^\prime_{1,2}$，等等，得到 $b^1$</li>
<li>$v^1$乘上 $\alpha^\prime_{1,1}$， 加上$v^2$乘上 $\alpha^\prime_{1,2}$，等等，得到 $b^2$</li>
<li>O 就是 Output</li>
</ul>
</li>
</ol>
<p><img src="/img/20230209/5.png" alt="5"></p>
<p>总结：先产生QKV，根据Q找出相关的位置，再对V做weighted sum。</p>
<p><img src="/img/20230209/6.png" alt="6"></p>
<h2 id="怎么得到wqwk和wv">怎么得到$W^q$、$W^k$和$W^v$</h2>
<p>初始化一个矩阵，通过training data 在训练过程中更新。</p>
<h2 id="自注意模块计算两个向量的关联性">自注意模块计算两个向量的关联性</h2>
<h3 id="内积方法"><strong>内积方法</strong></h3>
<p>左边的向量乘以 $W^q$ 矩阵，右边的向量乘以 $W^k$ 矩阵，得到 $q$ 和 $k$ 这两个向量。然后做内积，得到一个标量。</p>
<p>$$
\alpha = q \cdot k
$$</p>
<h3 id="相加方法"><strong>相加方法</strong></h3>
<p>左边的向量乘以 $W^q$ 矩阵，右边的向量乘以 $W^k$ 矩阵，得到 $q$ 和 $k$ 这两个向量。然后相加丢到tanh，再乘以 $W$，得到 $\alpha$。</p>
<p><img src="/img/20230209/7.png" alt="7"></p>
<h2 id="参考">参考：</h2>
<p>李宏毅老师的讲课视频</p>
<p><a href="https://www.bilibili.com/video/BV1v3411r78R?p=2&amp;vd_source=bbd38c44460fafa204a3540d4f8a2657" target="_blank" rel="noopener">11.【李宏毅机器学习2021】自注意力机制 (Self-attention) (下)_哔哩哔哩_bilibili</a>
</p>

  </article><div class="bg-pink-50 dark:bg-gray-900">
  <div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center">
    <div>
      <div class="text-2xl font-bold mb-2"></div>
      <p class="opacity-60"></p>
    </div>

    <ul class="flex justify-center gap-x-3 flex-wrap gap-y-2">
      
    </ul>
  </div>
</div>

    </main><footer class="container p-6 mx-auto flex justify-between items-center">
  <span class="text-sm font-light">
    
    Copyright © 2017 - Huizhi Xu · All rights reserved
    
  </span>
  <span onclick="window.scrollTo({top: 0, behavior: 'smooth'})" class="p-1 cursor-pointer">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5"
      stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M18 15l-6 -6l-6 6h12" />
    </svg>
  </span>
</footer>

<div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden">
  <div class="container max-w-3xl mx-auto p-12">
    <div class="relative">
      <div class="my-4 text-center text-2xl font-bold">Search</div>

      <span class="p-2 absolute right-0 top-0 cursor-pointer close-search">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <line x1="18" y1="6" x2="6" y2="18" />
          <line x1="6" y1="6" x2="18" y2="18" />
        </svg>
      </span>
    </div>

    <input type="search" class="py-2 px-3 w-full dark:text-black border dark:border-transparent"
      placeholder="Enter search query" />

    <div class="search-results text-lg font-medium my-4 hidden">Results</div>
    <ul class="search-list my-2">

    </ul>

    <div class="no-results text-center my-8 hidden">
      <div class="text-xl font-semibold mb-2">No results found</div>
      <p class="font-light text-sm">Try adjusting your search query</p>
    </div>
  </div>
</div>





<script src="https://huizhixu.github.io/js/scripts.min.js"></script>




<script>
  const languageMenuButton = document.querySelector('.language-switcher');
  const languageDropdown = document.querySelector('.language-dropdown');
  languageMenuButton.addEventListener('click', (evt) => {
    evt.preventDefault()
    if (languageDropdown.classList.contains('hidden')) {
      languageDropdown.classList.remove('hidden')
      languageDropdown.classList.add('flex')
    } else {
      languageDropdown.classList.add('hidden');
      languageDropdown.classList.remove('flex');
    }
  })
</script>



<script>
  
  const darkmode = document.querySelector('.toggle-dark-mode');
  function toggleDarkMode() {
    if (document.documentElement.classList.contains('dark')) {
      document.documentElement.classList.remove('dark')
      localStorage.setItem('darkmode', 'light')
    } else {
      document.documentElement.classList.add('dark')
      localStorage.setItem('darkmode', 'dark')
    }
  }
  if (darkmode) {
    darkmode.addEventListener('click', toggleDarkMode);
  }

  const darkStorage = localStorage.getItem('darkmode');
  const isBrowserDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

  if (!darkStorage && isBrowserDark) {
    document.documentElement.classList.add('dark');
  }

  if (darkStorage && darkStorage === 'dark') {
    toggleDarkMode();
  }
</script>


<script>
  const mobileMenuButton = document.querySelector('.mobile-menu-button')
  const mobileMenu = document.querySelector('.mobile-menu')
  function toggleMenu() {
    mobileMenu.classList.toggle('hidden');
    mobileMenu.classList.toggle('flex');
  }
  if(mobileMenu && mobileMenuButton){
    mobileMenuButton.addEventListener('click', toggleMenu)
  }
</script>
</body>
</html>
